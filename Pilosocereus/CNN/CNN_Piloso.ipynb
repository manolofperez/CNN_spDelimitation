{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CÃ³pia de Train_CNN_Piloso",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELhRS0fu2b6T"
      },
      "source": [
        "## **Notebook containing scripts and outputs of the training, cross-validation and empirical data prediction for *Pilosocereus aurisetus***\n",
        "From the manuscript Perez et al. \"Species Delimitation Meets Deep Learning: Insights from a Highly Fragmented Cactus System\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffjZgEDIRlld",
        "outputId": "2eb7eb84-5064-4a3e-9558-f77b1f2d2073"
      },
      "source": [
        "#mount google drive to load files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgc_VfbydhlW"
      },
      "source": [
        "# Import all required modules.\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.pooling import  AveragePooling1D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from random import shuffle\n",
        "import time\n",
        "\n",
        "# Define parameters for the CNN run.\n",
        "batch_size = 250\n",
        "epochs = 250\n",
        "num_classes = 7\n",
        "\n",
        "# Define the CNN architecture.\n",
        "def create_cnn(xtest, regularizer=None):\n",
        "\tinputShape = (xtest.shape[1], xtest.shape[2])\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = inputs\n",
        "\tx = Conv1D(250, kernel_size=2, activation='relu',input_shape=(xtest.shape[1], xtest.shape[2]))(x)\n",
        "\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n",
        "\tx = AveragePooling1D(pool_size=2)(x)\n",
        "\tx = Dropout(0.75)(x)\n",
        "\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n",
        "\tx = AveragePooling1D(pool_size=2)(x)\n",
        "\tx = Dropout(0.75)(x)\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(125, activation='relu')(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\tx = Dense(125, activation='relu')(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "  # The final fully-connected layer head will have a softmax dense layer.\n",
        "\tx = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\t# Construct the CNN.\n",
        "\tmodel = Model(inputs, x)\n",
        "\t# Return the CNN.\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_ohKNkh4Ki-"
      },
      "source": [
        "# **Train the network with 10,000 simulations from each model**\n",
        "Here we will use the full simulated dataset to train the network, by splitting the data with 75% of simulations for training and 25% for validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIM8vGTaaxRx",
        "outputId": "2608f470-311d-451e-b49e-f3248bcfa6a2"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/training10ksims.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/training10ksims.zip\n",
            "  inflating: simModel1.npy           \n",
            "  inflating: simModel2.npy           \n",
            "  inflating: simModel3.npy           \n",
            "  inflating: simModel4.npy           \n",
            "  inflating: simModel5.npy           \n",
            "  inflating: simModel6.npy           \n",
            "  inflating: simModel7.npy           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJgkHTL9Tddn",
        "outputId": "eb8889b1-0314-4b3b-8640-212a3adf760d"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train a network using 10K simulations per model.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing simulations.\n",
        "u1 = np.load(\"/content/simModel1.npy\",mmap_mode='r')\n",
        "u2 = np.load(\"/content/simModel2.npy\",mmap_mode='r')\n",
        "u3 = np.load(\"/content/simModel3.npy\",mmap_mode='r')\n",
        "u4 = np.load(\"/content/simModel4.npy\",mmap_mode='r')\n",
        "u5 = np.load(\"/content/simModel5.npy\",mmap_mode='r')\n",
        "u6 = np.load(\"/content/simModel6.npy\",mmap_mode='r')\n",
        "u7 = np.load(\"/content/simModel7.npy\",mmap_mode='r')\n",
        "\n",
        "# Combine all arrays.\n",
        "x=np.concatenate((u1,u2,u3,u4,u5,u6,u7),axis=0)\n",
        "\n",
        "# Label each simulated array.\n",
        "y=[0 for i in range(len(u1))]\n",
        "y.extend([1 for i in range(len(u2))])\n",
        "y.extend([2 for i in range(len(u3))])\n",
        "y.extend([3 for i in range(len(u4))])\n",
        "y.extend([4 for i in range(len(u5))])\n",
        "y.extend([5 for i in range(len(u6))])\n",
        "y.extend([6 for i in range(len(u7))])\n",
        "y = np.array(y)\n",
        "\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "\n",
        "x=x.astype(np.uint8)\n",
        "\n",
        "# Print label and simulations length, these should be the same.\n",
        "print (len(x), len(y))\n",
        "\n",
        "# Shuffle the arrays for training, keeping the labels in the same order.\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "# Separate train (75%) and validate (25%) sets.\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "del(x)\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network, using the architecture defined above.\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "# Compile the CNN.\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n",
        "print (f'Time: {time.time() - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70000 70000\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 195, 64)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 194, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 193, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d (AveragePo (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 95, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_1 (Average (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5875)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 125)               734500    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 882       \n",
            "=================================================================\n",
            "Total params: 877,382\n",
            "Trainable params: 877,382\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            "210/210 [==============================] - 40s 31ms/step - loss: 1.6314 - accuracy: 0.2721 - val_loss: 0.7130 - val_accuracy: 0.6727\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 2/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.7441 - accuracy: 0.6256 - val_loss: 0.4935 - val_accuracy: 0.7307\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 3/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.5792 - accuracy: 0.6920 - val_loss: 0.4780 - val_accuracy: 0.7110\n",
            "Epoch 4/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.5340 - accuracy: 0.7151 - val_loss: 0.4728 - val_accuracy: 0.7362\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 5/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.5156 - accuracy: 0.7222 - val_loss: 0.4773 - val_accuracy: 0.7338\n",
            "Epoch 6/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.4923 - accuracy: 0.7290 - val_loss: 0.5010 - val_accuracy: 0.7310\n",
            "Epoch 7/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.4941 - accuracy: 0.7338 - val_loss: 0.4628 - val_accuracy: 0.7558\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 8/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.4728 - accuracy: 0.7509 - val_loss: 0.4217 - val_accuracy: 0.7892\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 9/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.4499 - accuracy: 0.7737 - val_loss: 0.4546 - val_accuracy: 0.7913\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 10/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.4101 - accuracy: 0.8121 - val_loss: 0.2792 - val_accuracy: 0.9018\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 11/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.3147 - accuracy: 0.8813 - val_loss: 0.3047 - val_accuracy: 0.8995\n",
            "Epoch 12/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2893 - accuracy: 0.8964 - val_loss: 0.2696 - val_accuracy: 0.9088\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 13/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2690 - accuracy: 0.9043 - val_loss: 0.2248 - val_accuracy: 0.9183\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 14/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.2584 - accuracy: 0.9075 - val_loss: 0.2183 - val_accuracy: 0.9192\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 15/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2559 - accuracy: 0.9071 - val_loss: 0.2347 - val_accuracy: 0.9186\n",
            "Epoch 16/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.2427 - accuracy: 0.9126 - val_loss: 0.2467 - val_accuracy: 0.9135\n",
            "Epoch 17/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.2391 - accuracy: 0.9164 - val_loss: 0.2831 - val_accuracy: 0.9022\n",
            "Epoch 18/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.2288 - accuracy: 0.9178 - val_loss: 0.2020 - val_accuracy: 0.9270\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 19/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2251 - accuracy: 0.9205 - val_loss: 0.2199 - val_accuracy: 0.9173\n",
            "Epoch 20/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.2183 - accuracy: 0.9236 - val_loss: 0.2255 - val_accuracy: 0.9237\n",
            "Epoch 21/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.2251 - accuracy: 0.9218 - val_loss: 0.2576 - val_accuracy: 0.9155\n",
            "Epoch 22/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2123 - accuracy: 0.9230 - val_loss: 0.2363 - val_accuracy: 0.9190\n",
            "Epoch 23/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2020 - accuracy: 0.9288 - val_loss: 0.2039 - val_accuracy: 0.9229\n",
            "Epoch 24/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2089 - accuracy: 0.9256 - val_loss: 0.1989 - val_accuracy: 0.9297\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 25/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2071 - accuracy: 0.9270 - val_loss: 0.2085 - val_accuracy: 0.9261\n",
            "Epoch 26/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.2005 - accuracy: 0.9290 - val_loss: 0.2111 - val_accuracy: 0.9198\n",
            "Epoch 27/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1878 - accuracy: 0.9334 - val_loss: 0.2391 - val_accuracy: 0.9249\n",
            "Epoch 28/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1924 - accuracy: 0.9322 - val_loss: 0.2340 - val_accuracy: 0.9253\n",
            "Epoch 29/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1971 - accuracy: 0.9316 - val_loss: 0.2675 - val_accuracy: 0.9139\n",
            "Epoch 30/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1901 - accuracy: 0.9316 - val_loss: 0.2307 - val_accuracy: 0.9286\n",
            "Epoch 31/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1946 - accuracy: 0.9312 - val_loss: 0.2396 - val_accuracy: 0.9138\n",
            "Epoch 32/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1833 - accuracy: 0.9335 - val_loss: 0.2236 - val_accuracy: 0.9245\n",
            "Epoch 33/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1806 - accuracy: 0.9352 - val_loss: 0.2139 - val_accuracy: 0.9283\n",
            "Epoch 34/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1788 - accuracy: 0.9360 - val_loss: 0.1954 - val_accuracy: 0.9328\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "Epoch 35/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1742 - accuracy: 0.9391 - val_loss: 0.2219 - val_accuracy: 0.9244\n",
            "Epoch 36/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1912 - accuracy: 0.9326 - val_loss: 0.2209 - val_accuracy: 0.9281\n",
            "Epoch 37/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1643 - accuracy: 0.9401 - val_loss: 0.2303 - val_accuracy: 0.9259\n",
            "Epoch 38/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1624 - accuracy: 0.9413 - val_loss: 0.2321 - val_accuracy: 0.9251\n",
            "Epoch 39/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1673 - accuracy: 0.9413 - val_loss: 0.2241 - val_accuracy: 0.9244\n",
            "Epoch 40/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1690 - accuracy: 0.9403 - val_loss: 0.2279 - val_accuracy: 0.9277\n",
            "Epoch 41/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1685 - accuracy: 0.9405 - val_loss: 0.2259 - val_accuracy: 0.9269\n",
            "Epoch 42/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1647 - accuracy: 0.9414 - val_loss: 0.2272 - val_accuracy: 0.9206\n",
            "Epoch 43/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1632 - accuracy: 0.9412 - val_loss: 0.2485 - val_accuracy: 0.9222\n",
            "Epoch 44/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1673 - accuracy: 0.9423 - val_loss: 0.2260 - val_accuracy: 0.9256\n",
            "Epoch 45/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1643 - accuracy: 0.9422 - val_loss: 0.2310 - val_accuracy: 0.9266\n",
            "Epoch 46/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1529 - accuracy: 0.9461 - val_loss: 0.2554 - val_accuracy: 0.9223\n",
            "Epoch 47/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1612 - accuracy: 0.9437 - val_loss: 0.2267 - val_accuracy: 0.9276\n",
            "Epoch 48/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1560 - accuracy: 0.9450 - val_loss: 0.2200 - val_accuracy: 0.9266\n",
            "Epoch 49/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1526 - accuracy: 0.9461 - val_loss: 0.2485 - val_accuracy: 0.9247\n",
            "Epoch 50/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1509 - accuracy: 0.9465 - val_loss: 0.2618 - val_accuracy: 0.9194\n",
            "Epoch 51/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1565 - accuracy: 0.9458 - val_loss: 0.2576 - val_accuracy: 0.9217\n",
            "Epoch 52/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1487 - accuracy: 0.9478 - val_loss: 0.2158 - val_accuracy: 0.9275\n",
            "Epoch 53/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1401 - accuracy: 0.9514 - val_loss: 0.2543 - val_accuracy: 0.9253\n",
            "Epoch 54/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1443 - accuracy: 0.9485 - val_loss: 0.2670 - val_accuracy: 0.9169\n",
            "\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 55/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1277 - accuracy: 0.9546 - val_loss: 0.2344 - val_accuracy: 0.9275\n",
            "Epoch 56/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1217 - accuracy: 0.9567 - val_loss: 0.2431 - val_accuracy: 0.9249\n",
            "Epoch 57/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1237 - accuracy: 0.9558 - val_loss: 0.2307 - val_accuracy: 0.9287\n",
            "Epoch 58/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1243 - accuracy: 0.9565 - val_loss: 0.2410 - val_accuracy: 0.9276\n",
            "Epoch 59/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1159 - accuracy: 0.9594 - val_loss: 0.2532 - val_accuracy: 0.9254\n",
            "Epoch 60/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1169 - accuracy: 0.9592 - val_loss: 0.2585 - val_accuracy: 0.9243\n",
            "Epoch 61/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1157 - accuracy: 0.9594 - val_loss: 0.2692 - val_accuracy: 0.9258\n",
            "Epoch 62/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1110 - accuracy: 0.9593 - val_loss: 0.2508 - val_accuracy: 0.9269\n",
            "Epoch 63/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1128 - accuracy: 0.9613 - val_loss: 0.2443 - val_accuracy: 0.9279\n",
            "Epoch 64/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1122 - accuracy: 0.9610 - val_loss: 0.2486 - val_accuracy: 0.9285\n",
            "Epoch 65/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1105 - accuracy: 0.9612 - val_loss: 0.2814 - val_accuracy: 0.9195\n",
            "Epoch 66/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.1135 - accuracy: 0.9604 - val_loss: 0.2621 - val_accuracy: 0.9252\n",
            "Epoch 67/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1088 - accuracy: 0.9625 - val_loss: 0.2659 - val_accuracy: 0.9253\n",
            "Epoch 68/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1106 - accuracy: 0.9597 - val_loss: 0.2749 - val_accuracy: 0.9239\n",
            "Epoch 69/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1068 - accuracy: 0.9620 - val_loss: 0.2586 - val_accuracy: 0.9261\n",
            "Epoch 70/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1024 - accuracy: 0.9635 - val_loss: 0.2944 - val_accuracy: 0.9208\n",
            "Epoch 71/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1058 - accuracy: 0.9622 - val_loss: 0.2831 - val_accuracy: 0.9233\n",
            "Epoch 72/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1071 - accuracy: 0.9619 - val_loss: 0.2716 - val_accuracy: 0.9228\n",
            "Epoch 73/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1025 - accuracy: 0.9635 - val_loss: 0.2703 - val_accuracy: 0.9261\n",
            "Epoch 74/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1018 - accuracy: 0.9656 - val_loss: 0.2987 - val_accuracy: 0.9234\n",
            "\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 75/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1017 - accuracy: 0.9641 - val_loss: 0.2689 - val_accuracy: 0.9253\n",
            "Epoch 76/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0987 - accuracy: 0.9652 - val_loss: 0.2756 - val_accuracy: 0.9246\n",
            "Epoch 77/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0980 - accuracy: 0.9644 - val_loss: 0.2905 - val_accuracy: 0.9235\n",
            "Epoch 78/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0974 - accuracy: 0.9637 - val_loss: 0.2857 - val_accuracy: 0.9239\n",
            "Epoch 79/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0978 - accuracy: 0.9647 - val_loss: 0.2779 - val_accuracy: 0.9243\n",
            "Epoch 80/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.1020 - accuracy: 0.9640 - val_loss: 0.2892 - val_accuracy: 0.9240\n",
            "Epoch 81/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0975 - accuracy: 0.9650 - val_loss: 0.2787 - val_accuracy: 0.9251\n",
            "Epoch 82/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0990 - accuracy: 0.9654 - val_loss: 0.2767 - val_accuracy: 0.9251\n",
            "Epoch 83/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0996 - accuracy: 0.9648 - val_loss: 0.2821 - val_accuracy: 0.9246\n",
            "Epoch 84/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0972 - accuracy: 0.9643 - val_loss: 0.2807 - val_accuracy: 0.9247\n",
            "Epoch 85/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0907 - accuracy: 0.9671 - val_loss: 0.2902 - val_accuracy: 0.9244\n",
            "Epoch 86/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0907 - accuracy: 0.9682 - val_loss: 0.2905 - val_accuracy: 0.9230\n",
            "Epoch 87/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0964 - accuracy: 0.9650 - val_loss: 0.2798 - val_accuracy: 0.9251\n",
            "Epoch 88/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0948 - accuracy: 0.9666 - val_loss: 0.2835 - val_accuracy: 0.9245\n",
            "Epoch 89/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0940 - accuracy: 0.9666 - val_loss: 0.2893 - val_accuracy: 0.9245\n",
            "Epoch 90/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0948 - accuracy: 0.9672 - val_loss: 0.2908 - val_accuracy: 0.9243\n",
            "Epoch 91/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0924 - accuracy: 0.9680 - val_loss: 0.2796 - val_accuracy: 0.9252\n",
            "Epoch 92/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0946 - accuracy: 0.9665 - val_loss: 0.2873 - val_accuracy: 0.9253\n",
            "Epoch 93/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0954 - accuracy: 0.9658 - val_loss: 0.2841 - val_accuracy: 0.9251\n",
            "Epoch 94/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0944 - accuracy: 0.9665 - val_loss: 0.2898 - val_accuracy: 0.9246\n",
            "\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 95/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0894 - accuracy: 0.9678 - val_loss: 0.2939 - val_accuracy: 0.9238\n",
            "Epoch 96/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0941 - accuracy: 0.9668 - val_loss: 0.2887 - val_accuracy: 0.9243\n",
            "Epoch 97/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0956 - accuracy: 0.9659 - val_loss: 0.2896 - val_accuracy: 0.9245\n",
            "Epoch 98/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0903 - accuracy: 0.9671 - val_loss: 0.2929 - val_accuracy: 0.9242\n",
            "Epoch 99/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0897 - accuracy: 0.9687 - val_loss: 0.2937 - val_accuracy: 0.9241\n",
            "Epoch 100/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0947 - accuracy: 0.9664 - val_loss: 0.2941 - val_accuracy: 0.9244\n",
            "Epoch 101/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0883 - accuracy: 0.9687 - val_loss: 0.2863 - val_accuracy: 0.9252\n",
            "Epoch 102/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0910 - accuracy: 0.9685 - val_loss: 0.2900 - val_accuracy: 0.9246\n",
            "Epoch 103/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0887 - accuracy: 0.9682 - val_loss: 0.2881 - val_accuracy: 0.9246\n",
            "Epoch 104/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0918 - accuracy: 0.9672 - val_loss: 0.2925 - val_accuracy: 0.9247\n",
            "Epoch 105/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0923 - accuracy: 0.9672 - val_loss: 0.2889 - val_accuracy: 0.9248\n",
            "Epoch 106/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0884 - accuracy: 0.9682 - val_loss: 0.2950 - val_accuracy: 0.9246\n",
            "Epoch 107/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0914 - accuracy: 0.9680 - val_loss: 0.2928 - val_accuracy: 0.9242\n",
            "Epoch 108/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0909 - accuracy: 0.9685 - val_loss: 0.2860 - val_accuracy: 0.9255\n",
            "Epoch 109/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0888 - accuracy: 0.9680 - val_loss: 0.2926 - val_accuracy: 0.9245\n",
            "Epoch 110/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0866 - accuracy: 0.9686 - val_loss: 0.2893 - val_accuracy: 0.9251\n",
            "Epoch 111/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0894 - accuracy: 0.9680 - val_loss: 0.2908 - val_accuracy: 0.9245\n",
            "Epoch 112/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0911 - accuracy: 0.9681 - val_loss: 0.2893 - val_accuracy: 0.9254\n",
            "Epoch 113/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0846 - accuracy: 0.9704 - val_loss: 0.2908 - val_accuracy: 0.9247\n",
            "Epoch 114/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0895 - accuracy: 0.9687 - val_loss: 0.2864 - val_accuracy: 0.9255\n",
            "\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 115/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0946 - accuracy: 0.9664 - val_loss: 0.2895 - val_accuracy: 0.9252\n",
            "Epoch 116/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0902 - accuracy: 0.9671 - val_loss: 0.2882 - val_accuracy: 0.9255\n",
            "Epoch 117/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0893 - accuracy: 0.9683 - val_loss: 0.2886 - val_accuracy: 0.9250\n",
            "Epoch 118/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0941 - accuracy: 0.9657 - val_loss: 0.2882 - val_accuracy: 0.9255\n",
            "Epoch 119/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0873 - accuracy: 0.9697 - val_loss: 0.2890 - val_accuracy: 0.9250\n",
            "Epoch 120/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0946 - accuracy: 0.9679 - val_loss: 0.2886 - val_accuracy: 0.9254\n",
            "Epoch 121/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0898 - accuracy: 0.9675 - val_loss: 0.2900 - val_accuracy: 0.9252\n",
            "Epoch 122/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0911 - accuracy: 0.9670 - val_loss: 0.2917 - val_accuracy: 0.9247\n",
            "Epoch 123/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0919 - accuracy: 0.9671 - val_loss: 0.2917 - val_accuracy: 0.9247\n",
            "Epoch 124/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0901 - accuracy: 0.9666 - val_loss: 0.2924 - val_accuracy: 0.9247\n",
            "Epoch 125/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.2923 - val_accuracy: 0.9247\n",
            "Epoch 126/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0911 - accuracy: 0.9679 - val_loss: 0.2919 - val_accuracy: 0.9250\n",
            "Epoch 127/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0904 - accuracy: 0.9669 - val_loss: 0.2921 - val_accuracy: 0.9250\n",
            "Epoch 128/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0918 - accuracy: 0.9679 - val_loss: 0.2907 - val_accuracy: 0.9250\n",
            "Epoch 129/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0916 - accuracy: 0.9687 - val_loss: 0.2898 - val_accuracy: 0.9252\n",
            "Epoch 130/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0876 - accuracy: 0.9688 - val_loss: 0.2911 - val_accuracy: 0.9251\n",
            "Epoch 131/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0894 - accuracy: 0.9674 - val_loss: 0.2939 - val_accuracy: 0.9246\n",
            "Epoch 132/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0873 - accuracy: 0.9678 - val_loss: 0.2928 - val_accuracy: 0.9246\n",
            "Epoch 133/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0882 - accuracy: 0.9685 - val_loss: 0.2916 - val_accuracy: 0.9250\n",
            "Epoch 134/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0936 - accuracy: 0.9675 - val_loss: 0.2931 - val_accuracy: 0.9247\n",
            "\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "Epoch 135/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0886 - accuracy: 0.9685 - val_loss: 0.2929 - val_accuracy: 0.9249\n",
            "Epoch 136/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0898 - accuracy: 0.9678 - val_loss: 0.2929 - val_accuracy: 0.9250\n",
            "Epoch 137/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0924 - accuracy: 0.9674 - val_loss: 0.2929 - val_accuracy: 0.9249\n",
            "Epoch 138/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0873 - accuracy: 0.9677 - val_loss: 0.2925 - val_accuracy: 0.9249\n",
            "Epoch 139/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0941 - accuracy: 0.9665 - val_loss: 0.2924 - val_accuracy: 0.9248\n",
            "Epoch 140/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0893 - accuracy: 0.9691 - val_loss: 0.2923 - val_accuracy: 0.9249\n",
            "Epoch 141/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0927 - accuracy: 0.9673 - val_loss: 0.2919 - val_accuracy: 0.9250\n",
            "Epoch 142/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0896 - accuracy: 0.9674 - val_loss: 0.2923 - val_accuracy: 0.9249\n",
            "Epoch 143/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0917 - accuracy: 0.9672 - val_loss: 0.2918 - val_accuracy: 0.9248\n",
            "Epoch 144/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0911 - accuracy: 0.9674 - val_loss: 0.2913 - val_accuracy: 0.9250\n",
            "Epoch 145/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0894 - accuracy: 0.9678 - val_loss: 0.2914 - val_accuracy: 0.9250\n",
            "Epoch 146/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0881 - accuracy: 0.9686 - val_loss: 0.2917 - val_accuracy: 0.9249\n",
            "Epoch 147/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0892 - accuracy: 0.9676 - val_loss: 0.2914 - val_accuracy: 0.9249\n",
            "Epoch 148/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0870 - accuracy: 0.9693 - val_loss: 0.2910 - val_accuracy: 0.9249\n",
            "Epoch 149/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0889 - accuracy: 0.9677 - val_loss: 0.2911 - val_accuracy: 0.9249\n",
            "Epoch 150/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0930 - accuracy: 0.9663 - val_loss: 0.2908 - val_accuracy: 0.9248\n",
            "Epoch 151/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0928 - accuracy: 0.9665 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 152/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0876 - accuracy: 0.9681 - val_loss: 0.2906 - val_accuracy: 0.9249\n",
            "Epoch 153/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0895 - accuracy: 0.9669 - val_loss: 0.2904 - val_accuracy: 0.9250\n",
            "Epoch 154/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0937 - accuracy: 0.9666 - val_loss: 0.2905 - val_accuracy: 0.9249\n",
            "\n",
            "Epoch 00154: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "Epoch 155/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0916 - accuracy: 0.9682 - val_loss: 0.2906 - val_accuracy: 0.9249\n",
            "Epoch 156/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0902 - accuracy: 0.9678 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 157/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0882 - accuracy: 0.9691 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 158/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0886 - accuracy: 0.9682 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 159/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0880 - accuracy: 0.9683 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 160/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0901 - accuracy: 0.9685 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 161/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0890 - accuracy: 0.9681 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 162/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0908 - accuracy: 0.9676 - val_loss: 0.2906 - val_accuracy: 0.9249\n",
            "Epoch 163/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0899 - accuracy: 0.9682 - val_loss: 0.2906 - val_accuracy: 0.9249\n",
            "Epoch 164/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0899 - accuracy: 0.9683 - val_loss: 0.2906 - val_accuracy: 0.9249\n",
            "Epoch 165/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0901 - accuracy: 0.9678 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 166/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0891 - accuracy: 0.9679 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 167/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0898 - accuracy: 0.9670 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 168/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0945 - accuracy: 0.9673 - val_loss: 0.2907 - val_accuracy: 0.9250\n",
            "Epoch 169/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0898 - accuracy: 0.9684 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 170/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0877 - accuracy: 0.9679 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 171/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0926 - accuracy: 0.9667 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 172/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0930 - accuracy: 0.9675 - val_loss: 0.2907 - val_accuracy: 0.9249\n",
            "Epoch 173/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0904 - accuracy: 0.9677 - val_loss: 0.2907 - val_accuracy: 0.9250\n",
            "Epoch 174/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0925 - accuracy: 0.9672 - val_loss: 0.2908 - val_accuracy: 0.9250\n",
            "\n",
            "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "Epoch 175/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0896 - accuracy: 0.9679 - val_loss: 0.2908 - val_accuracy: 0.9250\n",
            "Epoch 176/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0936 - accuracy: 0.9661 - val_loss: 0.2908 - val_accuracy: 0.9250\n",
            "Epoch 177/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0929 - accuracy: 0.9668 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 178/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0916 - accuracy: 0.9679 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 179/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0895 - accuracy: 0.9671 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 180/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0908 - accuracy: 0.9679 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 181/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0894 - accuracy: 0.9679 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 182/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0880 - accuracy: 0.9700 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 183/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0908 - accuracy: 0.9675 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 184/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0905 - accuracy: 0.9687 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 185/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0891 - accuracy: 0.9678 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 186/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0905 - accuracy: 0.9667 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 187/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0872 - accuracy: 0.9701 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 188/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0918 - accuracy: 0.9665 - val_loss: 0.2908 - val_accuracy: 0.9249\n",
            "Epoch 189/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0969 - accuracy: 0.9653 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 190/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0939 - accuracy: 0.9664 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 191/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0951 - accuracy: 0.9683 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 192/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0909 - accuracy: 0.9681 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 193/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0910 - accuracy: 0.9677 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 194/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0933 - accuracy: 0.9656 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "\n",
            "Epoch 00194: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "Epoch 195/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0874 - accuracy: 0.9686 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 196/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0872 - accuracy: 0.9679 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 197/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0905 - accuracy: 0.9671 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 198/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0943 - accuracy: 0.9665 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 199/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0919 - accuracy: 0.9676 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 200/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0907 - accuracy: 0.9678 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 201/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0856 - accuracy: 0.9691 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 202/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0908 - accuracy: 0.9685 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 203/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0930 - accuracy: 0.9663 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 204/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0877 - accuracy: 0.9691 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 205/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0894 - accuracy: 0.9681 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 206/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0915 - accuracy: 0.9669 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 207/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0912 - accuracy: 0.9679 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 208/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0915 - accuracy: 0.9666 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 209/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0894 - accuracy: 0.9683 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 210/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0947 - accuracy: 0.9657 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 211/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0905 - accuracy: 0.9682 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 212/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0924 - accuracy: 0.9659 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 213/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0927 - accuracy: 0.9664 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 214/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0888 - accuracy: 0.9685 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "\n",
            "Epoch 00214: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
            "Epoch 215/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0859 - accuracy: 0.9703 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 216/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0887 - accuracy: 0.9692 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 217/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0941 - accuracy: 0.9659 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 218/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0896 - accuracy: 0.9681 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 219/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0901 - accuracy: 0.9668 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 220/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0903 - accuracy: 0.9675 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 221/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0876 - accuracy: 0.9678 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 222/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0876 - accuracy: 0.9691 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 223/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0885 - accuracy: 0.9689 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 224/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0923 - accuracy: 0.9675 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 225/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0882 - accuracy: 0.9692 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 226/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0934 - accuracy: 0.9665 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 227/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0881 - accuracy: 0.9686 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 228/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0857 - accuracy: 0.9686 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 229/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0949 - accuracy: 0.9683 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 230/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0906 - accuracy: 0.9678 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 231/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0967 - accuracy: 0.9654 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 232/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0908 - accuracy: 0.9685 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 233/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0864 - accuracy: 0.9687 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 234/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0908 - accuracy: 0.9683 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "\n",
            "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
            "Epoch 235/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0868 - accuracy: 0.9693 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 236/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0899 - accuracy: 0.9677 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 237/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0905 - accuracy: 0.9678 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 238/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0901 - accuracy: 0.9692 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 239/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0889 - accuracy: 0.9680 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 240/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0928 - accuracy: 0.9668 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 241/250\n",
            "210/210 [==============================] - 5s 26ms/step - loss: 0.0895 - accuracy: 0.9685 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 242/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0886 - accuracy: 0.9685 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 243/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0890 - accuracy: 0.9677 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 244/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0908 - accuracy: 0.9677 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 245/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0900 - accuracy: 0.9686 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 246/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0885 - accuracy: 0.9688 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 247/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0863 - accuracy: 0.9688 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 248/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0912 - accuracy: 0.9688 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 249/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0904 - accuracy: 0.9659 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Epoch 250/250\n",
            "210/210 [==============================] - 5s 25ms/step - loss: 0.0878 - accuracy: 0.9681 - val_loss: 0.2909 - val_accuracy: 0.9249\n",
            "Time: 1345.0518341064453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz0oGxt9B9C4",
        "outputId": "475ed701-21b7-467d-e91c-45a1172f4f1a"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/test1ksims.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/test1ksims.zip\n",
            "replace simModel1.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel1.npy           \n",
            "replace simModel2.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel2.npy           \n",
            "replace simModel3.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel3.npy           \n",
            "replace simModel4.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel4.npy           \n",
            "replace simModel5.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel5.npy           \n",
            "replace simModel6.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel6.npy           \n",
            "replace simModel7.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel7.npy           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYZM0kNZQUfR",
        "outputId": "61092bb6-b427-4f12-9335-6dccd0cfeb45"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 10K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing test set simulations.\n",
        "t1 = np.load(\"/content/simModel1.npy\",mmap_mode='r')\n",
        "t2 = np.load(\"/content/simModel2.npy\",mmap_mode='r')\n",
        "t3 = np.load(\"/content/simModel3.npy\",mmap_mode='r')\n",
        "t4 = np.load(\"/content/simModel4.npy\",mmap_mode='r')\n",
        "t5 = np.load(\"/content/simModel5.npy\",mmap_mode='r')\n",
        "t6 = np.load(\"/content/simModel6.npy\",mmap_mode='r')\n",
        "t7 = np.load(\"/content/simModel7.npy\",mmap_mode='r')\n",
        "t=np.concatenate((t1,t2,t3,t4,t5,t6,t7),axis=0)\n",
        "\n",
        "for arr,array in enumerate(t):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      t[arr][idx][t[arr][idx] == 0] = -1\n",
        "      t[arr][idx][t[arr][idx] == 1] = 0\n",
        "      t[arr][idx][t[arr][idx] == -1] = 1\n",
        "\n",
        "t=t.astype(np.uint8)\n",
        "\n",
        "# Label simulations from the test set.\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y.extend([5 for i in range(len(t6))])\n",
        "y.extend([6 for i in range(len(t7))])\n",
        "y = np.array(y)\n",
        "\n",
        "# Load the trained model.\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod')\n",
        "\n",
        "# Predict and export a confusion matrix.\n",
        "pred = model.predict(t)\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[876   0  18   0   0 106   0]\n",
            " [  2 824   0   9   5   0 160]\n",
            " [  0   0 998   2   0   0   0]\n",
            " [  0   1  46 929  23   0   1]\n",
            " [  0   1   0   1 997   0   1]\n",
            " [ 48   0  18   0   0 934   0]\n",
            " [  0  22   2  16   4   1 955]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "0PGIawyJEDo0",
        "outputId": "44d46ff4-24d4-4350-cc23-58f18322ca13"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Predict the most likely model for the empirical data, using the CNN trained with 10K simulations per model.\n",
        "################################################################################################################################################\n",
        "# Load the trained network.\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod')\n",
        "# Load empirical data and transpose it.\n",
        "infile=np.loadtxt(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Input_Piloso.txt\")\n",
        "inp=[]\n",
        "inp.append(np.array(infile).T)\n",
        "inp = np.array(inp)\n",
        "\n",
        "for idx,row in enumerate(inp[0]):\n",
        "  if np.count_nonzero(row) > len(row)/2:\n",
        "    inp[0][idx][inp[0][idx] == 0] = -1\n",
        "    inp[0][idx][inp[0][idx] == 1] = 0\n",
        "    inp[0][idx][inp[0][idx] == -1] = 1\n",
        "\n",
        "inp=inp.astype(np.uint8)\n",
        "\n",
        "#Export an image from the empirical data, to visualize its appearance\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(inp[0],cmap='gray', vmin=0, vmax=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f99e43512d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzIB9Q-nsFmE"
      },
      "source": [
        "t1 = np.load(\"/content/simModel1.npy\",mmap_mode='r')\n",
        "t2 = np.load(\"/content/simModel2.npy\",mmap_mode='r')\n",
        "t3 = np.load(\"/content/simModel3.npy\",mmap_mode='r')\n",
        "t4 = np.load(\"/content/simModel4.npy\",mmap_mode='r')\n",
        "t5 = np.load(\"/content/simModel5.npy\",mmap_mode='r')\n",
        "t6 = np.load(\"/content/simModel6.npy\",mmap_mode='r')\n",
        "t7 = np.load(\"/content/simModel7.npy\",mmap_mode='r')\n",
        "t=np.concatenate((t1,t2,t3,t4,t5,t6,t7),axis=0)\n",
        "\n",
        "for arr,array in enumerate(t):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      t[arr][idx][t[arr][idx] == 0] = -1\n",
        "      t[arr][idx][t[arr][idx] == 1] = 0\n",
        "      t[arr][idx][t[arr][idx] == -1] = 1\n",
        "\n",
        "t=t.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "BjhAI6Z694j3",
        "outputId": "b3fe8e76-9651-4eda-c355-8aaf6d636460"
      },
      "source": [
        "#now plot one image from each model to see their appearance\n",
        "f, axarr = plt.subplots(1,7) \n",
        "#model 1\n",
        "#ax.set_title(str(\"model 1\")\n",
        "axarr[0].imshow(t[0],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[1].imshow(t[1000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[2].imshow(t[2000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[3].imshow(t[3000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[4].imshow(t[4000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[5].imshow(t[5000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[6].imshow(t[6000],cmap='gray', vmin=0, vmax=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f99e408c990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhRSPczX7F92",
        "outputId": "c0c7474f-0b55-4573-9eff-eefbbc03b48d"
      },
      "source": [
        "# Predict the most likely model with the empirical data.\n",
        "pred = model.predict(inp)\n",
        "print(pred)\n",
        "\n",
        "#Repeat the predictions more 4 times after shuffling the order of rows (SNPs)\n",
        "#shuffle rows\n",
        "perm = np.arange(inp.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "inp = inp[perm]\n",
        "\n",
        "#and predict\n",
        "pred = model.predict(inp)\n",
        "print(pred)\n",
        "\n",
        "#shuffle rows\n",
        "perm = np.arange(inp.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "inp = inp[perm]\n",
        "\n",
        "#and predict\n",
        "pred = model.predict(inp)\n",
        "print(pred)\n",
        "\n",
        "#shuffle rows\n",
        "perm = np.arange(inp.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "inp = inp[perm]\n",
        "\n",
        "#and predict\n",
        "pred = model.predict(inp)\n",
        "print(pred)\n",
        "\n",
        "#shuffle rows\n",
        "perm = np.arange(inp.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "inp = inp[perm]\n",
        "\n",
        "#and predict\n",
        "pred = model.predict(inp)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9896288e-01 1.7545807e-04 1.4069257e-09 3.3225223e-10 6.5507436e-13\n",
            "  8.6170074e-04 7.3612116e-09]]\n",
            "[[9.9896288e-01 1.7545807e-04 1.4069257e-09 3.3225223e-10 6.5507436e-13\n",
            "  8.6170074e-04 7.3612116e-09]]\n",
            "[[9.9896288e-01 1.7545807e-04 1.4069257e-09 3.3225223e-10 6.5507436e-13\n",
            "  8.6170074e-04 7.3612116e-09]]\n",
            "[[9.9896288e-01 1.7545807e-04 1.4069257e-09 3.3225223e-10 6.5507436e-13\n",
            "  8.6170074e-04 7.3612116e-09]]\n",
            "[[9.9896288e-01 1.7545807e-04 1.4069257e-09 3.3225223e-10 6.5507436e-13\n",
            "  8.6170074e-04 7.3612116e-09]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ne-JFcm9eMw"
      },
      "source": [
        "# **Evaluate the impact of using different number of simulations to train the network**\n",
        "Below, we repeat the procedures of training and evalutating the CNN, with varying number of simulations (2,500; 1,000 and 500) per model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx3iXPj0Y_n4",
        "outputId": "5f596a03-4466-4e16-9ba7-b5e9042dc7b9"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 2.5K simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "x=np.concatenate((u1[0:2500,:,:],u2[0:2500,:,:],u3[0:2500,:,:],u4[0:2500,:,:],u5[0:2500,:,:],u6[0:2500,:,:],u7[0:2500,:,:]),axis=0)\n",
        "\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "\n",
        "x=x.astype(np.uint8)\n",
        "\n",
        "y=[0 for i in range(len(u1[0:2500,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:2500,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:2500,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:2500,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:2500,:,:]))])\n",
        "y.extend([5 for i in range(len(u6[0:2500,:,:]))])\n",
        "y.extend([6 for i in range(len(u7[0:2500,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n",
        "print (f'Time: {time.time() - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17500 17500\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 195, 64)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 194, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 193, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_2 (Average (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 95, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_3 (Average (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5875)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 125)               734500    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 882       \n",
            "=================================================================\n",
            "Total params: 877,382\n",
            "Trainable params: 877,382\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            "53/53 [==============================] - 4s 47ms/step - loss: 1.8976 - accuracy: 0.1908 - val_loss: 1.4259 - val_accuracy: 0.2901\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 2/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 1.4521 - accuracy: 0.3149 - val_loss: 1.1963 - val_accuracy: 0.3945\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 3/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1.2299 - accuracy: 0.4219 - val_loss: 0.8657 - val_accuracy: 0.5767\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 4/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.9445 - accuracy: 0.5720 - val_loss: 0.6645 - val_accuracy: 0.6251\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 5/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.7322 - accuracy: 0.6372 - val_loss: 0.6027 - val_accuracy: 0.6770\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 6/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.6603 - accuracy: 0.6538 - val_loss: 0.5598 - val_accuracy: 0.6843\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 7/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.6043 - accuracy: 0.6836 - val_loss: 0.5037 - val_accuracy: 0.7175\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 8/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.5936 - accuracy: 0.6964 - val_loss: 0.6391 - val_accuracy: 0.6738\n",
            "Epoch 9/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.5697 - accuracy: 0.6940 - val_loss: 0.5099 - val_accuracy: 0.7211\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 10/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.5392 - accuracy: 0.7079 - val_loss: 0.4984 - val_accuracy: 0.7184\n",
            "Epoch 11/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.5274 - accuracy: 0.7083 - val_loss: 0.5220 - val_accuracy: 0.7298\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 12/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.5382 - accuracy: 0.7029 - val_loss: 0.4944 - val_accuracy: 0.7303\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 13/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.5321 - accuracy: 0.7100 - val_loss: 0.4891 - val_accuracy: 0.7193\n",
            "Epoch 14/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.5036 - accuracy: 0.7199 - val_loss: 0.4951 - val_accuracy: 0.7381\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 15/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.4860 - accuracy: 0.7286 - val_loss: 0.5094 - val_accuracy: 0.7383\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 16/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.4980 - accuracy: 0.7270 - val_loss: 0.4798 - val_accuracy: 0.7371\n",
            "Epoch 17/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.4843 - accuracy: 0.7231 - val_loss: 0.5202 - val_accuracy: 0.7246\n",
            "Epoch 18/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4802 - accuracy: 0.7400 - val_loss: 0.5006 - val_accuracy: 0.7262\n",
            "Epoch 19/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4785 - accuracy: 0.7355 - val_loss: 0.5086 - val_accuracy: 0.7426\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 20/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.4654 - accuracy: 0.7372 - val_loss: 0.5037 - val_accuracy: 0.7445\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 21/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4641 - accuracy: 0.7425 - val_loss: 0.5262 - val_accuracy: 0.7216\n",
            "Epoch 22/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4549 - accuracy: 0.7433 - val_loss: 0.4786 - val_accuracy: 0.7374\n",
            "Epoch 23/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4485 - accuracy: 0.7534 - val_loss: 0.4923 - val_accuracy: 0.7463\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 24/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4509 - accuracy: 0.7548 - val_loss: 0.5065 - val_accuracy: 0.7458\n",
            "Epoch 25/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4437 - accuracy: 0.7645 - val_loss: 0.5555 - val_accuracy: 0.7346\n",
            "Epoch 26/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4642 - accuracy: 0.7540 - val_loss: 0.4799 - val_accuracy: 0.7598\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 27/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4291 - accuracy: 0.7771 - val_loss: 0.8015 - val_accuracy: 0.7202\n",
            "Epoch 28/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4614 - accuracy: 0.7762 - val_loss: 0.4367 - val_accuracy: 0.7849\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 29/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4235 - accuracy: 0.7824 - val_loss: 0.4939 - val_accuracy: 0.7749\n",
            "Epoch 30/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4106 - accuracy: 0.7881 - val_loss: 0.4806 - val_accuracy: 0.7909\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 31/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.4019 - accuracy: 0.7988 - val_loss: 0.4381 - val_accuracy: 0.7863\n",
            "Epoch 32/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.3994 - accuracy: 0.8048 - val_loss: 0.4728 - val_accuracy: 0.7762\n",
            "Epoch 33/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.3781 - accuracy: 0.8186 - val_loss: 0.4361 - val_accuracy: 0.8055\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 34/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.3750 - accuracy: 0.8332 - val_loss: 0.4383 - val_accuracy: 0.8041\n",
            "Epoch 35/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.3696 - accuracy: 0.8344 - val_loss: 0.4284 - val_accuracy: 0.8254\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 36/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.3629 - accuracy: 0.8415 - val_loss: 0.3908 - val_accuracy: 0.8322\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 37/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.3218 - accuracy: 0.8613 - val_loss: 0.4329 - val_accuracy: 0.8359\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 38/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.3181 - accuracy: 0.8677 - val_loss: 0.4013 - val_accuracy: 0.8466\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 39/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.2969 - accuracy: 0.8809 - val_loss: 0.3227 - val_accuracy: 0.8759\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 40/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.3246 - accuracy: 0.8686 - val_loss: 0.4039 - val_accuracy: 0.8592\n",
            "Epoch 41/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.2723 - accuracy: 0.8907 - val_loss: 0.3163 - val_accuracy: 0.8805\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 42/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2804 - accuracy: 0.8975 - val_loss: 0.3238 - val_accuracy: 0.8802\n",
            "Epoch 43/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2671 - accuracy: 0.8934 - val_loss: 0.3042 - val_accuracy: 0.8935\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 44/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2431 - accuracy: 0.9059 - val_loss: 0.3205 - val_accuracy: 0.8825\n",
            "Epoch 45/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.2458 - accuracy: 0.9086 - val_loss: 0.3375 - val_accuracy: 0.8896\n",
            "Epoch 46/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2422 - accuracy: 0.9070 - val_loss: 0.3146 - val_accuracy: 0.8953\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 47/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2438 - accuracy: 0.9122 - val_loss: 0.3241 - val_accuracy: 0.8885\n",
            "Epoch 48/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2053 - accuracy: 0.9246 - val_loss: 0.3382 - val_accuracy: 0.8919\n",
            "Epoch 49/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2245 - accuracy: 0.9163 - val_loss: 0.3137 - val_accuracy: 0.8946\n",
            "Epoch 50/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2038 - accuracy: 0.9247 - val_loss: 0.3257 - val_accuracy: 0.8937\n",
            "Epoch 51/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2199 - accuracy: 0.9194 - val_loss: 0.4446 - val_accuracy: 0.8658\n",
            "Epoch 52/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2149 - accuracy: 0.9205 - val_loss: 0.4000 - val_accuracy: 0.8789\n",
            "Epoch 53/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2042 - accuracy: 0.9255 - val_loss: 0.3068 - val_accuracy: 0.9022\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 54/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2080 - accuracy: 0.9229 - val_loss: 0.4262 - val_accuracy: 0.8768\n",
            "Epoch 55/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2031 - accuracy: 0.9251 - val_loss: 0.3779 - val_accuracy: 0.8709\n",
            "Epoch 56/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1966 - accuracy: 0.9283 - val_loss: 0.3878 - val_accuracy: 0.8875\n",
            "Epoch 57/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1896 - accuracy: 0.9334 - val_loss: 0.3058 - val_accuracy: 0.9097\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 58/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.2075 - accuracy: 0.9268 - val_loss: 0.3555 - val_accuracy: 0.8798\n",
            "Epoch 59/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1975 - accuracy: 0.9283 - val_loss: 0.3270 - val_accuracy: 0.8971\n",
            "Epoch 60/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1921 - accuracy: 0.9299 - val_loss: 0.3474 - val_accuracy: 0.8894\n",
            "Epoch 61/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1758 - accuracy: 0.9367 - val_loss: 0.3474 - val_accuracy: 0.8939\n",
            "Epoch 62/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1805 - accuracy: 0.9355 - val_loss: 0.2885 - val_accuracy: 0.9095\n",
            "Epoch 63/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1685 - accuracy: 0.9400 - val_loss: 0.4131 - val_accuracy: 0.8814\n",
            "Epoch 64/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1652 - accuracy: 0.9440 - val_loss: 0.3733 - val_accuracy: 0.8891\n",
            "Epoch 65/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1767 - accuracy: 0.9385 - val_loss: 0.3011 - val_accuracy: 0.9125\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 66/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1669 - accuracy: 0.9416 - val_loss: 0.4617 - val_accuracy: 0.8715\n",
            "Epoch 67/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1724 - accuracy: 0.9369 - val_loss: 0.3324 - val_accuracy: 0.8983\n",
            "Epoch 68/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1575 - accuracy: 0.9434 - val_loss: 0.4817 - val_accuracy: 0.8683\n",
            "Epoch 69/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1588 - accuracy: 0.9450 - val_loss: 0.3265 - val_accuracy: 0.8953\n",
            "Epoch 70/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1612 - accuracy: 0.9430 - val_loss: 0.4147 - val_accuracy: 0.8935\n",
            "Epoch 71/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1447 - accuracy: 0.9484 - val_loss: 0.3357 - val_accuracy: 0.9134\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "Epoch 72/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1571 - accuracy: 0.9467 - val_loss: 0.3905 - val_accuracy: 0.8869\n",
            "Epoch 73/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1567 - accuracy: 0.9398 - val_loss: 0.4020 - val_accuracy: 0.9003\n",
            "Epoch 74/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1438 - accuracy: 0.9484 - val_loss: 0.3538 - val_accuracy: 0.9031\n",
            "Epoch 75/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1410 - accuracy: 0.9498 - val_loss: 0.3681 - val_accuracy: 0.9029\n",
            "Epoch 76/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1482 - accuracy: 0.9455 - val_loss: 0.3433 - val_accuracy: 0.9054\n",
            "Epoch 77/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1314 - accuracy: 0.9529 - val_loss: 0.3542 - val_accuracy: 0.9019\n",
            "Epoch 78/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1317 - accuracy: 0.9518 - val_loss: 0.4969 - val_accuracy: 0.8798\n",
            "Epoch 79/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1337 - accuracy: 0.9525 - val_loss: 0.5913 - val_accuracy: 0.8633\n",
            "Epoch 80/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1433 - accuracy: 0.9463 - val_loss: 0.3468 - val_accuracy: 0.9035\n",
            "Epoch 81/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1354 - accuracy: 0.9487 - val_loss: 0.3866 - val_accuracy: 0.8997\n",
            "Epoch 82/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1503 - accuracy: 0.9455 - val_loss: 0.3408 - val_accuracy: 0.9033\n",
            "Epoch 83/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1257 - accuracy: 0.9559 - val_loss: 0.4476 - val_accuracy: 0.8834\n",
            "Epoch 84/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1189 - accuracy: 0.9556 - val_loss: 0.3422 - val_accuracy: 0.9131\n",
            "Epoch 85/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1224 - accuracy: 0.9552 - val_loss: 0.3752 - val_accuracy: 0.9006\n",
            "Epoch 86/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1196 - accuracy: 0.9550 - val_loss: 0.4286 - val_accuracy: 0.8999\n",
            "Epoch 87/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1259 - accuracy: 0.9555 - val_loss: 0.3910 - val_accuracy: 0.9058\n",
            "Epoch 88/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1229 - accuracy: 0.9594 - val_loss: 0.3764 - val_accuracy: 0.9079\n",
            "Epoch 89/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1171 - accuracy: 0.9566 - val_loss: 0.4211 - val_accuracy: 0.8965\n",
            "Epoch 90/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1185 - accuracy: 0.9595 - val_loss: 0.3567 - val_accuracy: 0.9058\n",
            "Epoch 91/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1268 - accuracy: 0.9545 - val_loss: 0.3958 - val_accuracy: 0.8994\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 92/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1105 - accuracy: 0.9618 - val_loss: 0.3735 - val_accuracy: 0.8983\n",
            "Epoch 93/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.1005 - accuracy: 0.9641 - val_loss: 0.3828 - val_accuracy: 0.8994\n",
            "Epoch 94/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0991 - accuracy: 0.9643 - val_loss: 0.3687 - val_accuracy: 0.9070\n",
            "Epoch 95/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0951 - accuracy: 0.9667 - val_loss: 0.4002 - val_accuracy: 0.8994\n",
            "Epoch 96/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0952 - accuracy: 0.9676 - val_loss: 0.4049 - val_accuracy: 0.8997\n",
            "Epoch 97/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0967 - accuracy: 0.9634 - val_loss: 0.4062 - val_accuracy: 0.9019\n",
            "Epoch 98/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0886 - accuracy: 0.9676 - val_loss: 0.4983 - val_accuracy: 0.8882\n",
            "Epoch 99/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0929 - accuracy: 0.9641 - val_loss: 0.4512 - val_accuracy: 0.8905\n",
            "Epoch 100/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0874 - accuracy: 0.9695 - val_loss: 0.4625 - val_accuracy: 0.8917\n",
            "Epoch 101/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0898 - accuracy: 0.9713 - val_loss: 0.4084 - val_accuracy: 0.9061\n",
            "Epoch 102/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0924 - accuracy: 0.9672 - val_loss: 0.4255 - val_accuracy: 0.9019\n",
            "Epoch 103/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0801 - accuracy: 0.9707 - val_loss: 0.4190 - val_accuracy: 0.9017\n",
            "Epoch 104/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0915 - accuracy: 0.9657 - val_loss: 0.4548 - val_accuracy: 0.8997\n",
            "Epoch 105/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0786 - accuracy: 0.9727 - val_loss: 0.4637 - val_accuracy: 0.8905\n",
            "Epoch 106/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0848 - accuracy: 0.9708 - val_loss: 0.4240 - val_accuracy: 0.9061\n",
            "Epoch 107/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0750 - accuracy: 0.9728 - val_loss: 0.4332 - val_accuracy: 0.9038\n",
            "Epoch 108/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0858 - accuracy: 0.9703 - val_loss: 0.4206 - val_accuracy: 0.9033\n",
            "Epoch 109/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0856 - accuracy: 0.9692 - val_loss: 0.4549 - val_accuracy: 0.8962\n",
            "Epoch 110/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0920 - accuracy: 0.9681 - val_loss: 0.4160 - val_accuracy: 0.9019\n",
            "Epoch 111/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0832 - accuracy: 0.9714 - val_loss: 0.4671 - val_accuracy: 0.8939\n",
            "\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 112/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0694 - accuracy: 0.9739 - val_loss: 0.4169 - val_accuracy: 0.9067\n",
            "Epoch 113/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0816 - accuracy: 0.9725 - val_loss: 0.4567 - val_accuracy: 0.8976\n",
            "Epoch 114/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0768 - accuracy: 0.9734 - val_loss: 0.4513 - val_accuracy: 0.8978\n",
            "Epoch 115/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 0.4675 - val_accuracy: 0.8942\n",
            "Epoch 116/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0785 - accuracy: 0.9727 - val_loss: 0.4514 - val_accuracy: 0.8990\n",
            "Epoch 117/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0797 - accuracy: 0.9717 - val_loss: 0.4456 - val_accuracy: 0.8999\n",
            "Epoch 118/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0800 - accuracy: 0.9725 - val_loss: 0.4513 - val_accuracy: 0.8987\n",
            "Epoch 119/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0726 - accuracy: 0.9751 - val_loss: 0.4616 - val_accuracy: 0.8971\n",
            "Epoch 120/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0717 - accuracy: 0.9757 - val_loss: 0.4847 - val_accuracy: 0.8939\n",
            "Epoch 121/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0758 - accuracy: 0.9730 - val_loss: 0.4643 - val_accuracy: 0.8987\n",
            "Epoch 122/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0737 - accuracy: 0.9730 - val_loss: 0.4696 - val_accuracy: 0.8971\n",
            "Epoch 123/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0758 - accuracy: 0.9753 - val_loss: 0.4779 - val_accuracy: 0.8960\n",
            "Epoch 124/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0742 - accuracy: 0.9745 - val_loss: 0.4748 - val_accuracy: 0.8965\n",
            "Epoch 125/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0753 - accuracy: 0.9746 - val_loss: 0.4739 - val_accuracy: 0.8969\n",
            "Epoch 126/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0746 - accuracy: 0.9718 - val_loss: 0.4522 - val_accuracy: 0.9013\n",
            "Epoch 127/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0696 - accuracy: 0.9747 - val_loss: 0.4927 - val_accuracy: 0.8951\n",
            "Epoch 128/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0804 - accuracy: 0.9724 - val_loss: 0.4929 - val_accuracy: 0.8944\n",
            "Epoch 129/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0730 - accuracy: 0.9741 - val_loss: 0.4646 - val_accuracy: 0.9013\n",
            "Epoch 130/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0718 - accuracy: 0.9739 - val_loss: 0.4826 - val_accuracy: 0.8960\n",
            "Epoch 131/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0754 - accuracy: 0.9740 - val_loss: 0.5017 - val_accuracy: 0.8912\n",
            "\n",
            "Epoch 00131: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 132/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0796 - accuracy: 0.9726 - val_loss: 0.4807 - val_accuracy: 0.8967\n",
            "Epoch 133/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0776 - accuracy: 0.9730 - val_loss: 0.4638 - val_accuracy: 0.9003\n",
            "Epoch 134/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0776 - accuracy: 0.9711 - val_loss: 0.4825 - val_accuracy: 0.8965\n",
            "Epoch 135/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0846 - accuracy: 0.9713 - val_loss: 0.4573 - val_accuracy: 0.9015\n",
            "Epoch 136/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0703 - accuracy: 0.9754 - val_loss: 0.4744 - val_accuracy: 0.8976\n",
            "Epoch 137/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0730 - accuracy: 0.9765 - val_loss: 0.4750 - val_accuracy: 0.8971\n",
            "Epoch 138/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0679 - accuracy: 0.9748 - val_loss: 0.4723 - val_accuracy: 0.8976\n",
            "Epoch 139/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0790 - accuracy: 0.9765 - val_loss: 0.4724 - val_accuracy: 0.8985\n",
            "Epoch 140/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0715 - accuracy: 0.9731 - val_loss: 0.4688 - val_accuracy: 0.8985\n",
            "Epoch 141/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0717 - accuracy: 0.9757 - val_loss: 0.4754 - val_accuracy: 0.8974\n",
            "Epoch 142/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0659 - accuracy: 0.9765 - val_loss: 0.4712 - val_accuracy: 0.8983\n",
            "Epoch 143/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0760 - accuracy: 0.9735 - val_loss: 0.4754 - val_accuracy: 0.8981\n",
            "Epoch 144/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0724 - accuracy: 0.9739 - val_loss: 0.4705 - val_accuracy: 0.8985\n",
            "Epoch 145/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0792 - accuracy: 0.9718 - val_loss: 0.4798 - val_accuracy: 0.8971\n",
            "Epoch 146/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0732 - accuracy: 0.9749 - val_loss: 0.4812 - val_accuracy: 0.8958\n",
            "Epoch 147/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0725 - accuracy: 0.9750 - val_loss: 0.4540 - val_accuracy: 0.9017\n",
            "Epoch 148/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0720 - accuracy: 0.9747 - val_loss: 0.4757 - val_accuracy: 0.8976\n",
            "Epoch 149/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0729 - accuracy: 0.9740 - val_loss: 0.4683 - val_accuracy: 0.8974\n",
            "Epoch 150/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0779 - accuracy: 0.9734 - val_loss: 0.4799 - val_accuracy: 0.8971\n",
            "Epoch 151/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0704 - accuracy: 0.9735 - val_loss: 0.4671 - val_accuracy: 0.8994\n",
            "\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 152/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0722 - accuracy: 0.9723 - val_loss: 0.4680 - val_accuracy: 0.8990\n",
            "Epoch 153/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0800 - accuracy: 0.9697 - val_loss: 0.4657 - val_accuracy: 0.9001\n",
            "Epoch 154/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0716 - accuracy: 0.9752 - val_loss: 0.4669 - val_accuracy: 0.8992\n",
            "Epoch 155/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0732 - accuracy: 0.9753 - val_loss: 0.4708 - val_accuracy: 0.8987\n",
            "Epoch 156/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 0.4707 - val_accuracy: 0.8987\n",
            "Epoch 157/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0698 - accuracy: 0.9757 - val_loss: 0.4721 - val_accuracy: 0.8983\n",
            "Epoch 158/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0764 - accuracy: 0.9730 - val_loss: 0.4737 - val_accuracy: 0.8981\n",
            "Epoch 159/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0726 - accuracy: 0.9746 - val_loss: 0.4772 - val_accuracy: 0.8976\n",
            "Epoch 160/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0725 - accuracy: 0.9746 - val_loss: 0.4777 - val_accuracy: 0.8971\n",
            "Epoch 161/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0716 - accuracy: 0.9724 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 162/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0721 - accuracy: 0.9741 - val_loss: 0.4721 - val_accuracy: 0.8983\n",
            "Epoch 163/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0692 - accuracy: 0.9764 - val_loss: 0.4711 - val_accuracy: 0.8987\n",
            "Epoch 164/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0707 - accuracy: 0.9742 - val_loss: 0.4731 - val_accuracy: 0.8985\n",
            "Epoch 165/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0727 - accuracy: 0.9723 - val_loss: 0.4738 - val_accuracy: 0.8985\n",
            "Epoch 166/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0702 - accuracy: 0.9768 - val_loss: 0.4729 - val_accuracy: 0.8985\n",
            "Epoch 167/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0718 - accuracy: 0.9735 - val_loss: 0.4749 - val_accuracy: 0.8981\n",
            "Epoch 168/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0687 - accuracy: 0.9753 - val_loss: 0.4797 - val_accuracy: 0.8974\n",
            "Epoch 169/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0764 - accuracy: 0.9743 - val_loss: 0.4805 - val_accuracy: 0.8971\n",
            "Epoch 170/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0751 - accuracy: 0.9733 - val_loss: 0.4737 - val_accuracy: 0.8983\n",
            "Epoch 171/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0705 - accuracy: 0.9743 - val_loss: 0.4750 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 00171: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "Epoch 172/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0692 - accuracy: 0.9759 - val_loss: 0.4748 - val_accuracy: 0.8985\n",
            "Epoch 173/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0770 - accuracy: 0.9745 - val_loss: 0.4747 - val_accuracy: 0.8985\n",
            "Epoch 174/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0797 - accuracy: 0.9731 - val_loss: 0.4744 - val_accuracy: 0.8985\n",
            "Epoch 175/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0713 - accuracy: 0.9772 - val_loss: 0.4740 - val_accuracy: 0.8987\n",
            "Epoch 176/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0705 - accuracy: 0.9742 - val_loss: 0.4736 - val_accuracy: 0.8987\n",
            "Epoch 177/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0738 - accuracy: 0.9752 - val_loss: 0.4740 - val_accuracy: 0.8985\n",
            "Epoch 178/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0722 - accuracy: 0.9744 - val_loss: 0.4740 - val_accuracy: 0.8985\n",
            "Epoch 179/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0698 - accuracy: 0.9767 - val_loss: 0.4737 - val_accuracy: 0.8985\n",
            "Epoch 180/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0706 - accuracy: 0.9768 - val_loss: 0.4735 - val_accuracy: 0.8985\n",
            "Epoch 181/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0626 - accuracy: 0.9771 - val_loss: 0.4728 - val_accuracy: 0.8990\n",
            "Epoch 182/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0776 - accuracy: 0.9721 - val_loss: 0.4732 - val_accuracy: 0.8987\n",
            "Epoch 183/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0675 - accuracy: 0.9751 - val_loss: 0.4728 - val_accuracy: 0.8987\n",
            "Epoch 184/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0710 - accuracy: 0.9756 - val_loss: 0.4729 - val_accuracy: 0.8985\n",
            "Epoch 185/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0762 - accuracy: 0.9731 - val_loss: 0.4728 - val_accuracy: 0.8987\n",
            "Epoch 186/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0687 - accuracy: 0.9752 - val_loss: 0.4736 - val_accuracy: 0.8981\n",
            "Epoch 187/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0753 - accuracy: 0.9741 - val_loss: 0.4743 - val_accuracy: 0.8981\n",
            "Epoch 188/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0765 - accuracy: 0.9738 - val_loss: 0.4742 - val_accuracy: 0.8981\n",
            "Epoch 189/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0702 - accuracy: 0.9751 - val_loss: 0.4735 - val_accuracy: 0.8981\n",
            "Epoch 190/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0722 - accuracy: 0.9743 - val_loss: 0.4733 - val_accuracy: 0.8981\n",
            "Epoch 191/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0796 - accuracy: 0.9728 - val_loss: 0.4736 - val_accuracy: 0.8981\n",
            "\n",
            "Epoch 00191: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "Epoch 192/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0712 - accuracy: 0.9736 - val_loss: 0.4735 - val_accuracy: 0.8983\n",
            "Epoch 193/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0747 - accuracy: 0.9729 - val_loss: 0.4737 - val_accuracy: 0.8981\n",
            "Epoch 194/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0788 - accuracy: 0.9761 - val_loss: 0.4737 - val_accuracy: 0.8981\n",
            "Epoch 195/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0736 - accuracy: 0.9745 - val_loss: 0.4737 - val_accuracy: 0.8981\n",
            "Epoch 196/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0703 - accuracy: 0.9745 - val_loss: 0.4737 - val_accuracy: 0.8981\n",
            "Epoch 197/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0718 - accuracy: 0.9757 - val_loss: 0.4739 - val_accuracy: 0.8981\n",
            "Epoch 198/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0770 - accuracy: 0.9724 - val_loss: 0.4738 - val_accuracy: 0.8981\n",
            "Epoch 199/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0700 - accuracy: 0.9743 - val_loss: 0.4736 - val_accuracy: 0.8981\n",
            "Epoch 200/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0704 - accuracy: 0.9747 - val_loss: 0.4736 - val_accuracy: 0.8981\n",
            "Epoch 201/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0696 - accuracy: 0.9755 - val_loss: 0.4736 - val_accuracy: 0.8983\n",
            "Epoch 202/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0749 - accuracy: 0.9736 - val_loss: 0.4734 - val_accuracy: 0.8983\n",
            "Epoch 203/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0712 - accuracy: 0.9756 - val_loss: 0.4735 - val_accuracy: 0.8981\n",
            "Epoch 204/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0783 - accuracy: 0.9730 - val_loss: 0.4735 - val_accuracy: 0.8983\n",
            "Epoch 205/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0764 - accuracy: 0.9746 - val_loss: 0.4733 - val_accuracy: 0.8983\n",
            "Epoch 206/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0713 - accuracy: 0.9749 - val_loss: 0.4733 - val_accuracy: 0.8983\n",
            "Epoch 207/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0663 - accuracy: 0.9758 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 208/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0673 - accuracy: 0.9765 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 209/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0693 - accuracy: 0.9770 - val_loss: 0.4730 - val_accuracy: 0.8983\n",
            "Epoch 210/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0727 - accuracy: 0.9754 - val_loss: 0.4730 - val_accuracy: 0.8983\n",
            "Epoch 211/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0725 - accuracy: 0.9740 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00211: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "Epoch 212/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0723 - accuracy: 0.9738 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 213/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0722 - accuracy: 0.9744 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 214/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0678 - accuracy: 0.9773 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 215/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0835 - accuracy: 0.9715 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 216/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0756 - accuracy: 0.9751 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 217/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0739 - accuracy: 0.9724 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 218/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0758 - accuracy: 0.9741 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 219/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0746 - accuracy: 0.9751 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 220/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0691 - accuracy: 0.9760 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 221/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0795 - accuracy: 0.9720 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 222/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0736 - accuracy: 0.9732 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 223/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0688 - accuracy: 0.9753 - val_loss: 0.4730 - val_accuracy: 0.8983\n",
            "Epoch 224/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0775 - accuracy: 0.9731 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 225/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0737 - accuracy: 0.9751 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 226/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0729 - accuracy: 0.9766 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 227/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0741 - accuracy: 0.9726 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 228/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0792 - accuracy: 0.9730 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 229/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0726 - accuracy: 0.9749 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 230/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0725 - accuracy: 0.9767 - val_loss: 0.4731 - val_accuracy: 0.8983\n",
            "Epoch 231/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0728 - accuracy: 0.9741 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "\n",
            "Epoch 00231: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "Epoch 232/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0727 - accuracy: 0.9747 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 233/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0703 - accuracy: 0.9751 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 234/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0728 - accuracy: 0.9766 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 235/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0726 - accuracy: 0.9731 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 236/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0674 - accuracy: 0.9768 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 237/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0698 - accuracy: 0.9752 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 238/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0762 - accuracy: 0.9727 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 239/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0711 - accuracy: 0.9760 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 240/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0715 - accuracy: 0.9757 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 241/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0751 - accuracy: 0.9741 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 242/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0717 - accuracy: 0.9758 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 243/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0720 - accuracy: 0.9737 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 244/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0716 - accuracy: 0.9762 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 245/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0719 - accuracy: 0.9742 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 246/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0701 - accuracy: 0.9737 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 247/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0740 - accuracy: 0.9735 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 248/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0727 - accuracy: 0.9747 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 249/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0760 - accuracy: 0.9724 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Epoch 250/250\n",
            "53/53 [==============================] - 1s 26ms/step - loss: 0.0765 - accuracy: 0.9734 - val_loss: 0.4732 - val_accuracy: 0.8983\n",
            "Time: 390.4167366027832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0StnjUKSv4R",
        "outputId": "834d40f9-f3fe-4582-860c-a867cb937468"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 1K simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "x=np.concatenate((u1[0:1000,:,:],u2[0:1000,:,:],u3[0:1000,:,:],u4[0:1000,:,:],u5[0:1000,:,:],u6[0:1000,:,:],u7[0:1000,:,:]),axis=0)\n",
        "\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "\n",
        "y=[0 for i in range(len(u1[0:1000,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:1000,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:1000,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:1000,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:1000,:,:]))])\n",
        "y.extend([5 for i in range(len(u6[0:1000,:,:]))])\n",
        "y.extend([6 for i in range(len(u7[0:1000,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n",
        "print (f'Time: {time.time() - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7000 7000\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 195, 64)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 194, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 193, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_4 (Average (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 95, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_5 (Average (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 5875)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 125)               734500    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 7)                 882       \n",
            "=================================================================\n",
            "Total params: 877,382\n",
            "Trainable params: 877,382\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            "21/21 [==============================] - 2s 45ms/step - loss: 1.9873 - accuracy: 0.1517 - val_loss: 1.9411 - val_accuracy: 0.2543\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 2/250\n",
            "21/21 [==============================] - 1s 34ms/step - loss: 1.9094 - accuracy: 0.1969 - val_loss: 1.5183 - val_accuracy: 0.2794\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 3/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 1.6088 - accuracy: 0.2967 - val_loss: 1.3151 - val_accuracy: 0.3674\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 4/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 1.4146 - accuracy: 0.3465 - val_loss: 1.1489 - val_accuracy: 0.4166\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 5/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 1.2401 - accuracy: 0.4397 - val_loss: 1.1007 - val_accuracy: 0.5063\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 6/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 1.1720 - accuracy: 0.4613 - val_loss: 0.9086 - val_accuracy: 0.5371\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 7/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 1.0139 - accuracy: 0.5248 - val_loss: 0.7931 - val_accuracy: 0.5891\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 8/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.9084 - accuracy: 0.5549 - val_loss: 0.6727 - val_accuracy: 0.6469\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 9/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.8221 - accuracy: 0.5991 - val_loss: 0.6453 - val_accuracy: 0.6771\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 10/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.7808 - accuracy: 0.6076 - val_loss: 0.5785 - val_accuracy: 0.6771\n",
            "Epoch 11/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.7112 - accuracy: 0.6379 - val_loss: 0.5864 - val_accuracy: 0.6606\n",
            "Epoch 12/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.6498 - accuracy: 0.6601 - val_loss: 0.5578 - val_accuracy: 0.6903\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 13/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.6252 - accuracy: 0.6624 - val_loss: 0.5551 - val_accuracy: 0.6851\n",
            "Epoch 14/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.6309 - accuracy: 0.6608 - val_loss: 0.5380 - val_accuracy: 0.6920\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 15/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.5897 - accuracy: 0.6679 - val_loss: 0.5821 - val_accuracy: 0.6731\n",
            "Epoch 16/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.5623 - accuracy: 0.6900 - val_loss: 0.5379 - val_accuracy: 0.6954\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 17/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.5559 - accuracy: 0.6927 - val_loss: 0.5264 - val_accuracy: 0.7046\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 18/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.5234 - accuracy: 0.7025 - val_loss: 0.5319 - val_accuracy: 0.7046\n",
            "Epoch 19/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.5197 - accuracy: 0.6993 - val_loss: 0.5867 - val_accuracy: 0.6874\n",
            "Epoch 20/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.5370 - accuracy: 0.7099 - val_loss: 0.5307 - val_accuracy: 0.7057\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 21/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.5199 - accuracy: 0.6963 - val_loss: 0.6480 - val_accuracy: 0.6851\n",
            "Epoch 22/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.5277 - accuracy: 0.7102 - val_loss: 0.5323 - val_accuracy: 0.7126\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 23/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.5168 - accuracy: 0.7104 - val_loss: 0.5168 - val_accuracy: 0.7200\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 24/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4942 - accuracy: 0.7143 - val_loss: 0.5335 - val_accuracy: 0.7057\n",
            "Epoch 25/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.5145 - accuracy: 0.7143 - val_loss: 0.5475 - val_accuracy: 0.7091\n",
            "Epoch 26/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.4979 - accuracy: 0.7198 - val_loss: 0.5382 - val_accuracy: 0.7217\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 27/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4792 - accuracy: 0.7251 - val_loss: 0.5875 - val_accuracy: 0.6960\n",
            "Epoch 28/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4987 - accuracy: 0.7190 - val_loss: 0.5623 - val_accuracy: 0.7029\n",
            "Epoch 29/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4656 - accuracy: 0.7357 - val_loss: 0.5683 - val_accuracy: 0.6931\n",
            "Epoch 30/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.5141 - accuracy: 0.7094 - val_loss: 0.6368 - val_accuracy: 0.6811\n",
            "Epoch 31/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4976 - accuracy: 0.7266 - val_loss: 0.5079 - val_accuracy: 0.7149\n",
            "Epoch 32/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4808 - accuracy: 0.7340 - val_loss: 0.5078 - val_accuracy: 0.7189\n",
            "Epoch 33/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.4451 - accuracy: 0.7507 - val_loss: 0.5672 - val_accuracy: 0.7137\n",
            "Epoch 34/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4612 - accuracy: 0.7311 - val_loss: 0.6053 - val_accuracy: 0.6983\n",
            "Epoch 35/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4471 - accuracy: 0.7290 - val_loss: 0.5285 - val_accuracy: 0.7291\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 36/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4575 - accuracy: 0.7346 - val_loss: 0.5358 - val_accuracy: 0.7223\n",
            "Epoch 37/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4547 - accuracy: 0.7359 - val_loss: 0.5560 - val_accuracy: 0.7126\n",
            "Epoch 38/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4377 - accuracy: 0.7484 - val_loss: 0.5991 - val_accuracy: 0.7074\n",
            "Epoch 39/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4367 - accuracy: 0.7634 - val_loss: 0.5597 - val_accuracy: 0.7211\n",
            "Epoch 40/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4260 - accuracy: 0.7464 - val_loss: 0.5539 - val_accuracy: 0.7223\n",
            "Epoch 41/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4243 - accuracy: 0.7578 - val_loss: 0.5322 - val_accuracy: 0.7177\n",
            "Epoch 42/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4356 - accuracy: 0.7515 - val_loss: 0.5250 - val_accuracy: 0.7171\n",
            "Epoch 43/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4498 - accuracy: 0.7487 - val_loss: 0.5729 - val_accuracy: 0.7080\n",
            "Epoch 44/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4509 - accuracy: 0.7482 - val_loss: 0.5750 - val_accuracy: 0.7223\n",
            "Epoch 45/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4089 - accuracy: 0.7682 - val_loss: 0.5376 - val_accuracy: 0.7229\n",
            "Epoch 46/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.4289 - accuracy: 0.7572 - val_loss: 0.6096 - val_accuracy: 0.7103\n",
            "Epoch 47/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4399 - accuracy: 0.7514 - val_loss: 0.5276 - val_accuracy: 0.7326\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 48/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.4073 - accuracy: 0.7737 - val_loss: 0.5811 - val_accuracy: 0.7286\n",
            "Epoch 49/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4145 - accuracy: 0.7713 - val_loss: 0.6119 - val_accuracy: 0.7166\n",
            "Epoch 50/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4203 - accuracy: 0.7675 - val_loss: 0.5212 - val_accuracy: 0.7411\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 51/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4081 - accuracy: 0.7654 - val_loss: 0.5836 - val_accuracy: 0.7211\n",
            "Epoch 52/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3958 - accuracy: 0.7853 - val_loss: 0.5512 - val_accuracy: 0.7309\n",
            "Epoch 53/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.4016 - accuracy: 0.7802 - val_loss: 0.5792 - val_accuracy: 0.7097\n",
            "Epoch 54/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4317 - accuracy: 0.7613 - val_loss: 0.5434 - val_accuracy: 0.7394\n",
            "Epoch 55/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4026 - accuracy: 0.7830 - val_loss: 0.5564 - val_accuracy: 0.7211\n",
            "Epoch 56/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4020 - accuracy: 0.7717 - val_loss: 0.5816 - val_accuracy: 0.7297\n",
            "Epoch 57/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3982 - accuracy: 0.7738 - val_loss: 0.5717 - val_accuracy: 0.7417\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 58/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3889 - accuracy: 0.7930 - val_loss: 0.6274 - val_accuracy: 0.7200\n",
            "Epoch 59/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.4026 - accuracy: 0.7857 - val_loss: 0.5479 - val_accuracy: 0.7463\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 60/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3737 - accuracy: 0.7841 - val_loss: 0.6466 - val_accuracy: 0.7286\n",
            "Epoch 61/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3694 - accuracy: 0.7933 - val_loss: 0.6587 - val_accuracy: 0.7463\n",
            "Epoch 62/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3624 - accuracy: 0.8076 - val_loss: 0.5863 - val_accuracy: 0.7543\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 63/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.3487 - accuracy: 0.8172 - val_loss: 0.6438 - val_accuracy: 0.7297\n",
            "Epoch 64/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3557 - accuracy: 0.8074 - val_loss: 0.6286 - val_accuracy: 0.7434\n",
            "Epoch 65/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.3301 - accuracy: 0.8240 - val_loss: 0.6384 - val_accuracy: 0.7423\n",
            "Epoch 66/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3308 - accuracy: 0.8174 - val_loss: 0.5756 - val_accuracy: 0.7440\n",
            "Epoch 67/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.3425 - accuracy: 0.8224 - val_loss: 0.5360 - val_accuracy: 0.7526\n",
            "Epoch 68/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.3669 - accuracy: 0.8158 - val_loss: 0.5702 - val_accuracy: 0.7577\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 69/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.3588 - accuracy: 0.8211 - val_loss: 0.5730 - val_accuracy: 0.7720\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 70/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.3439 - accuracy: 0.8258 - val_loss: 0.6294 - val_accuracy: 0.7629\n",
            "Epoch 71/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.3184 - accuracy: 0.8310 - val_loss: 0.6723 - val_accuracy: 0.7669\n",
            "Epoch 72/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3207 - accuracy: 0.8271 - val_loss: 0.6136 - val_accuracy: 0.7657\n",
            "Epoch 73/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3458 - accuracy: 0.8224 - val_loss: 0.6506 - val_accuracy: 0.7611\n",
            "Epoch 74/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.3084 - accuracy: 0.8472 - val_loss: 0.6884 - val_accuracy: 0.7703\n",
            "Epoch 75/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.3041 - accuracy: 0.8414 - val_loss: 0.5841 - val_accuracy: 0.7914\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 76/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2948 - accuracy: 0.8465 - val_loss: 0.6161 - val_accuracy: 0.7669\n",
            "Epoch 77/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2904 - accuracy: 0.8529 - val_loss: 0.7817 - val_accuracy: 0.7446\n",
            "Epoch 78/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2925 - accuracy: 0.8480 - val_loss: 0.5822 - val_accuracy: 0.7783\n",
            "Epoch 79/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.3213 - accuracy: 0.8441 - val_loss: 0.5845 - val_accuracy: 0.8097\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 80/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.2947 - accuracy: 0.8596 - val_loss: 0.5612 - val_accuracy: 0.8086\n",
            "Epoch 81/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2770 - accuracy: 0.8729 - val_loss: 0.5551 - val_accuracy: 0.8051\n",
            "Epoch 82/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2709 - accuracy: 0.8751 - val_loss: 0.5442 - val_accuracy: 0.8291\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 83/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2526 - accuracy: 0.8930 - val_loss: 0.8021 - val_accuracy: 0.8091\n",
            "Epoch 84/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2470 - accuracy: 0.8889 - val_loss: 0.5852 - val_accuracy: 0.8234\n",
            "Epoch 85/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.2498 - accuracy: 0.8926 - val_loss: 0.6295 - val_accuracy: 0.8154\n",
            "Epoch 86/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2285 - accuracy: 0.9028 - val_loss: 0.4913 - val_accuracy: 0.8611\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 87/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.2329 - accuracy: 0.9004 - val_loss: 0.5959 - val_accuracy: 0.8423\n",
            "Epoch 88/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.2012 - accuracy: 0.9209 - val_loss: 0.6186 - val_accuracy: 0.8331\n",
            "Epoch 89/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.2076 - accuracy: 0.9167 - val_loss: 0.5903 - val_accuracy: 0.8497\n",
            "Epoch 90/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1984 - accuracy: 0.9184 - val_loss: 0.7426 - val_accuracy: 0.8297\n",
            "Epoch 91/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.2185 - accuracy: 0.9063 - val_loss: 0.4629 - val_accuracy: 0.8726\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 92/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2076 - accuracy: 0.9182 - val_loss: 0.4826 - val_accuracy: 0.8617\n",
            "Epoch 93/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1884 - accuracy: 0.9253 - val_loss: 0.5378 - val_accuracy: 0.8623\n",
            "Epoch 94/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1793 - accuracy: 0.9312 - val_loss: 0.4938 - val_accuracy: 0.8720\n",
            "Epoch 95/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.1644 - accuracy: 0.9348 - val_loss: 0.5387 - val_accuracy: 0.8669\n",
            "Epoch 96/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.1553 - accuracy: 0.9366 - val_loss: 0.5120 - val_accuracy: 0.8714\n",
            "Epoch 97/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1790 - accuracy: 0.9307 - val_loss: 0.6030 - val_accuracy: 0.8520\n",
            "Epoch 98/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.1668 - accuracy: 0.9349 - val_loss: 0.7447 - val_accuracy: 0.8389\n",
            "Epoch 99/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.1500 - accuracy: 0.9408 - val_loss: 0.5448 - val_accuracy: 0.8731\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 100/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.1465 - accuracy: 0.9411 - val_loss: 0.5578 - val_accuracy: 0.8663\n",
            "Epoch 101/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1495 - accuracy: 0.9393 - val_loss: 0.5645 - val_accuracy: 0.8651\n",
            "Epoch 102/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1546 - accuracy: 0.9378 - val_loss: 0.5467 - val_accuracy: 0.8680\n",
            "Epoch 103/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1663 - accuracy: 0.9385 - val_loss: 1.0471 - val_accuracy: 0.8074\n",
            "Epoch 104/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1840 - accuracy: 0.9332 - val_loss: 0.4948 - val_accuracy: 0.8817\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 105/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1316 - accuracy: 0.9537 - val_loss: 0.6650 - val_accuracy: 0.8480\n",
            "Epoch 106/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1575 - accuracy: 0.9399 - val_loss: 0.5066 - val_accuracy: 0.8789\n",
            "Epoch 107/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1443 - accuracy: 0.9473 - val_loss: 0.7779 - val_accuracy: 0.8406\n",
            "Epoch 108/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1478 - accuracy: 0.9473 - val_loss: 0.5423 - val_accuracy: 0.8714\n",
            "Epoch 109/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.1333 - accuracy: 0.9517 - val_loss: 0.6296 - val_accuracy: 0.8583\n",
            "Epoch 110/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1231 - accuracy: 0.9519 - val_loss: 0.6887 - val_accuracy: 0.8583\n",
            "Epoch 111/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.1385 - accuracy: 0.9488 - val_loss: 0.5900 - val_accuracy: 0.8617\n",
            "Epoch 112/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.2016 - accuracy: 0.9297 - val_loss: 0.5754 - val_accuracy: 0.8469\n",
            "Epoch 113/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1871 - accuracy: 0.9308 - val_loss: 0.4821 - val_accuracy: 0.8794\n",
            "Epoch 114/250\n",
            "21/21 [==============================] - 1s 33ms/step - loss: 0.1403 - accuracy: 0.9490 - val_loss: 0.5442 - val_accuracy: 0.8680\n",
            "Epoch 115/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1221 - accuracy: 0.9541 - val_loss: 0.5421 - val_accuracy: 0.8823\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 116/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1205 - accuracy: 0.9576 - val_loss: 0.5566 - val_accuracy: 0.8703\n",
            "Epoch 117/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1123 - accuracy: 0.9571 - val_loss: 0.6614 - val_accuracy: 0.8617\n",
            "Epoch 118/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1148 - accuracy: 0.9551 - val_loss: 0.6538 - val_accuracy: 0.8680\n",
            "Epoch 119/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1108 - accuracy: 0.9564 - val_loss: 0.7305 - val_accuracy: 0.8594\n",
            "Epoch 120/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1111 - accuracy: 0.9588 - val_loss: 0.6282 - val_accuracy: 0.8760\n",
            "Epoch 121/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.1076 - accuracy: 0.9629 - val_loss: 0.8350 - val_accuracy: 0.8360\n",
            "Epoch 122/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.1143 - accuracy: 0.9630 - val_loss: 0.6631 - val_accuracy: 0.8606\n",
            "Epoch 123/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.1079 - accuracy: 0.9596 - val_loss: 0.6327 - val_accuracy: 0.8657\n",
            "Epoch 124/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1050 - accuracy: 0.9598 - val_loss: 0.5926 - val_accuracy: 0.8829\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 125/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1160 - accuracy: 0.9529 - val_loss: 0.6648 - val_accuracy: 0.8714\n",
            "Epoch 126/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0921 - accuracy: 0.9618 - val_loss: 0.6751 - val_accuracy: 0.8714\n",
            "Epoch 127/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1299 - accuracy: 0.9547 - val_loss: 0.5778 - val_accuracy: 0.8806\n",
            "Epoch 128/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.1070 - accuracy: 0.9611 - val_loss: 0.6659 - val_accuracy: 0.8697\n",
            "Epoch 129/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0977 - accuracy: 0.9639 - val_loss: 0.5970 - val_accuracy: 0.8834\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 130/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.1089 - accuracy: 0.9589 - val_loss: 0.7552 - val_accuracy: 0.8646\n",
            "Epoch 131/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.1093 - accuracy: 0.9569 - val_loss: 0.6123 - val_accuracy: 0.8783\n",
            "Epoch 132/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0980 - accuracy: 0.9610 - val_loss: 0.6617 - val_accuracy: 0.8794\n",
            "Epoch 133/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0910 - accuracy: 0.9658 - val_loss: 0.7797 - val_accuracy: 0.8577\n",
            "Epoch 134/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0850 - accuracy: 0.9693 - val_loss: 0.7267 - val_accuracy: 0.8697\n",
            "Epoch 135/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0858 - accuracy: 0.9665 - val_loss: 0.8330 - val_accuracy: 0.8566\n",
            "Epoch 136/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1063 - accuracy: 0.9581 - val_loss: 0.7654 - val_accuracy: 0.8623\n",
            "Epoch 137/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.0955 - accuracy: 0.9657 - val_loss: 0.7321 - val_accuracy: 0.8743\n",
            "Epoch 138/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1140 - accuracy: 0.9580 - val_loss: 0.6711 - val_accuracy: 0.8657\n",
            "Epoch 139/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.1141 - accuracy: 0.9569 - val_loss: 0.6398 - val_accuracy: 0.8731\n",
            "Epoch 140/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.1047 - accuracy: 0.9598 - val_loss: 0.5947 - val_accuracy: 0.8840\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 141/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0768 - accuracy: 0.9734 - val_loss: 0.7404 - val_accuracy: 0.8560\n",
            "Epoch 142/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0976 - accuracy: 0.9668 - val_loss: 0.6709 - val_accuracy: 0.8834\n",
            "Epoch 143/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0848 - accuracy: 0.9684 - val_loss: 0.6418 - val_accuracy: 0.8709\n",
            "Epoch 144/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0974 - accuracy: 0.9644 - val_loss: 0.5580 - val_accuracy: 0.8857\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "Epoch 145/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0940 - accuracy: 0.9684 - val_loss: 0.6240 - val_accuracy: 0.8806\n",
            "Epoch 146/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0835 - accuracy: 0.9682 - val_loss: 0.6431 - val_accuracy: 0.8777\n",
            "Epoch 147/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0788 - accuracy: 0.9720 - val_loss: 0.8273 - val_accuracy: 0.8606\n",
            "Epoch 148/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0650 - accuracy: 0.9789 - val_loss: 0.7723 - val_accuracy: 0.8686\n",
            "Epoch 149/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0829 - accuracy: 0.9694 - val_loss: 0.7122 - val_accuracy: 0.8703\n",
            "Epoch 150/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0758 - accuracy: 0.9691 - val_loss: 0.7463 - val_accuracy: 0.8686\n",
            "Epoch 151/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0935 - accuracy: 0.9697 - val_loss: 1.0008 - val_accuracy: 0.8400\n",
            "Epoch 152/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0919 - accuracy: 0.9657 - val_loss: 0.6525 - val_accuracy: 0.8794\n",
            "Epoch 153/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0727 - accuracy: 0.9770 - val_loss: 0.8192 - val_accuracy: 0.8577\n",
            "Epoch 154/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0781 - accuracy: 0.9716 - val_loss: 0.8059 - val_accuracy: 0.8480\n",
            "Epoch 155/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.0536 - accuracy: 0.9806 - val_loss: 0.8130 - val_accuracy: 0.8577\n",
            "Epoch 156/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.0734 - accuracy: 0.9727 - val_loss: 0.9086 - val_accuracy: 0.8543\n",
            "Epoch 157/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0651 - accuracy: 0.9760 - val_loss: 0.7328 - val_accuracy: 0.8823\n",
            "Epoch 158/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0799 - accuracy: 0.9683 - val_loss: 0.7256 - val_accuracy: 0.8686\n",
            "Epoch 159/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.0808 - accuracy: 0.9726 - val_loss: 0.8266 - val_accuracy: 0.8651\n",
            "Epoch 160/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0693 - accuracy: 0.9752 - val_loss: 0.7346 - val_accuracy: 0.8697\n",
            "Epoch 161/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0690 - accuracy: 0.9758 - val_loss: 0.8278 - val_accuracy: 0.8589\n",
            "Epoch 162/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0737 - accuracy: 0.9729 - val_loss: 0.6884 - val_accuracy: 0.8754\n",
            "Epoch 163/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0625 - accuracy: 0.9791 - val_loss: 0.9199 - val_accuracy: 0.8731\n",
            "Epoch 164/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0823 - accuracy: 0.9728 - val_loss: 0.8151 - val_accuracy: 0.8589\n",
            "\n",
            "Epoch 00164: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 165/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0760 - accuracy: 0.9736 - val_loss: 0.7388 - val_accuracy: 0.8726\n",
            "Epoch 166/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0617 - accuracy: 0.9815 - val_loss: 0.8187 - val_accuracy: 0.8566\n",
            "Epoch 167/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0635 - accuracy: 0.9761 - val_loss: 0.7671 - val_accuracy: 0.8726\n",
            "Epoch 168/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 0.8220 - val_accuracy: 0.8640\n",
            "Epoch 169/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0532 - accuracy: 0.9795 - val_loss: 0.7789 - val_accuracy: 0.8680\n",
            "Epoch 170/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0569 - accuracy: 0.9814 - val_loss: 0.7866 - val_accuracy: 0.8686\n",
            "Epoch 171/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0420 - accuracy: 0.9854 - val_loss: 0.8303 - val_accuracy: 0.8623\n",
            "Epoch 172/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 0.7834 - val_accuracy: 0.8709\n",
            "Epoch 173/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0528 - accuracy: 0.9808 - val_loss: 0.8124 - val_accuracy: 0.8674\n",
            "Epoch 174/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0437 - accuracy: 0.9863 - val_loss: 0.8419 - val_accuracy: 0.8651\n",
            "Epoch 175/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0415 - accuracy: 0.9858 - val_loss: 0.8160 - val_accuracy: 0.8697\n",
            "Epoch 176/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0476 - accuracy: 0.9832 - val_loss: 0.8259 - val_accuracy: 0.8720\n",
            "Epoch 177/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.0472 - accuracy: 0.9830 - val_loss: 0.8227 - val_accuracy: 0.8709\n",
            "Epoch 178/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0421 - accuracy: 0.9835 - val_loss: 0.8592 - val_accuracy: 0.8663\n",
            "Epoch 179/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0550 - accuracy: 0.9829 - val_loss: 0.8315 - val_accuracy: 0.8731\n",
            "Epoch 180/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0437 - accuracy: 0.9868 - val_loss: 0.9244 - val_accuracy: 0.8589\n",
            "Epoch 181/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0373 - accuracy: 0.9847 - val_loss: 0.8828 - val_accuracy: 0.8623\n",
            "Epoch 182/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0394 - accuracy: 0.9860 - val_loss: 0.8749 - val_accuracy: 0.8657\n",
            "Epoch 183/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0405 - accuracy: 0.9854 - val_loss: 0.8427 - val_accuracy: 0.8709\n",
            "Epoch 184/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.8782 - val_accuracy: 0.8703\n",
            "\n",
            "Epoch 00184: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 185/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 0.9146 - val_accuracy: 0.8623\n",
            "Epoch 186/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0378 - accuracy: 0.9868 - val_loss: 0.9085 - val_accuracy: 0.8623\n",
            "Epoch 187/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0373 - accuracy: 0.9863 - val_loss: 0.8553 - val_accuracy: 0.8691\n",
            "Epoch 188/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0389 - accuracy: 0.9859 - val_loss: 0.8683 - val_accuracy: 0.8651\n",
            "Epoch 189/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0460 - accuracy: 0.9863 - val_loss: 0.9103 - val_accuracy: 0.8606\n",
            "Epoch 190/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0393 - accuracy: 0.9859 - val_loss: 0.9010 - val_accuracy: 0.8634\n",
            "Epoch 191/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 0.8759 - val_accuracy: 0.8674\n",
            "Epoch 192/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0385 - accuracy: 0.9879 - val_loss: 0.8579 - val_accuracy: 0.8703\n",
            "Epoch 193/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0407 - accuracy: 0.9855 - val_loss: 0.9063 - val_accuracy: 0.8640\n",
            "Epoch 194/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0341 - accuracy: 0.9871 - val_loss: 0.8675 - val_accuracy: 0.8691\n",
            "Epoch 195/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0422 - accuracy: 0.9847 - val_loss: 0.8762 - val_accuracy: 0.8680\n",
            "Epoch 196/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.8696 - val_accuracy: 0.8680\n",
            "Epoch 197/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0380 - accuracy: 0.9880 - val_loss: 0.8961 - val_accuracy: 0.8640\n",
            "Epoch 198/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0347 - accuracy: 0.9904 - val_loss: 0.8835 - val_accuracy: 0.8669\n",
            "Epoch 199/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.8923 - val_accuracy: 0.8663\n",
            "Epoch 200/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0375 - accuracy: 0.9862 - val_loss: 0.9033 - val_accuracy: 0.8674\n",
            "Epoch 201/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0372 - accuracy: 0.9851 - val_loss: 0.8953 - val_accuracy: 0.8663\n",
            "Epoch 202/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0401 - accuracy: 0.9857 - val_loss: 0.9031 - val_accuracy: 0.8663\n",
            "Epoch 203/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0357 - accuracy: 0.9900 - val_loss: 0.8978 - val_accuracy: 0.8663\n",
            "Epoch 204/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0354 - accuracy: 0.9869 - val_loss: 0.8966 - val_accuracy: 0.8657\n",
            "\n",
            "Epoch 00204: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 205/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 0.8937 - val_accuracy: 0.8663\n",
            "Epoch 206/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0399 - accuracy: 0.9858 - val_loss: 0.8876 - val_accuracy: 0.8674\n",
            "Epoch 207/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0361 - accuracy: 0.9891 - val_loss: 0.8933 - val_accuracy: 0.8663\n",
            "Epoch 208/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.8895 - val_accuracy: 0.8663\n",
            "Epoch 209/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 0.8868 - val_accuracy: 0.8669\n",
            "Epoch 210/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0408 - accuracy: 0.9869 - val_loss: 0.8778 - val_accuracy: 0.8680\n",
            "Epoch 211/250\n",
            "21/21 [==============================] - 1s 42ms/step - loss: 0.0427 - accuracy: 0.9849 - val_loss: 0.8799 - val_accuracy: 0.8680\n",
            "Epoch 212/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0464 - accuracy: 0.9828 - val_loss: 0.8931 - val_accuracy: 0.8663\n",
            "Epoch 213/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0393 - accuracy: 0.9855 - val_loss: 0.8922 - val_accuracy: 0.8669\n",
            "Epoch 214/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0338 - accuracy: 0.9873 - val_loss: 0.8866 - val_accuracy: 0.8674\n",
            "Epoch 215/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0379 - accuracy: 0.9880 - val_loss: 0.8939 - val_accuracy: 0.8669\n",
            "Epoch 216/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.9017 - val_accuracy: 0.8657\n",
            "Epoch 217/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.8951 - val_accuracy: 0.8674\n",
            "Epoch 218/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.8929 - val_accuracy: 0.8674\n",
            "Epoch 219/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.8937 - val_accuracy: 0.8674\n",
            "Epoch 220/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.8935 - val_accuracy: 0.8674\n",
            "Epoch 221/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.8813 - val_accuracy: 0.8674\n",
            "Epoch 222/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0332 - accuracy: 0.9888 - val_loss: 0.8948 - val_accuracy: 0.8669\n",
            "Epoch 223/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0347 - accuracy: 0.9904 - val_loss: 0.8983 - val_accuracy: 0.8663\n",
            "Epoch 224/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0376 - accuracy: 0.9883 - val_loss: 0.8821 - val_accuracy: 0.8669\n",
            "\n",
            "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 225/250\n",
            "21/21 [==============================] - 1s 30ms/step - loss: 0.0448 - accuracy: 0.9851 - val_loss: 0.8799 - val_accuracy: 0.8680\n",
            "Epoch 226/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.8803 - val_accuracy: 0.8680\n",
            "Epoch 227/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0345 - accuracy: 0.9859 - val_loss: 0.8812 - val_accuracy: 0.8680\n",
            "Epoch 228/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0393 - accuracy: 0.9869 - val_loss: 0.8833 - val_accuracy: 0.8680\n",
            "Epoch 229/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 0.8849 - val_accuracy: 0.8669\n",
            "Epoch 230/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.8827 - val_accuracy: 0.8674\n",
            "Epoch 231/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0320 - accuracy: 0.9886 - val_loss: 0.8832 - val_accuracy: 0.8674\n",
            "Epoch 232/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0380 - accuracy: 0.9856 - val_loss: 0.8834 - val_accuracy: 0.8674\n",
            "Epoch 233/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0454 - accuracy: 0.9857 - val_loss: 0.8829 - val_accuracy: 0.8674\n",
            "Epoch 234/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0389 - accuracy: 0.9894 - val_loss: 0.8817 - val_accuracy: 0.8680\n",
            "Epoch 235/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0386 - accuracy: 0.9853 - val_loss: 0.8809 - val_accuracy: 0.8680\n",
            "Epoch 236/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0421 - accuracy: 0.9863 - val_loss: 0.8811 - val_accuracy: 0.8680\n",
            "Epoch 237/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.8807 - val_accuracy: 0.8680\n",
            "Epoch 238/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0416 - accuracy: 0.9840 - val_loss: 0.8808 - val_accuracy: 0.8680\n",
            "Epoch 239/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0338 - accuracy: 0.9910 - val_loss: 0.8803 - val_accuracy: 0.8674\n",
            "Epoch 240/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0340 - accuracy: 0.9894 - val_loss: 0.8789 - val_accuracy: 0.8680\n",
            "Epoch 241/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0359 - accuracy: 0.9882 - val_loss: 0.8802 - val_accuracy: 0.8680\n",
            "Epoch 242/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0391 - accuracy: 0.9866 - val_loss: 0.8837 - val_accuracy: 0.8686\n",
            "Epoch 243/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 0.8849 - val_accuracy: 0.8686\n",
            "Epoch 244/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.8853 - val_accuracy: 0.8686\n",
            "\n",
            "Epoch 00244: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "Epoch 245/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.8857 - val_accuracy: 0.8686\n",
            "Epoch 246/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0406 - accuracy: 0.9862 - val_loss: 0.8855 - val_accuracy: 0.8686\n",
            "Epoch 247/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0357 - accuracy: 0.9865 - val_loss: 0.8856 - val_accuracy: 0.8686\n",
            "Epoch 248/250\n",
            "21/21 [==============================] - 1s 31ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.8854 - val_accuracy: 0.8686\n",
            "Epoch 249/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 0.8855 - val_accuracy: 0.8686\n",
            "Epoch 250/250\n",
            "21/21 [==============================] - 1s 32ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.8857 - val_accuracy: 0.8686\n",
            "Time: 219.1190276145935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLLmpfmQnnck",
        "outputId": "afa97b71-5f6c-4b18-a66a-312989c678a4"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 500 simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "x=np.concatenate((u1[0:500,:,:],u2[0:500,:,:],u3[0:500,:,:],u4[0:500,:,:],u5[0:500,:,:],u6[0:500,:,:],u7[0:500,:,:]),axis=0)\n",
        "\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "\n",
        "x=x.astype(np.uint8)\n",
        "\n",
        "y=[0 for i in range(len(u1[0:500,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:500,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:500,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:500,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:500,:,:]))])\n",
        "y.extend([5 for i in range(len(u6[0:500,:,:]))])\n",
        "y.extend([6 for i in range(len(u7[0:500,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n",
        "print (f'Time: {time.time() - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3500 3500\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 195, 64)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 194, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 193, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_6 (Average (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 95, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_7 (Average (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 5875)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 125)               734500    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 7)                 882       \n",
            "=================================================================\n",
            "Total params: 877,382\n",
            "Trainable params: 877,382\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 2.0072 - accuracy: 0.1372 - val_loss: 1.9397 - val_accuracy: 0.2206\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 2/250\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 1.9433 - accuracy: 0.1701 - val_loss: 1.9222 - val_accuracy: 0.2663\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 3/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.9071 - accuracy: 0.2076 - val_loss: 1.7483 - val_accuracy: 0.2640\n",
            "Epoch 4/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.7308 - accuracy: 0.2506 - val_loss: 1.5158 - val_accuracy: 0.2914\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 5/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.5816 - accuracy: 0.2934 - val_loss: 1.4242 - val_accuracy: 0.2949\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 6/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.5239 - accuracy: 0.3028 - val_loss: 1.3992 - val_accuracy: 0.3074\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 7/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.4516 - accuracy: 0.3084 - val_loss: 1.3487 - val_accuracy: 0.3120\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 8/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.3932 - accuracy: 0.3243 - val_loss: 1.3192 - val_accuracy: 0.3383\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 9/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.3645 - accuracy: 0.3423 - val_loss: 1.2849 - val_accuracy: 0.4126\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 10/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.3255 - accuracy: 0.3754 - val_loss: 1.2152 - val_accuracy: 0.3931\n",
            "Epoch 11/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.2832 - accuracy: 0.3882 - val_loss: 1.1471 - val_accuracy: 0.4846\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 12/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.2328 - accuracy: 0.4292 - val_loss: 1.1062 - val_accuracy: 0.4331\n",
            "Epoch 13/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.1859 - accuracy: 0.4574 - val_loss: 1.0519 - val_accuracy: 0.5154\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 14/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.1395 - accuracy: 0.4775 - val_loss: 1.0145 - val_accuracy: 0.4983\n",
            "Epoch 15/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.0825 - accuracy: 0.5015 - val_loss: 0.9262 - val_accuracy: 0.5406\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 16/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.0088 - accuracy: 0.5358 - val_loss: 0.8557 - val_accuracy: 0.5977\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 17/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.9397 - accuracy: 0.5776 - val_loss: 0.7926 - val_accuracy: 0.5806\n",
            "Epoch 18/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.8888 - accuracy: 0.5967 - val_loss: 0.7357 - val_accuracy: 0.6240\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 19/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.8253 - accuracy: 0.6227 - val_loss: 0.6503 - val_accuracy: 0.6537\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 20/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.7812 - accuracy: 0.6346 - val_loss: 0.7395 - val_accuracy: 0.6091\n",
            "Epoch 21/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.7459 - accuracy: 0.6279 - val_loss: 0.6239 - val_accuracy: 0.6446\n",
            "Epoch 22/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.7455 - accuracy: 0.6336 - val_loss: 0.6438 - val_accuracy: 0.6446\n",
            "Epoch 23/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.7046 - accuracy: 0.6448 - val_loss: 0.5944 - val_accuracy: 0.6446\n",
            "Epoch 24/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6506 - accuracy: 0.6830 - val_loss: 0.6706 - val_accuracy: 0.6091\n",
            "Epoch 25/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6393 - accuracy: 0.6593 - val_loss: 0.5530 - val_accuracy: 0.6617\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 26/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6249 - accuracy: 0.6701 - val_loss: 0.5400 - val_accuracy: 0.6754\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 27/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6211 - accuracy: 0.6630 - val_loss: 0.5350 - val_accuracy: 0.7291\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "Epoch 28/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5941 - accuracy: 0.6827 - val_loss: 0.5966 - val_accuracy: 0.6469\n",
            "Epoch 29/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6202 - accuracy: 0.6801 - val_loss: 0.5434 - val_accuracy: 0.7063\n",
            "Epoch 30/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.5551 - accuracy: 0.6983 - val_loss: 0.5990 - val_accuracy: 0.6503\n",
            "Epoch 31/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.5631 - accuracy: 0.6711 - val_loss: 0.5599 - val_accuracy: 0.7029\n",
            "Epoch 32/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5293 - accuracy: 0.7139 - val_loss: 0.5646 - val_accuracy: 0.6526\n",
            "Epoch 33/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.5781 - accuracy: 0.6976 - val_loss: 0.6648 - val_accuracy: 0.6537\n",
            "Epoch 34/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6447 - accuracy: 0.6603 - val_loss: 0.6248 - val_accuracy: 0.6354\n",
            "Epoch 35/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5460 - accuracy: 0.6857 - val_loss: 0.5529 - val_accuracy: 0.6789\n",
            "Epoch 36/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5315 - accuracy: 0.7157 - val_loss: 0.5796 - val_accuracy: 0.7086\n",
            "Epoch 37/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5437 - accuracy: 0.6879 - val_loss: 0.7638 - val_accuracy: 0.6229\n",
            "Epoch 38/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5177 - accuracy: 0.7092 - val_loss: 0.6347 - val_accuracy: 0.6926\n",
            "Epoch 39/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.5073 - accuracy: 0.7090 - val_loss: 0.6444 - val_accuracy: 0.6857\n",
            "Epoch 40/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.5067 - accuracy: 0.7123 - val_loss: 0.6037 - val_accuracy: 0.6686\n",
            "Epoch 41/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4986 - accuracy: 0.7152 - val_loss: 0.6713 - val_accuracy: 0.6823\n",
            "Epoch 42/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.5114 - accuracy: 0.7051 - val_loss: 0.5328 - val_accuracy: 0.6571\n",
            "Epoch 43/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.5134 - accuracy: 0.7098 - val_loss: 0.5782 - val_accuracy: 0.7051\n",
            "Epoch 44/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4804 - accuracy: 0.7183 - val_loss: 0.6015 - val_accuracy: 0.6629\n",
            "Epoch 45/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4896 - accuracy: 0.7266 - val_loss: 0.5940 - val_accuracy: 0.7177\n",
            "Epoch 46/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4641 - accuracy: 0.7313 - val_loss: 0.7379 - val_accuracy: 0.6526\n",
            "Epoch 47/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4912 - accuracy: 0.6988 - val_loss: 0.5403 - val_accuracy: 0.6834\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 48/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4577 - accuracy: 0.7282 - val_loss: 0.5803 - val_accuracy: 0.6834\n",
            "Epoch 49/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4677 - accuracy: 0.7039 - val_loss: 0.6045 - val_accuracy: 0.7097\n",
            "Epoch 50/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4575 - accuracy: 0.7288 - val_loss: 0.5689 - val_accuracy: 0.6811\n",
            "Epoch 51/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4560 - accuracy: 0.7361 - val_loss: 0.5801 - val_accuracy: 0.6811\n",
            "Epoch 52/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4594 - accuracy: 0.7266 - val_loss: 0.6205 - val_accuracy: 0.6777\n",
            "Epoch 53/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4385 - accuracy: 0.7225 - val_loss: 0.5830 - val_accuracy: 0.6777\n",
            "Epoch 54/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4726 - accuracy: 0.7252 - val_loss: 0.6339 - val_accuracy: 0.6766\n",
            "Epoch 55/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4420 - accuracy: 0.7285 - val_loss: 0.5835 - val_accuracy: 0.6789\n",
            "Epoch 56/250\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.4440 - accuracy: 0.7465 - val_loss: 0.6262 - val_accuracy: 0.6777\n",
            "Epoch 57/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4234 - accuracy: 0.7497 - val_loss: 0.5955 - val_accuracy: 0.6834\n",
            "Epoch 58/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4459 - accuracy: 0.7301 - val_loss: 0.5799 - val_accuracy: 0.6789\n",
            "Epoch 59/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4332 - accuracy: 0.7436 - val_loss: 0.6060 - val_accuracy: 0.7189\n",
            "Epoch 60/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4385 - accuracy: 0.7401 - val_loss: 0.5925 - val_accuracy: 0.6789\n",
            "Epoch 61/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4314 - accuracy: 0.7565 - val_loss: 0.5857 - val_accuracy: 0.6789\n",
            "Epoch 62/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4314 - accuracy: 0.7419 - val_loss: 0.6873 - val_accuracy: 0.6629\n",
            "Epoch 63/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4544 - accuracy: 0.7377 - val_loss: 0.6287 - val_accuracy: 0.6743\n",
            "Epoch 64/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4212 - accuracy: 0.7598 - val_loss: 0.5593 - val_accuracy: 0.6949\n",
            "Epoch 65/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4462 - accuracy: 0.7304 - val_loss: 0.5853 - val_accuracy: 0.6789\n",
            "Epoch 66/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4394 - accuracy: 0.7470 - val_loss: 0.6315 - val_accuracy: 0.6937\n",
            "Epoch 67/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4420 - accuracy: 0.7371 - val_loss: 0.5443 - val_accuracy: 0.7166\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 68/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4264 - accuracy: 0.7433 - val_loss: 0.5711 - val_accuracy: 0.7074\n",
            "Epoch 69/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4178 - accuracy: 0.7501 - val_loss: 0.6517 - val_accuracy: 0.6777\n",
            "Epoch 70/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4315 - accuracy: 0.7361 - val_loss: 0.6451 - val_accuracy: 0.6697\n",
            "Epoch 71/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4245 - accuracy: 0.7611 - val_loss: 0.5928 - val_accuracy: 0.6800\n",
            "Epoch 72/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4390 - accuracy: 0.7343 - val_loss: 0.5851 - val_accuracy: 0.6766\n",
            "Epoch 73/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4347 - accuracy: 0.7586 - val_loss: 0.6070 - val_accuracy: 0.6811\n",
            "Epoch 74/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4255 - accuracy: 0.7570 - val_loss: 0.6128 - val_accuracy: 0.6800\n",
            "Epoch 75/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4228 - accuracy: 0.7543 - val_loss: 0.6175 - val_accuracy: 0.6960\n",
            "Epoch 76/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4217 - accuracy: 0.7503 - val_loss: 0.6202 - val_accuracy: 0.6743\n",
            "Epoch 77/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4219 - accuracy: 0.7457 - val_loss: 0.6377 - val_accuracy: 0.6731\n",
            "Epoch 78/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4364 - accuracy: 0.7376 - val_loss: 0.6223 - val_accuracy: 0.6914\n",
            "Epoch 79/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4308 - accuracy: 0.7434 - val_loss: 0.5956 - val_accuracy: 0.6971\n",
            "Epoch 80/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4239 - accuracy: 0.7539 - val_loss: 0.6151 - val_accuracy: 0.6960\n",
            "Epoch 81/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4303 - accuracy: 0.7289 - val_loss: 0.6018 - val_accuracy: 0.7074\n",
            "Epoch 82/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4318 - accuracy: 0.7318 - val_loss: 0.6066 - val_accuracy: 0.7029\n",
            "Epoch 83/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4152 - accuracy: 0.7564 - val_loss: 0.6308 - val_accuracy: 0.6777\n",
            "Epoch 84/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4284 - accuracy: 0.7472 - val_loss: 0.6191 - val_accuracy: 0.6926\n",
            "Epoch 85/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4266 - accuracy: 0.7458 - val_loss: 0.6212 - val_accuracy: 0.6800\n",
            "Epoch 86/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4288 - accuracy: 0.7473 - val_loss: 0.6310 - val_accuracy: 0.6857\n",
            "Epoch 87/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4310 - accuracy: 0.7309 - val_loss: 0.6365 - val_accuracy: 0.6766\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "Epoch 88/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4191 - accuracy: 0.7542 - val_loss: 0.6280 - val_accuracy: 0.6754\n",
            "Epoch 89/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4312 - accuracy: 0.7474 - val_loss: 0.6226 - val_accuracy: 0.6720\n",
            "Epoch 90/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4188 - accuracy: 0.7607 - val_loss: 0.6207 - val_accuracy: 0.6731\n",
            "Epoch 91/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4287 - accuracy: 0.7432 - val_loss: 0.6161 - val_accuracy: 0.6720\n",
            "Epoch 92/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4236 - accuracy: 0.7542 - val_loss: 0.6175 - val_accuracy: 0.6720\n",
            "Epoch 93/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4220 - accuracy: 0.7499 - val_loss: 0.6217 - val_accuracy: 0.6766\n",
            "Epoch 94/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4261 - accuracy: 0.7481 - val_loss: 0.6190 - val_accuracy: 0.6766\n",
            "Epoch 95/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4394 - accuracy: 0.7265 - val_loss: 0.6212 - val_accuracy: 0.6754\n",
            "Epoch 96/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4247 - accuracy: 0.7447 - val_loss: 0.6245 - val_accuracy: 0.6766\n",
            "Epoch 97/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4422 - accuracy: 0.7506 - val_loss: 0.6292 - val_accuracy: 0.6754\n",
            "Epoch 98/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4168 - accuracy: 0.7519 - val_loss: 0.6213 - val_accuracy: 0.6754\n",
            "Epoch 99/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4153 - accuracy: 0.7552 - val_loss: 0.6148 - val_accuracy: 0.6731\n",
            "Epoch 100/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4231 - accuracy: 0.7421 - val_loss: 0.6125 - val_accuracy: 0.6720\n",
            "Epoch 101/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4252 - accuracy: 0.7619 - val_loss: 0.6118 - val_accuracy: 0.6720\n",
            "Epoch 102/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4372 - accuracy: 0.7438 - val_loss: 0.6082 - val_accuracy: 0.6731\n",
            "Epoch 103/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4284 - accuracy: 0.7464 - val_loss: 0.6114 - val_accuracy: 0.6731\n",
            "Epoch 104/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4273 - accuracy: 0.7456 - val_loss: 0.6139 - val_accuracy: 0.6731\n",
            "Epoch 105/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4369 - accuracy: 0.7373 - val_loss: 0.6147 - val_accuracy: 0.6743\n",
            "Epoch 106/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4243 - accuracy: 0.7454 - val_loss: 0.6151 - val_accuracy: 0.6777\n",
            "Epoch 107/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4353 - accuracy: 0.7265 - val_loss: 0.6193 - val_accuracy: 0.6777\n",
            "\n",
            "Epoch 00107: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "Epoch 108/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4325 - accuracy: 0.7420 - val_loss: 0.6195 - val_accuracy: 0.6777\n",
            "Epoch 109/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4139 - accuracy: 0.7555 - val_loss: 0.6190 - val_accuracy: 0.6777\n",
            "Epoch 110/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4262 - accuracy: 0.7554 - val_loss: 0.6180 - val_accuracy: 0.6777\n",
            "Epoch 111/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4111 - accuracy: 0.7567 - val_loss: 0.6174 - val_accuracy: 0.6777\n",
            "Epoch 112/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4178 - accuracy: 0.7514 - val_loss: 0.6167 - val_accuracy: 0.6777\n",
            "Epoch 113/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4273 - accuracy: 0.7564 - val_loss: 0.6174 - val_accuracy: 0.6777\n",
            "Epoch 114/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4233 - accuracy: 0.7532 - val_loss: 0.6176 - val_accuracy: 0.6777\n",
            "Epoch 115/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4253 - accuracy: 0.7496 - val_loss: 0.6175 - val_accuracy: 0.6777\n",
            "Epoch 116/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4300 - accuracy: 0.7339 - val_loss: 0.6165 - val_accuracy: 0.6766\n",
            "Epoch 117/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4172 - accuracy: 0.7592 - val_loss: 0.6162 - val_accuracy: 0.6777\n",
            "Epoch 118/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4238 - accuracy: 0.7478 - val_loss: 0.6172 - val_accuracy: 0.6766\n",
            "Epoch 119/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4227 - accuracy: 0.7578 - val_loss: 0.6168 - val_accuracy: 0.6766\n",
            "Epoch 120/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4201 - accuracy: 0.7537 - val_loss: 0.6179 - val_accuracy: 0.6777\n",
            "Epoch 121/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4182 - accuracy: 0.7477 - val_loss: 0.6187 - val_accuracy: 0.6766\n",
            "Epoch 122/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4191 - accuracy: 0.7500 - val_loss: 0.6195 - val_accuracy: 0.6766\n",
            "Epoch 123/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4344 - accuracy: 0.7429 - val_loss: 0.6193 - val_accuracy: 0.6777\n",
            "Epoch 124/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4351 - accuracy: 0.7417 - val_loss: 0.6193 - val_accuracy: 0.6777\n",
            "Epoch 125/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4274 - accuracy: 0.7451 - val_loss: 0.6200 - val_accuracy: 0.6777\n",
            "Epoch 126/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4181 - accuracy: 0.7598 - val_loss: 0.6187 - val_accuracy: 0.6777\n",
            "Epoch 127/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4253 - accuracy: 0.7384 - val_loss: 0.6184 - val_accuracy: 0.6777\n",
            "\n",
            "Epoch 00127: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "Epoch 128/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4252 - accuracy: 0.7455 - val_loss: 0.6189 - val_accuracy: 0.6777\n",
            "Epoch 129/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4125 - accuracy: 0.7612 - val_loss: 0.6194 - val_accuracy: 0.6777\n",
            "Epoch 130/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4179 - accuracy: 0.7659 - val_loss: 0.6195 - val_accuracy: 0.6777\n",
            "Epoch 131/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4162 - accuracy: 0.7574 - val_loss: 0.6196 - val_accuracy: 0.6777\n",
            "Epoch 132/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4204 - accuracy: 0.7538 - val_loss: 0.6198 - val_accuracy: 0.6777\n",
            "Epoch 133/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4269 - accuracy: 0.7514 - val_loss: 0.6199 - val_accuracy: 0.6777\n",
            "Epoch 134/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4241 - accuracy: 0.7579 - val_loss: 0.6201 - val_accuracy: 0.6777\n",
            "Epoch 135/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4223 - accuracy: 0.7425 - val_loss: 0.6205 - val_accuracy: 0.6777\n",
            "Epoch 136/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4255 - accuracy: 0.7442 - val_loss: 0.6207 - val_accuracy: 0.6777\n",
            "Epoch 137/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4169 - accuracy: 0.7470 - val_loss: 0.6207 - val_accuracy: 0.6777\n",
            "Epoch 138/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4274 - accuracy: 0.7418 - val_loss: 0.6208 - val_accuracy: 0.6777\n",
            "Epoch 139/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4234 - accuracy: 0.7496 - val_loss: 0.6209 - val_accuracy: 0.6777\n",
            "Epoch 140/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4316 - accuracy: 0.7452 - val_loss: 0.6206 - val_accuracy: 0.6777\n",
            "Epoch 141/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4355 - accuracy: 0.7378 - val_loss: 0.6204 - val_accuracy: 0.6777\n",
            "Epoch 142/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4200 - accuracy: 0.7379 - val_loss: 0.6205 - val_accuracy: 0.6777\n",
            "Epoch 143/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4270 - accuracy: 0.7473 - val_loss: 0.6204 - val_accuracy: 0.6777\n",
            "Epoch 144/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4332 - accuracy: 0.7446 - val_loss: 0.6203 - val_accuracy: 0.6777\n",
            "Epoch 145/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4397 - accuracy: 0.7453 - val_loss: 0.6200 - val_accuracy: 0.6777\n",
            "Epoch 146/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4255 - accuracy: 0.7503 - val_loss: 0.6193 - val_accuracy: 0.6777\n",
            "Epoch 147/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4303 - accuracy: 0.7454 - val_loss: 0.6187 - val_accuracy: 0.6777\n",
            "\n",
            "Epoch 00147: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "Epoch 148/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4290 - accuracy: 0.7609 - val_loss: 0.6186 - val_accuracy: 0.6777\n",
            "Epoch 149/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4337 - accuracy: 0.7364 - val_loss: 0.6185 - val_accuracy: 0.6777\n",
            "Epoch 150/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4330 - accuracy: 0.7428 - val_loss: 0.6184 - val_accuracy: 0.6777\n",
            "Epoch 151/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4201 - accuracy: 0.7449 - val_loss: 0.6183 - val_accuracy: 0.6766\n",
            "Epoch 152/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4287 - accuracy: 0.7443 - val_loss: 0.6181 - val_accuracy: 0.6766\n",
            "Epoch 153/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4339 - accuracy: 0.7452 - val_loss: 0.6180 - val_accuracy: 0.6766\n",
            "Epoch 154/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4252 - accuracy: 0.7472 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 155/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4179 - accuracy: 0.7551 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 156/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4112 - accuracy: 0.7518 - val_loss: 0.6178 - val_accuracy: 0.6766\n",
            "Epoch 157/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4212 - accuracy: 0.7669 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 158/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4283 - accuracy: 0.7557 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 159/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4219 - accuracy: 0.7503 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 160/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4172 - accuracy: 0.7555 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 161/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4375 - accuracy: 0.7614 - val_loss: 0.6178 - val_accuracy: 0.6766\n",
            "Epoch 162/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4186 - accuracy: 0.7470 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 163/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4226 - accuracy: 0.7640 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 164/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4335 - accuracy: 0.7467 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 165/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4254 - accuracy: 0.7430 - val_loss: 0.6179 - val_accuracy: 0.6766\n",
            "Epoch 166/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4370 - accuracy: 0.7622 - val_loss: 0.6180 - val_accuracy: 0.6766\n",
            "Epoch 167/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4319 - accuracy: 0.7402 - val_loss: 0.6181 - val_accuracy: 0.6777\n",
            "\n",
            "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "Epoch 168/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4450 - accuracy: 0.7226 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 169/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4262 - accuracy: 0.7422 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 170/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4225 - accuracy: 0.7516 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 171/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4075 - accuracy: 0.7573 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 172/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4321 - accuracy: 0.7425 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 173/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4236 - accuracy: 0.7466 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 174/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4115 - accuracy: 0.7595 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 175/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4105 - accuracy: 0.7588 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 176/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4255 - accuracy: 0.7468 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 177/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4271 - accuracy: 0.7488 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 178/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4253 - accuracy: 0.7458 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 179/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4226 - accuracy: 0.7423 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 180/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4086 - accuracy: 0.7652 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 181/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4203 - accuracy: 0.7506 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 182/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4217 - accuracy: 0.7572 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 183/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4258 - accuracy: 0.7533 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 184/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4231 - accuracy: 0.7428 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 185/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4141 - accuracy: 0.7515 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 186/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4165 - accuracy: 0.7602 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 187/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4356 - accuracy: 0.7515 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "\n",
            "Epoch 00187: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "Epoch 188/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4281 - accuracy: 0.7359 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 189/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4357 - accuracy: 0.7352 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 190/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4278 - accuracy: 0.7459 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 191/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4386 - accuracy: 0.7556 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 192/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4265 - accuracy: 0.7540 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 193/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4347 - accuracy: 0.7302 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 194/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4153 - accuracy: 0.7476 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 195/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4336 - accuracy: 0.7525 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 196/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4341 - accuracy: 0.7562 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 197/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4332 - accuracy: 0.7387 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 198/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4303 - accuracy: 0.7439 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 199/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4288 - accuracy: 0.7357 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 200/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4166 - accuracy: 0.7549 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 201/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4079 - accuracy: 0.7468 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 202/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4229 - accuracy: 0.7452 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 203/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4384 - accuracy: 0.7357 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 204/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4263 - accuracy: 0.7490 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 205/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4287 - accuracy: 0.7581 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 206/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4307 - accuracy: 0.7486 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 207/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4216 - accuracy: 0.7438 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "\n",
            "Epoch 00207: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
            "Epoch 208/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4328 - accuracy: 0.7510 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 209/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4243 - accuracy: 0.7504 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 210/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4221 - accuracy: 0.7494 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 211/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4388 - accuracy: 0.7225 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 212/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4211 - accuracy: 0.7516 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 213/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4352 - accuracy: 0.7427 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 214/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4165 - accuracy: 0.7583 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 215/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4175 - accuracy: 0.7574 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 216/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4210 - accuracy: 0.7411 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 217/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4194 - accuracy: 0.7546 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 218/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4259 - accuracy: 0.7409 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 219/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4180 - accuracy: 0.7407 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 220/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4178 - accuracy: 0.7468 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 221/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4346 - accuracy: 0.7396 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 222/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4266 - accuracy: 0.7498 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 223/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4261 - accuracy: 0.7472 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 224/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4050 - accuracy: 0.7685 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 225/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4313 - accuracy: 0.7506 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 226/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4255 - accuracy: 0.7389 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 227/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4360 - accuracy: 0.7422 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "\n",
            "Epoch 00227: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
            "Epoch 228/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4189 - accuracy: 0.7378 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 229/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4089 - accuracy: 0.7521 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 230/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4235 - accuracy: 0.7486 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 231/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4296 - accuracy: 0.7406 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 232/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4290 - accuracy: 0.7397 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 233/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4260 - accuracy: 0.7537 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 234/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4285 - accuracy: 0.7568 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 235/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4151 - accuracy: 0.7517 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 236/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4283 - accuracy: 0.7416 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 237/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4224 - accuracy: 0.7433 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 238/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4311 - accuracy: 0.7603 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 239/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4254 - accuracy: 0.7484 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 240/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4242 - accuracy: 0.7517 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 241/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4340 - accuracy: 0.7300 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 242/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4166 - accuracy: 0.7541 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 243/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4126 - accuracy: 0.7636 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 244/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4140 - accuracy: 0.7500 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 245/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4335 - accuracy: 0.7435 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 246/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4122 - accuracy: 0.7472 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 247/250\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4355 - accuracy: 0.7435 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "\n",
            "Epoch 00247: ReduceLROnPlateau reducing learning rate to 2.0480002416167767e-11.\n",
            "Epoch 248/250\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.4237 - accuracy: 0.7423 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 249/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4253 - accuracy: 0.7612 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Epoch 250/250\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.4172 - accuracy: 0.7500 - val_loss: 0.6182 - val_accuracy: 0.6777\n",
            "Time: 103.11782121658325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYlMXO8wiOai",
        "outputId": "06e477c0-9b8b-4791-fb43-2b4079733af2"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 2.5K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "\n",
        "t=np.concatenate((t1,t2,t3,t4,t5,t6,t7),axis=0)\n",
        "\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      t[arr][idx][t[arr][idx] == 0] = -1\n",
        "      t[arr][idx][t[arr][idx] == 1] = 0\n",
        "      t[arr][idx][t[arr][idx] == -1] = 1\n",
        "\n",
        "t=t.astype(np.uint8)\n",
        "\n",
        "# Label simulations from the test set.\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y.extend([5 for i in range(len(t6))])\n",
        "y.extend([6 for i in range(len(t7))])\n",
        "y = np.array(y)\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod')\n",
        "pred = model.predict(t)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 738    0   52    0    0  210    0]\n",
            " [   3  800    0   13   15    0  169]\n",
            " [   0    0 1000    0    0    0    0]\n",
            " [   0    0  107  858   34    0    1]\n",
            " [   0    1    0    6  993    0    0]\n",
            " [   9    0   44    0    0  947    0]\n",
            " [   0   60    4   20    3    6  907]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfN2JKeeQpwo",
        "outputId": "47aae1e4-71f7-43b8-b8b2-d1a3b033811f"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 1K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod')\n",
        "pred = model.predict(t)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[781   0  74   0   0 145   0]\n",
            " [  5 764   0  19  20   0 192]\n",
            " [  0   0 999   1   0   0   0]\n",
            " [  0   0 124 830  43   0   3]\n",
            " [  0   3   0   5 991   0   1]\n",
            " [ 52   0  54   0   0 894   0]\n",
            " [  1  79   3  15   6   4 892]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYKdCeqPT5Q9",
        "outputId": "6009e1d1-d073-4a31-ab2a-6a716a7b6dbd"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 500 simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "t=np.concatenate((t1,t2,t3,t4,t5,t6,t7),axis=0)\n",
        "\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      t[arr][idx][t[arr][idx] == 0] = -1\n",
        "      t[arr][idx][t[arr][idx] == 1] = 0\n",
        "      t[arr][idx][t[arr][idx] == -1] = 1\n",
        "\n",
        "t=t.astype(np.uint8)\n",
        "\n",
        "# Label simulations from the test set.\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y.extend([5 for i in range(len(t6))])\n",
        "y.extend([6 for i in range(len(t7))])\n",
        "y = np.array(y)\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod')\n",
        "pred = model.predict(t)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 20   0  90   0   0 890   0]\n",
            " [  3 578   0  33  49   2 335]\n",
            " [  0   0 998   2   0   0   0]\n",
            " [  0   1 126 842  31   0   0]\n",
            " [  0   0   0  11 989   0   0]\n",
            " [ 21   0  71   0   0 908   0]\n",
            " [  9 353   4  23  11   6 594]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}