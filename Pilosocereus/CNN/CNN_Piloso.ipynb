{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_CNN_Piloso",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELhRS0fu2b6T",
        "colab_type": "text"
      },
      "source": [
        "## **Notebook containing scripts and outputs of the training, cross-validation and empirical data prediction for *Pilosocereus aurisetus***\n",
        "From the manuscript Perez et al. \"Species Delimitation Meets Deep Learning: Insights from a Highly Fragmented Cactus System\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffjZgEDIRlld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7ff037ee-518b-4cc9-a4a9-c03a0242b885"
      },
      "source": [
        "#mount google drive to load files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgc_VfbydhlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all required modules.\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.pooling import  AveragePooling1D\n",
        "from keras import backend as K\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from random import shuffle\n",
        "import time\n",
        "\n",
        "# Define parameters for the CNN run.\n",
        "batch_size = 250\n",
        "epochs = 250\n",
        "num_classes = 5\n",
        "\n",
        "# Define the CNN architecture.\n",
        "def create_cnn(xtest, regularizer=None):\n",
        "\tinputShape = (xtest.shape[1], xtest.shape[2])\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = inputs\n",
        "\tx = Conv1D(250, kernel_size=2, activation='relu',input_shape=(xtest.shape[1], xtest.shape[2]))(x)\n",
        "\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n",
        "\tx = AveragePooling1D(pool_size=2)(x)\n",
        "\tx = Dropout(0.75)(x)\n",
        "\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n",
        "\tx = AveragePooling1D(pool_size=2)(x)\n",
        "\tx = Dropout(0.75)(x)\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(125, activation='relu')(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\tx = Dense(125, activation='relu')(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "  # The final fully-connected layer head will have a softmax dense layer.\n",
        "\tx = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\t# Construct the CNN.\n",
        "\tmodel = Model(inputs, x)\n",
        "\t# Return the CNN.\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_ohKNkh4Ki-",
        "colab_type": "text"
      },
      "source": [
        "# **Train the network with 10,000 simulations from each model**\n",
        "Here we will use the full simulated dataset to train the network, by splitting the data with 75% of simulations for training and 25% for validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJgkHTL9Tddn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9a4e0b4-c5b5-4b1a-cf23-10b7223175d7"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train a network using 10K simulations per model.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing simulations.\n",
        "u1 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/simModel1.npy\",mmap_mode='r')\n",
        "u2 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/simModel2.npy\",mmap_mode='r')\n",
        "u3 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/simModel3.npy\",mmap_mode='r')\n",
        "u4 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/simModel4.npy\",mmap_mode='r')\n",
        "u5 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/simModel5.npy\",mmap_mode='r')\n",
        "\n",
        "# Combine all arrays.\n",
        "x=np.concatenate((u1,u2,u3,u4,u5),axis=0)\n",
        "\n",
        "# Label each simulated array.\n",
        "y=[0 for i in range(len(u1))]\n",
        "y.extend([1 for i in range(len(u2))])\n",
        "y.extend([2 for i in range(len(u3))])\n",
        "y.extend([3 for i in range(len(u4))])\n",
        "y.extend([4 for i in range(len(u5))])\n",
        "y = np.array(y)\n",
        "\n",
        "# Print label and simulations length, these should be the same.\n",
        "print (len(x), len(y))\n",
        "\n",
        "# Shuffle the arrays for training, keeping the labels in the same order.\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "# Separate train (75%) and validate (25%) sets.\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network, using the architecture defined above.\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "# Compile the CNN.\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "print(cnn.summary())\n",
        "\n",
        "# Start a timer to estimate training runtime.\n",
        "start = time.time()\n",
        "# Run the CNN.\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest))\n",
        "print ('Time: ')\n",
        "print (time.time() - start)\n",
        "\n",
        "# Save the trained model\n",
        "cnn.save(filepath='/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 50000\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 214, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 213, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 212, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_1 (Average (None, 106, 125)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 106, 125)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 105, 125)          31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_2 (Average (None, 52, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 52, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6500)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 125)               812625    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 630       \n",
            "=================================================================\n",
            "Total params: 955,255\n",
            "Trainable params: 955,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 37500 samples, validate on 12500 samples\n",
            "Epoch 1/250\n",
            "37500/37500 [==============================] - 18s 484us/step - loss: 1.2014 - accuracy: 0.4199 - val_loss: 0.4812 - val_accuracy: 0.8262\n",
            "Epoch 2/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.3494 - accuracy: 0.8809 - val_loss: 0.2051 - val_accuracy: 0.9278\n",
            "Epoch 3/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.1984 - accuracy: 0.9415 - val_loss: 0.1269 - val_accuracy: 0.9561\n",
            "Epoch 4/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.1491 - accuracy: 0.9575 - val_loss: 0.1397 - val_accuracy: 0.9556\n",
            "Epoch 5/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.1300 - accuracy: 0.9644 - val_loss: 0.0851 - val_accuracy: 0.9740\n",
            "Epoch 6/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.1174 - accuracy: 0.9687 - val_loss: 0.1141 - val_accuracy: 0.9661\n",
            "Epoch 7/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.1084 - accuracy: 0.9722 - val_loss: 0.0846 - val_accuracy: 0.9750\n",
            "Epoch 8/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0954 - accuracy: 0.9747 - val_loss: 0.0751 - val_accuracy: 0.9772\n",
            "Epoch 9/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0844 - accuracy: 0.9776 - val_loss: 0.0857 - val_accuracy: 0.9747\n",
            "Epoch 10/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0854 - accuracy: 0.9780 - val_loss: 0.0810 - val_accuracy: 0.9766\n",
            "Epoch 11/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0788 - accuracy: 0.9793 - val_loss: 0.0802 - val_accuracy: 0.9784\n",
            "Epoch 12/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0738 - accuracy: 0.9807 - val_loss: 0.0693 - val_accuracy: 0.9793\n",
            "Epoch 13/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0724 - accuracy: 0.9821 - val_loss: 0.0550 - val_accuracy: 0.9839\n",
            "Epoch 14/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0720 - accuracy: 0.9820 - val_loss: 0.0552 - val_accuracy: 0.9835\n",
            "Epoch 15/250\n",
            "37500/37500 [==============================] - 12s 311us/step - loss: 0.0631 - accuracy: 0.9843 - val_loss: 0.0530 - val_accuracy: 0.9847\n",
            "Epoch 16/250\n",
            "37500/37500 [==============================] - 12s 311us/step - loss: 0.0678 - accuracy: 0.9826 - val_loss: 0.0748 - val_accuracy: 0.9794\n",
            "Epoch 17/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0594 - accuracy: 0.9849 - val_loss: 0.0547 - val_accuracy: 0.9854\n",
            "Epoch 18/250\n",
            "37500/37500 [==============================] - 12s 310us/step - loss: 0.0678 - accuracy: 0.9830 - val_loss: 0.0606 - val_accuracy: 0.9831\n",
            "Epoch 19/250\n",
            "37500/37500 [==============================] - 12s 310us/step - loss: 0.0592 - accuracy: 0.9855 - val_loss: 0.0461 - val_accuracy: 0.9866\n",
            "Epoch 20/250\n",
            "37500/37500 [==============================] - 12s 312us/step - loss: 0.0550 - accuracy: 0.9856 - val_loss: 0.0588 - val_accuracy: 0.9837\n",
            "Epoch 21/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0543 - accuracy: 0.9864 - val_loss: 0.0844 - val_accuracy: 0.9758\n",
            "Epoch 22/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0572 - accuracy: 0.9858 - val_loss: 0.1196 - val_accuracy: 0.9714\n",
            "Epoch 23/250\n",
            "37500/37500 [==============================] - 12s 310us/step - loss: 0.0537 - accuracy: 0.9860 - val_loss: 0.0715 - val_accuracy: 0.9801\n",
            "Epoch 24/250\n",
            "37500/37500 [==============================] - 12s 311us/step - loss: 0.0493 - accuracy: 0.9876 - val_loss: 0.0436 - val_accuracy: 0.9882\n",
            "Epoch 25/250\n",
            "37500/37500 [==============================] - 12s 313us/step - loss: 0.0498 - accuracy: 0.9872 - val_loss: 0.0823 - val_accuracy: 0.9794\n",
            "Epoch 26/250\n",
            "37500/37500 [==============================] - 12s 312us/step - loss: 0.0482 - accuracy: 0.9871 - val_loss: 0.0763 - val_accuracy: 0.9819\n",
            "Epoch 27/250\n",
            "37500/37500 [==============================] - 12s 317us/step - loss: 0.0494 - accuracy: 0.9873 - val_loss: 0.0875 - val_accuracy: 0.9794\n",
            "Epoch 28/250\n",
            "37500/37500 [==============================] - 12s 312us/step - loss: 0.0417 - accuracy: 0.9897 - val_loss: 0.0570 - val_accuracy: 0.9859\n",
            "Epoch 29/250\n",
            "37500/37500 [==============================] - 12s 310us/step - loss: 0.0434 - accuracy: 0.9882 - val_loss: 0.0479 - val_accuracy: 0.9862\n",
            "Epoch 30/250\n",
            "37500/37500 [==============================] - 12s 312us/step - loss: 0.0489 - accuracy: 0.9876 - val_loss: 0.0550 - val_accuracy: 0.9854\n",
            "Epoch 31/250\n",
            "37500/37500 [==============================] - 12s 312us/step - loss: 0.0449 - accuracy: 0.9880 - val_loss: 0.0974 - val_accuracy: 0.9746\n",
            "Epoch 32/250\n",
            "37500/37500 [==============================] - 12s 312us/step - loss: 0.0516 - accuracy: 0.9868 - val_loss: 0.0507 - val_accuracy: 0.9864\n",
            "Epoch 33/250\n",
            "37500/37500 [==============================] - 12s 312us/step - loss: 0.0442 - accuracy: 0.9883 - val_loss: 0.0799 - val_accuracy: 0.9817\n",
            "Epoch 34/250\n",
            "37500/37500 [==============================] - 12s 314us/step - loss: 0.0417 - accuracy: 0.9900 - val_loss: 0.0514 - val_accuracy: 0.9872\n",
            "Epoch 35/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0392 - accuracy: 0.9898 - val_loss: 0.0953 - val_accuracy: 0.9769\n",
            "Epoch 36/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0378 - accuracy: 0.9901 - val_loss: 0.0558 - val_accuracy: 0.9865\n",
            "Epoch 37/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0359 - accuracy: 0.9907 - val_loss: 0.0802 - val_accuracy: 0.9813\n",
            "Epoch 38/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.0726 - val_accuracy: 0.9845\n",
            "Epoch 39/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0358 - accuracy: 0.9901 - val_loss: 0.0738 - val_accuracy: 0.9807\n",
            "Epoch 40/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0425 - accuracy: 0.9889 - val_loss: 0.0503 - val_accuracy: 0.9875\n",
            "Epoch 41/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.0514 - val_accuracy: 0.9876\n",
            "Epoch 42/250\n",
            "37500/37500 [==============================] - 11s 307us/step - loss: 0.0322 - accuracy: 0.9916 - val_loss: 0.1128 - val_accuracy: 0.9734\n",
            "Epoch 43/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
            "Epoch 44/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0316 - accuracy: 0.9917 - val_loss: 0.0500 - val_accuracy: 0.9875\n",
            "Epoch 45/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0302 - accuracy: 0.9924 - val_loss: 0.1124 - val_accuracy: 0.9760\n",
            "Epoch 46/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0296 - accuracy: 0.9925 - val_loss: 0.1298 - val_accuracy: 0.9722\n",
            "Epoch 47/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0294 - accuracy: 0.9919 - val_loss: 0.0835 - val_accuracy: 0.9818\n",
            "Epoch 48/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0275 - accuracy: 0.9926 - val_loss: 0.0973 - val_accuracy: 0.9804\n",
            "Epoch 49/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0279 - accuracy: 0.9926 - val_loss: 0.0659 - val_accuracy: 0.9840\n",
            "Epoch 50/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.0521 - val_accuracy: 0.9875\n",
            "Epoch 51/250\n",
            "37500/37500 [==============================] - 12s 310us/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 0.0622 - val_accuracy: 0.9810\n",
            "Epoch 52/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0253 - accuracy: 0.9934 - val_loss: 0.0586 - val_accuracy: 0.9873\n",
            "Epoch 53/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0272 - accuracy: 0.9933 - val_loss: 0.0607 - val_accuracy: 0.9848\n",
            "Epoch 54/250\n",
            "37500/37500 [==============================] - 12s 314us/step - loss: 0.0322 - accuracy: 0.9913 - val_loss: 0.0598 - val_accuracy: 0.9843\n",
            "Epoch 55/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0225 - accuracy: 0.9941 - val_loss: 0.0935 - val_accuracy: 0.9811\n",
            "Epoch 56/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0251 - accuracy: 0.9930 - val_loss: 0.0828 - val_accuracy: 0.9792\n",
            "Epoch 57/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0729 - val_accuracy: 0.9834\n",
            "Epoch 58/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0279 - accuracy: 0.9926 - val_loss: 0.0832 - val_accuracy: 0.9802\n",
            "Epoch 59/250\n",
            "37500/37500 [==============================] - 11s 307us/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0643 - val_accuracy: 0.9852\n",
            "Epoch 60/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.1027 - val_accuracy: 0.9775\n",
            "Epoch 61/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0263 - accuracy: 0.9933 - val_loss: 0.0779 - val_accuracy: 0.9824\n",
            "Epoch 62/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.1063 - val_accuracy: 0.9829\n",
            "Epoch 63/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 0.0993 - val_accuracy: 0.9777\n",
            "Epoch 64/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0242 - accuracy: 0.9938 - val_loss: 0.1121 - val_accuracy: 0.9801\n",
            "Epoch 65/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.1540 - val_accuracy: 0.9718\n",
            "Epoch 66/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.1078 - val_accuracy: 0.9803\n",
            "Epoch 67/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0321 - accuracy: 0.9918 - val_loss: 0.1219 - val_accuracy: 0.9778\n",
            "Epoch 68/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 0.0707 - val_accuracy: 0.9870\n",
            "Epoch 69/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.0792 - val_accuracy: 0.9854\n",
            "Epoch 70/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.0921 - val_accuracy: 0.9772\n",
            "Epoch 71/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.0700 - val_accuracy: 0.9868\n",
            "Epoch 72/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.1412 - val_accuracy: 0.9722\n",
            "Epoch 73/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.1108 - val_accuracy: 0.9757\n",
            "Epoch 74/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.1001 - val_accuracy: 0.9842\n",
            "Epoch 75/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.1193 - val_accuracy: 0.9817\n",
            "Epoch 76/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.0876 - val_accuracy: 0.9864\n",
            "Epoch 77/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.1630 - val_accuracy: 0.9655\n",
            "Epoch 78/250\n",
            "37500/37500 [==============================] - 12s 310us/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.0825 - val_accuracy: 0.9813\n",
            "Epoch 79/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0197 - accuracy: 0.9947 - val_loss: 0.0843 - val_accuracy: 0.9837\n",
            "Epoch 80/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.0940 - val_accuracy: 0.9838\n",
            "Epoch 81/250\n",
            "37500/37500 [==============================] - 12s 312us/step - loss: 0.0212 - accuracy: 0.9943 - val_loss: 0.2306 - val_accuracy: 0.9530\n",
            "Epoch 82/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0240 - accuracy: 0.9935 - val_loss: 0.1427 - val_accuracy: 0.9726\n",
            "Epoch 83/250\n",
            "37500/37500 [==============================] - 11s 307us/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0987 - val_accuracy: 0.9841\n",
            "Epoch 84/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0854 - val_accuracy: 0.9880\n",
            "Epoch 85/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.0999 - val_accuracy: 0.9842\n",
            "Epoch 86/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0945 - val_accuracy: 0.9856\n",
            "Epoch 87/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0909 - val_accuracy: 0.9805\n",
            "Epoch 88/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.1167 - val_accuracy: 0.9825\n",
            "Epoch 89/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.1151 - val_accuracy: 0.9828\n",
            "Epoch 90/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.1468 - val_accuracy: 0.9782\n",
            "Epoch 91/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.1351 - val_accuracy: 0.9816\n",
            "Epoch 92/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0152 - accuracy: 0.9960 - val_loss: 0.1390 - val_accuracy: 0.9806\n",
            "Epoch 93/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.1241 - val_accuracy: 0.9826\n",
            "Epoch 94/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.0845 - val_accuracy: 0.9848\n",
            "Epoch 95/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.1077 - val_accuracy: 0.9799\n",
            "Epoch 96/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.1617 - val_accuracy: 0.9746\n",
            "Epoch 97/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.1028 - val_accuracy: 0.9860\n",
            "Epoch 98/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.0979 - val_accuracy: 0.9855\n",
            "Epoch 99/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.1211 - val_accuracy: 0.9851\n",
            "Epoch 100/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.1166 - val_accuracy: 0.9834\n",
            "Epoch 101/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 0.1159 - val_accuracy: 0.9844\n",
            "Epoch 102/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 0.1116 - val_accuracy: 0.9827\n",
            "Epoch 103/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0143 - accuracy: 0.9966 - val_loss: 0.0938 - val_accuracy: 0.9853\n",
            "Epoch 104/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.2434 - val_accuracy: 0.9667\n",
            "Epoch 105/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.2012 - val_accuracy: 0.9774\n",
            "Epoch 106/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.1357 - val_accuracy: 0.9802\n",
            "Epoch 107/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.1160 - val_accuracy: 0.9837\n",
            "Epoch 108/250\n",
            "37500/37500 [==============================] - 12s 311us/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1525 - val_accuracy: 0.9798\n",
            "Epoch 109/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.1667 - val_accuracy: 0.9798\n",
            "Epoch 110/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1231 - val_accuracy: 0.9793\n",
            "Epoch 111/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.3844 - val_accuracy: 0.9538\n",
            "Epoch 112/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.1318 - val_accuracy: 0.9776\n",
            "Epoch 113/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.1677 - val_accuracy: 0.9796\n",
            "Epoch 114/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0977 - val_accuracy: 0.9842\n",
            "Epoch 115/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1731 - val_accuracy: 0.9763\n",
            "Epoch 116/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 0.1337 - val_accuracy: 0.9785\n",
            "Epoch 117/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1927 - val_accuracy: 0.9746\n",
            "Epoch 118/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.1274 - val_accuracy: 0.9854\n",
            "Epoch 119/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0119 - accuracy: 0.9970 - val_loss: 0.0955 - val_accuracy: 0.9858\n",
            "Epoch 120/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.1151 - val_accuracy: 0.9824\n",
            "Epoch 121/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.1543 - val_accuracy: 0.9789\n",
            "Epoch 122/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.1142 - val_accuracy: 0.9866\n",
            "Epoch 123/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1488 - val_accuracy: 0.9816\n",
            "Epoch 124/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0132 - accuracy: 0.9966 - val_loss: 0.1872 - val_accuracy: 0.9751\n",
            "Epoch 125/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.1386 - val_accuracy: 0.9847\n",
            "Epoch 126/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.1557 - val_accuracy: 0.9820\n",
            "Epoch 127/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.1654 - val_accuracy: 0.9812\n",
            "Epoch 128/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 0.1371 - val_accuracy: 0.9819\n",
            "Epoch 129/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0196 - accuracy: 0.9953 - val_loss: 0.0841 - val_accuracy: 0.9850\n",
            "Epoch 130/250\n",
            "37500/37500 [==============================] - 11s 307us/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.1487 - val_accuracy: 0.9776\n",
            "Epoch 131/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.1637 - val_accuracy: 0.9785\n",
            "Epoch 132/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.1928 - val_accuracy: 0.9767\n",
            "Epoch 133/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1851 - val_accuracy: 0.9814\n",
            "Epoch 134/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.2174 - val_accuracy: 0.9756\n",
            "Epoch 135/250\n",
            "37500/37500 [==============================] - 12s 311us/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.1998 - val_accuracy: 0.9802\n",
            "Epoch 136/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.1717 - val_accuracy: 0.9795\n",
            "Epoch 137/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.1835 - val_accuracy: 0.9786\n",
            "Epoch 138/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.2893 - val_accuracy: 0.9729\n",
            "Epoch 139/250\n",
            "37500/37500 [==============================] - 11s 307us/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.1001 - val_accuracy: 0.9862\n",
            "Epoch 140/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.1639 - val_accuracy: 0.9814\n",
            "Epoch 141/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.1244 - val_accuracy: 0.9856\n",
            "Epoch 142/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.1916 - val_accuracy: 0.9744\n",
            "Epoch 143/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.1751 - val_accuracy: 0.9798\n",
            "Epoch 144/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 0.1685 - val_accuracy: 0.9818\n",
            "Epoch 145/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.1082 - val_accuracy: 0.9861\n",
            "Epoch 146/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.1056 - val_accuracy: 0.9873\n",
            "Epoch 147/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.1554 - val_accuracy: 0.9842\n",
            "Epoch 148/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.1530 - val_accuracy: 0.9845\n",
            "Epoch 149/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.1470 - val_accuracy: 0.9831\n",
            "Epoch 150/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1712 - val_accuracy: 0.9785\n",
            "Epoch 151/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.1291 - val_accuracy: 0.9802\n",
            "Epoch 152/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.1368 - val_accuracy: 0.9809\n",
            "Epoch 153/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.1512 - val_accuracy: 0.9726\n",
            "Epoch 154/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.1283 - val_accuracy: 0.9845\n",
            "Epoch 155/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.1812 - val_accuracy: 0.9786\n",
            "Epoch 156/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.1350 - val_accuracy: 0.9853\n",
            "Epoch 157/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.1235 - val_accuracy: 0.9870\n",
            "Epoch 158/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.1687 - val_accuracy: 0.9775\n",
            "Epoch 159/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1892 - val_accuracy: 0.9771\n",
            "Epoch 160/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.1176 - val_accuracy: 0.9874\n",
            "Epoch 161/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.1788 - val_accuracy: 0.9771\n",
            "Epoch 162/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.1741 - val_accuracy: 0.9794\n",
            "Epoch 163/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.1694 - val_accuracy: 0.9802\n",
            "Epoch 164/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0119 - accuracy: 0.9976 - val_loss: 0.1338 - val_accuracy: 0.9855\n",
            "Epoch 165/250\n",
            "37500/37500 [==============================] - 11s 301us/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1375 - val_accuracy: 0.9833\n",
            "Epoch 166/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.1814 - val_accuracy: 0.9843\n",
            "Epoch 167/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.1737 - val_accuracy: 0.9811\n",
            "Epoch 168/250\n",
            "37500/37500 [==============================] - 11s 301us/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.2081 - val_accuracy: 0.9819\n",
            "Epoch 169/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1572 - val_accuracy: 0.9872\n",
            "Epoch 170/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.1695 - val_accuracy: 0.9854\n",
            "Epoch 171/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.1802 - val_accuracy: 0.9819\n",
            "Epoch 172/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.2660 - val_accuracy: 0.9722\n",
            "Epoch 173/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.1894 - val_accuracy: 0.9786\n",
            "Epoch 174/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 0.1408 - val_accuracy: 0.9838\n",
            "Epoch 175/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.1527 - val_accuracy: 0.9822\n",
            "Epoch 176/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0243 - accuracy: 0.9954 - val_loss: 0.2166 - val_accuracy: 0.9677\n",
            "Epoch 177/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.1459 - val_accuracy: 0.9799\n",
            "Epoch 178/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1867 - val_accuracy: 0.9828\n",
            "Epoch 179/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.1624 - val_accuracy: 0.9842\n",
            "Epoch 180/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.2040 - val_accuracy: 0.9767\n",
            "Epoch 181/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.1423 - val_accuracy: 0.9821\n",
            "Epoch 182/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1643 - val_accuracy: 0.9853\n",
            "Epoch 183/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0207 - accuracy: 0.9955 - val_loss: 0.2005 - val_accuracy: 0.9737\n",
            "Epoch 184/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.1676 - val_accuracy: 0.9811\n",
            "Epoch 185/250\n",
            "37500/37500 [==============================] - 11s 307us/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.1786 - val_accuracy: 0.9770\n",
            "Epoch 186/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1822 - val_accuracy: 0.9822\n",
            "Epoch 187/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.2248 - val_accuracy: 0.9709\n",
            "Epoch 188/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.1415 - val_accuracy: 0.9807\n",
            "Epoch 189/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 0.1495 - val_accuracy: 0.9854\n",
            "Epoch 190/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.1240 - val_accuracy: 0.9828\n",
            "Epoch 191/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.1696 - val_accuracy: 0.9834\n",
            "Epoch 192/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.1577 - val_accuracy: 0.9790\n",
            "Epoch 193/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.1866 - val_accuracy: 0.9815\n",
            "Epoch 194/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.2392 - val_accuracy: 0.9802\n",
            "Epoch 195/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.1928 - val_accuracy: 0.9750\n",
            "Epoch 196/250\n",
            "37500/37500 [==============================] - 11s 301us/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.1611 - val_accuracy: 0.9871\n",
            "Epoch 197/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1765 - val_accuracy: 0.9864\n",
            "Epoch 198/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.1948 - val_accuracy: 0.9808\n",
            "Epoch 199/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.2146 - val_accuracy: 0.9800\n",
            "Epoch 200/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.1335 - val_accuracy: 0.9814\n",
            "Epoch 201/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.1242 - val_accuracy: 0.9837\n",
            "Epoch 202/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.1368 - val_accuracy: 0.9831\n",
            "Epoch 203/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.1283 - val_accuracy: 0.9810\n",
            "Epoch 204/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.2480 - val_accuracy: 0.9744\n",
            "Epoch 205/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0085 - accuracy: 0.9981 - val_loss: 0.1589 - val_accuracy: 0.9814\n",
            "Epoch 206/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.1520 - val_accuracy: 0.9860\n",
            "Epoch 207/250\n",
            "37500/37500 [==============================] - 11s 303us/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.1904 - val_accuracy: 0.9835\n",
            "Epoch 208/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.2282 - val_accuracy: 0.9740\n",
            "Epoch 209/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0134 - accuracy: 0.9966 - val_loss: 0.1302 - val_accuracy: 0.9834\n",
            "Epoch 210/250\n",
            "37500/37500 [==============================] - 11s 302us/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.1655 - val_accuracy: 0.9846\n",
            "Epoch 211/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.1458 - val_accuracy: 0.9815\n",
            "Epoch 212/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.1749 - val_accuracy: 0.9846\n",
            "Epoch 213/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0117 - accuracy: 0.9970 - val_loss: 0.1680 - val_accuracy: 0.9838\n",
            "Epoch 214/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.1363 - val_accuracy: 0.9842\n",
            "Epoch 215/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1341 - val_accuracy: 0.9853\n",
            "Epoch 216/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.2956 - val_accuracy: 0.9716\n",
            "Epoch 217/250\n",
            "37500/37500 [==============================] - 12s 310us/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.2070 - val_accuracy: 0.9810\n",
            "Epoch 218/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.2028 - val_accuracy: 0.9786\n",
            "Epoch 219/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1576 - val_accuracy: 0.9808\n",
            "Epoch 220/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.2150 - val_accuracy: 0.9793\n",
            "Epoch 221/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0126 - accuracy: 0.9971 - val_loss: 0.1652 - val_accuracy: 0.9843\n",
            "Epoch 222/250\n",
            "37500/37500 [==============================] - 11s 307us/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.2453 - val_accuracy: 0.9754\n",
            "Epoch 223/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.2355 - val_accuracy: 0.9778\n",
            "Epoch 224/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.2040 - val_accuracy: 0.9802\n",
            "Epoch 225/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.1635 - val_accuracy: 0.9831\n",
            "Epoch 226/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.1944 - val_accuracy: 0.9758\n",
            "Epoch 227/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.2062 - val_accuracy: 0.9775\n",
            "Epoch 228/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.1698 - val_accuracy: 0.9850\n",
            "Epoch 229/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.1714 - val_accuracy: 0.9818\n",
            "Epoch 230/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.2051 - val_accuracy: 0.9819\n",
            "Epoch 231/250\n",
            "37500/37500 [==============================] - 11s 304us/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.1785 - val_accuracy: 0.9827\n",
            "Epoch 232/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.1443 - val_accuracy: 0.9841\n",
            "Epoch 233/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.2190 - val_accuracy: 0.9785\n",
            "Epoch 234/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.1297 - val_accuracy: 0.9855\n",
            "Epoch 235/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.1678 - val_accuracy: 0.9828\n",
            "Epoch 236/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.1675 - val_accuracy: 0.9820\n",
            "Epoch 237/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.2075 - val_accuracy: 0.9804\n",
            "Epoch 238/250\n",
            "37500/37500 [==============================] - 12s 310us/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.1268 - val_accuracy: 0.9859\n",
            "Epoch 239/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.1879 - val_accuracy: 0.9814\n",
            "Epoch 240/250\n",
            "37500/37500 [==============================] - 12s 307us/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1446 - val_accuracy: 0.9842\n",
            "Epoch 241/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.1424 - val_accuracy: 0.9856\n",
            "Epoch 242/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0068 - accuracy: 0.9984 - val_loss: 0.2534 - val_accuracy: 0.9772\n",
            "Epoch 243/250\n",
            "37500/37500 [==============================] - 12s 309us/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.2897 - val_accuracy: 0.9685\n",
            "Epoch 244/250\n",
            "37500/37500 [==============================] - 12s 311us/step - loss: 0.0133 - accuracy: 0.9967 - val_loss: 0.1499 - val_accuracy: 0.9829\n",
            "Epoch 245/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.1324 - val_accuracy: 0.9826\n",
            "Epoch 246/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.2486 - val_accuracy: 0.9757\n",
            "Epoch 247/250\n",
            "37500/37500 [==============================] - 11s 305us/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.1964 - val_accuracy: 0.9763\n",
            "Epoch 248/250\n",
            "37500/37500 [==============================] - 11s 306us/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.3632 - val_accuracy: 0.9647\n",
            "Epoch 249/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.2523 - val_accuracy: 0.9754\n",
            "Epoch 250/250\n",
            "37500/37500 [==============================] - 12s 308us/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.2166 - val_accuracy: 0.9755\n",
            "Time: \n",
            "2877.539078950882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYZM0kNZQUfR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ecedd306-fc89-407b-c02f-16615119b2a0"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 10K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing test set simulations.\n",
        "t1 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/simModel1.npz\")\n",
        "t2 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/simModel2.npz\")\n",
        "t3 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/simModel3.npz\")\n",
        "t4 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/simModel4.npz\")\n",
        "t5 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/simModel5.npz\")\n",
        "t1 = t1[\"simModel1\"]\n",
        "t2 = t2[\"simModel2\"]\n",
        "t3 = t3[\"simModel3\"]\n",
        "t4 = t4[\"simModel4\"]\n",
        "t5 = t5[\"simModel5\"]\n",
        "x=np.concatenate((t1,t2,t3,t4,t5),axis=0)\n",
        "\n",
        "# Label simulations from the test set.\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y = np.array(y)\n",
        "\n",
        "# Load the trained model.\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod')\n",
        "\n",
        "# Predict and export a confusion matrix.\n",
        "pred = model.predict(x)\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))\n",
        "print (confusion_matrix(y, pred_cat) / float(len(y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 965    0   35    0    0]\n",
            " [   0  978    0   13    9]\n",
            " [   0    0  999    1    0]\n",
            " [   0    0   23  941   36]\n",
            " [   0    0    0    0 1000]]\n",
            "[[0.193  0.     0.007  0.     0.    ]\n",
            " [0.     0.1956 0.     0.0026 0.0018]\n",
            " [0.     0.     0.1998 0.0002 0.    ]\n",
            " [0.     0.     0.0046 0.1882 0.0072]\n",
            " [0.     0.     0.     0.     0.2   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PGIawyJEDo0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c8727c1-fe68-428f-8a8c-74408ebf95f4"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Predict the mos likely model for the empirical data, using the CNN trained with 10K simulations per model.\n",
        "################################################################################################################################################\n",
        "# Load the trained network.\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/Trained_10KSims.acc.mod')\n",
        "# Load empirical data and transpose it.\n",
        "infile=np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/Input_Piloso.txt\")\n",
        "inp=[]\n",
        "inp.append(np.array(infile).T)\n",
        "x = np.array(inp)\n",
        "# Predict the most likely model.\n",
        "pred = model.predict(x)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.3287163e-02 9.4671279e-01 0.0000000e+00 1.4628516e-13 4.1710716e-16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ne-JFcm9eMw",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluate the impact of using different number of simulations to train the network**\n",
        "Below, we repeat the procedures of training and evalutating the CNN, with varying number of simulations (2,500; 1,000 and 500) per model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx3iXPj0Y_n4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b81c8ed4-d3e2-4e61-e443-240c80318d25"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 2.5K simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "x=np.concatenate((u1[0:2500,:,:],u2[0:2500,:,:],u3[0:2500,:,:],u4[0:2500,:,:],u5[0:2500,:,:]),axis=0)\n",
        "\n",
        "y=[0 for i in range(len(u1[0:2500,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:2500,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:2500,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:2500,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:2500,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest))\n",
        "print ('Time: ')\n",
        "print (time.time() - start)\n",
        "\n",
        "cnn.save(filepath='/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12500 12500\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 214, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 213, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 212, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_3 (Average (None, 106, 125)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 106, 125)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 105, 125)          31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_4 (Average (None, 52, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 52, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6500)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 125)               812625    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 630       \n",
            "=================================================================\n",
            "Total params: 955,255\n",
            "Trainable params: 955,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 9375 samples, validate on 3125 samples\n",
            "Epoch 1/250\n",
            "9375/9375 [==============================] - 2s 234us/step - loss: 1.5913 - accuracy: 0.2281 - val_loss: 1.3717 - val_accuracy: 0.3949\n",
            "Epoch 2/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 1.2047 - accuracy: 0.4191 - val_loss: 0.9939 - val_accuracy: 0.4368\n",
            "Epoch 3/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 1.0169 - accuracy: 0.4914 - val_loss: 0.8872 - val_accuracy: 0.5600\n",
            "Epoch 4/250\n",
            "9375/9375 [==============================] - 2s 171us/step - loss: 0.8564 - accuracy: 0.6046 - val_loss: 0.7351 - val_accuracy: 0.6403\n",
            "Epoch 5/250\n",
            "9375/9375 [==============================] - 2s 173us/step - loss: 0.5959 - accuracy: 0.7777 - val_loss: 0.3027 - val_accuracy: 0.9094\n",
            "Epoch 6/250\n",
            "9375/9375 [==============================] - 2s 173us/step - loss: 0.3954 - accuracy: 0.8686 - val_loss: 0.3069 - val_accuracy: 0.8909\n",
            "Epoch 7/250\n",
            "9375/9375 [==============================] - 2s 173us/step - loss: 0.2843 - accuracy: 0.9129 - val_loss: 0.2048 - val_accuracy: 0.9277\n",
            "Epoch 8/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.2458 - accuracy: 0.9263 - val_loss: 0.2013 - val_accuracy: 0.9338\n",
            "Epoch 9/250\n",
            "9375/9375 [==============================] - 2s 171us/step - loss: 0.2287 - accuracy: 0.9340 - val_loss: 0.1548 - val_accuracy: 0.9466\n",
            "Epoch 10/250\n",
            "9375/9375 [==============================] - 2s 173us/step - loss: 0.2028 - accuracy: 0.9413 - val_loss: 0.2640 - val_accuracy: 0.9235\n",
            "Epoch 11/250\n",
            "9375/9375 [==============================] - 2s 171us/step - loss: 0.1805 - accuracy: 0.9476 - val_loss: 0.1751 - val_accuracy: 0.9434\n",
            "Epoch 12/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.1541 - accuracy: 0.9578 - val_loss: 0.1158 - val_accuracy: 0.9658\n",
            "Epoch 13/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.1507 - accuracy: 0.9580 - val_loss: 0.1397 - val_accuracy: 0.9562\n",
            "Epoch 14/250\n",
            "9375/9375 [==============================] - 2s 171us/step - loss: 0.1425 - accuracy: 0.9601 - val_loss: 0.1935 - val_accuracy: 0.9443\n",
            "Epoch 15/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.1480 - accuracy: 0.9594 - val_loss: 0.2865 - val_accuracy: 0.9258\n",
            "Epoch 16/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.1433 - accuracy: 0.9584 - val_loss: 0.1198 - val_accuracy: 0.9654\n",
            "Epoch 17/250\n",
            "9375/9375 [==============================] - 2s 171us/step - loss: 0.1495 - accuracy: 0.9573 - val_loss: 0.1539 - val_accuracy: 0.9510\n",
            "Epoch 18/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.1331 - accuracy: 0.9632 - val_loss: 0.1655 - val_accuracy: 0.9443\n",
            "Epoch 19/250\n",
            "9375/9375 [==============================] - 2s 173us/step - loss: 0.1189 - accuracy: 0.9666 - val_loss: 0.1315 - val_accuracy: 0.9622\n",
            "Epoch 20/250\n",
            "9375/9375 [==============================] - 2s 173us/step - loss: 0.1296 - accuracy: 0.9626 - val_loss: 0.1057 - val_accuracy: 0.9709\n",
            "Epoch 21/250\n",
            "9375/9375 [==============================] - 2s 173us/step - loss: 0.1351 - accuracy: 0.9630 - val_loss: 0.0943 - val_accuracy: 0.9744\n",
            "Epoch 22/250\n",
            "9375/9375 [==============================] - 2s 171us/step - loss: 0.1025 - accuracy: 0.9721 - val_loss: 0.1066 - val_accuracy: 0.9702\n",
            "Epoch 23/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.1040 - accuracy: 0.9712 - val_loss: 0.1301 - val_accuracy: 0.9632\n",
            "Epoch 24/250\n",
            "9375/9375 [==============================] - 2s 173us/step - loss: 0.1049 - accuracy: 0.9724 - val_loss: 0.1187 - val_accuracy: 0.9648\n",
            "Epoch 25/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0990 - accuracy: 0.9744 - val_loss: 0.1215 - val_accuracy: 0.9654\n",
            "Epoch 26/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.0899 - accuracy: 0.9759 - val_loss: 0.2146 - val_accuracy: 0.9469\n",
            "Epoch 27/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0876 - accuracy: 0.9766 - val_loss: 0.1362 - val_accuracy: 0.9616\n",
            "Epoch 28/250\n",
            "9375/9375 [==============================] - 2s 172us/step - loss: 0.0997 - accuracy: 0.9710 - val_loss: 0.0767 - val_accuracy: 0.9766\n",
            "Epoch 29/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0972 - accuracy: 0.9735 - val_loss: 0.1130 - val_accuracy: 0.9654\n",
            "Epoch 30/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0843 - accuracy: 0.9780 - val_loss: 0.1983 - val_accuracy: 0.9507\n",
            "Epoch 31/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0877 - accuracy: 0.9750 - val_loss: 0.1482 - val_accuracy: 0.9606\n",
            "Epoch 32/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0924 - accuracy: 0.9746 - val_loss: 0.1324 - val_accuracy: 0.9619\n",
            "Epoch 33/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0713 - accuracy: 0.9799 - val_loss: 0.0975 - val_accuracy: 0.9738\n",
            "Epoch 34/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0666 - accuracy: 0.9808 - val_loss: 0.1077 - val_accuracy: 0.9747\n",
            "Epoch 35/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0684 - accuracy: 0.9829 - val_loss: 0.0950 - val_accuracy: 0.9757\n",
            "Epoch 36/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0718 - accuracy: 0.9807 - val_loss: 0.1427 - val_accuracy: 0.9635\n",
            "Epoch 37/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0628 - accuracy: 0.9833 - val_loss: 0.1475 - val_accuracy: 0.9667\n",
            "Epoch 38/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0676 - accuracy: 0.9826 - val_loss: 0.1976 - val_accuracy: 0.9539\n",
            "Epoch 39/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0690 - accuracy: 0.9837 - val_loss: 0.1171 - val_accuracy: 0.9731\n",
            "Epoch 40/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0610 - accuracy: 0.9853 - val_loss: 0.2039 - val_accuracy: 0.9555\n",
            "Epoch 41/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0695 - accuracy: 0.9813 - val_loss: 0.1016 - val_accuracy: 0.9741\n",
            "Epoch 42/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0751 - accuracy: 0.9807 - val_loss: 0.1008 - val_accuracy: 0.9706\n",
            "Epoch 43/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0677 - accuracy: 0.9808 - val_loss: 0.0874 - val_accuracy: 0.9773\n",
            "Epoch 44/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0533 - accuracy: 0.9860 - val_loss: 0.1088 - val_accuracy: 0.9750\n",
            "Epoch 45/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0629 - accuracy: 0.9830 - val_loss: 0.2930 - val_accuracy: 0.9370\n",
            "Epoch 46/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0584 - accuracy: 0.9856 - val_loss: 0.1209 - val_accuracy: 0.9683\n",
            "Epoch 47/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0601 - accuracy: 0.9841 - val_loss: 0.0875 - val_accuracy: 0.9795\n",
            "Epoch 48/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0583 - accuracy: 0.9850 - val_loss: 0.1155 - val_accuracy: 0.9770\n",
            "Epoch 49/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0488 - accuracy: 0.9863 - val_loss: 0.0879 - val_accuracy: 0.9814\n",
            "Epoch 50/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0502 - accuracy: 0.9877 - val_loss: 0.1157 - val_accuracy: 0.9747\n",
            "Epoch 51/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0440 - accuracy: 0.9881 - val_loss: 0.3416 - val_accuracy: 0.9402\n",
            "Epoch 52/250\n",
            "9375/9375 [==============================] - 2s 181us/step - loss: 0.0534 - accuracy: 0.9867 - val_loss: 0.3601 - val_accuracy: 0.9408\n",
            "Epoch 53/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0748 - accuracy: 0.9810 - val_loss: 0.1187 - val_accuracy: 0.9709\n",
            "Epoch 54/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0469 - accuracy: 0.9876 - val_loss: 0.1300 - val_accuracy: 0.9699\n",
            "Epoch 55/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0450 - accuracy: 0.9881 - val_loss: 0.1051 - val_accuracy: 0.9776\n",
            "Epoch 56/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0392 - accuracy: 0.9899 - val_loss: 0.1405 - val_accuracy: 0.9754\n",
            "Epoch 57/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0485 - accuracy: 0.9866 - val_loss: 0.1359 - val_accuracy: 0.9718\n",
            "Epoch 58/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0433 - accuracy: 0.9881 - val_loss: 0.0879 - val_accuracy: 0.9795\n",
            "Epoch 59/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0463 - accuracy: 0.9874 - val_loss: 0.2469 - val_accuracy: 0.9475\n",
            "Epoch 60/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0494 - accuracy: 0.9884 - val_loss: 0.1142 - val_accuracy: 0.9734\n",
            "Epoch 61/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0380 - accuracy: 0.9898 - val_loss: 0.1356 - val_accuracy: 0.9709\n",
            "Epoch 62/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0344 - accuracy: 0.9923 - val_loss: 0.1614 - val_accuracy: 0.9690\n",
            "Epoch 63/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0361 - accuracy: 0.9909 - val_loss: 0.2259 - val_accuracy: 0.9581\n",
            "Epoch 64/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0545 - accuracy: 0.9849 - val_loss: 0.0808 - val_accuracy: 0.9824\n",
            "Epoch 65/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0565 - accuracy: 0.9847 - val_loss: 0.1552 - val_accuracy: 0.9648\n",
            "Epoch 66/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0416 - accuracy: 0.9901 - val_loss: 0.1484 - val_accuracy: 0.9629\n",
            "Epoch 67/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0385 - accuracy: 0.9908 - val_loss: 0.0979 - val_accuracy: 0.9786\n",
            "Epoch 68/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0308 - accuracy: 0.9920 - val_loss: 0.1535 - val_accuracy: 0.9670\n",
            "Epoch 69/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0428 - accuracy: 0.9888 - val_loss: 0.1148 - val_accuracy: 0.9728\n",
            "Epoch 70/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0484 - accuracy: 0.9867 - val_loss: 0.1075 - val_accuracy: 0.9754\n",
            "Epoch 71/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0361 - accuracy: 0.9907 - val_loss: 0.1134 - val_accuracy: 0.9750\n",
            "Epoch 72/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0331 - accuracy: 0.9907 - val_loss: 0.1665 - val_accuracy: 0.9667\n",
            "Epoch 73/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0309 - accuracy: 0.9914 - val_loss: 0.1186 - val_accuracy: 0.9715\n",
            "Epoch 74/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0265 - accuracy: 0.9924 - val_loss: 0.1323 - val_accuracy: 0.9773\n",
            "Epoch 75/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0401 - accuracy: 0.9903 - val_loss: 0.1470 - val_accuracy: 0.9722\n",
            "Epoch 76/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0428 - accuracy: 0.9903 - val_loss: 0.2646 - val_accuracy: 0.9443\n",
            "Epoch 77/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 0.1100 - val_accuracy: 0.9782\n",
            "Epoch 78/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0225 - accuracy: 0.9940 - val_loss: 0.2136 - val_accuracy: 0.9568\n",
            "Epoch 79/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0567 - accuracy: 0.9855 - val_loss: 0.0825 - val_accuracy: 0.9827\n",
            "Epoch 80/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0287 - accuracy: 0.9924 - val_loss: 0.1446 - val_accuracy: 0.9677\n",
            "Epoch 81/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0236 - accuracy: 0.9939 - val_loss: 0.1613 - val_accuracy: 0.9702\n",
            "Epoch 82/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0348 - accuracy: 0.9900 - val_loss: 0.1074 - val_accuracy: 0.9789\n",
            "Epoch 83/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0274 - accuracy: 0.9919 - val_loss: 0.1663 - val_accuracy: 0.9648\n",
            "Epoch 84/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0232 - accuracy: 0.9943 - val_loss: 0.1366 - val_accuracy: 0.9766\n",
            "Epoch 85/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.1798 - val_accuracy: 0.9670\n",
            "Epoch 86/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0410 - accuracy: 0.9899 - val_loss: 0.1046 - val_accuracy: 0.9776\n",
            "Epoch 87/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 0.4330 - val_accuracy: 0.9338\n",
            "Epoch 88/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 0.1479 - val_accuracy: 0.9709\n",
            "Epoch 89/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.2158 - val_accuracy: 0.9622\n",
            "Epoch 90/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0334 - accuracy: 0.9923 - val_loss: 0.2714 - val_accuracy: 0.9482\n",
            "Epoch 91/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0272 - accuracy: 0.9924 - val_loss: 0.1422 - val_accuracy: 0.9696\n",
            "Epoch 92/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.1406 - val_accuracy: 0.9680\n",
            "Epoch 93/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 0.1078 - val_accuracy: 0.9782\n",
            "Epoch 94/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0254 - accuracy: 0.9932 - val_loss: 0.1260 - val_accuracy: 0.9741\n",
            "Epoch 95/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.1282 - val_accuracy: 0.9782\n",
            "Epoch 96/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.1775 - val_accuracy: 0.9661\n",
            "Epoch 97/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.1581 - val_accuracy: 0.9744\n",
            "Epoch 98/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0140 - accuracy: 0.9963 - val_loss: 0.2159 - val_accuracy: 0.9645\n",
            "Epoch 99/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0183 - accuracy: 0.9952 - val_loss: 0.1137 - val_accuracy: 0.9821\n",
            "Epoch 100/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0260 - accuracy: 0.9931 - val_loss: 0.6207 - val_accuracy: 0.9162\n",
            "Epoch 101/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.1430 - val_accuracy: 0.9699\n",
            "Epoch 102/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0303 - accuracy: 0.9923 - val_loss: 0.0966 - val_accuracy: 0.9798\n",
            "Epoch 103/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0143 - accuracy: 0.9967 - val_loss: 0.1433 - val_accuracy: 0.9760\n",
            "Epoch 104/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.1070 - val_accuracy: 0.9824\n",
            "Epoch 105/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.1683 - val_accuracy: 0.9674\n",
            "Epoch 106/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.1680 - val_accuracy: 0.9709\n",
            "Epoch 107/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.1534 - val_accuracy: 0.9744\n",
            "Epoch 108/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 0.1705 - val_accuracy: 0.9661\n",
            "Epoch 109/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.1439 - val_accuracy: 0.9741\n",
            "Epoch 110/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.1244 - val_accuracy: 0.9795\n",
            "Epoch 111/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.1493 - val_accuracy: 0.9718\n",
            "Epoch 112/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.1867 - val_accuracy: 0.9693\n",
            "Epoch 113/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.1900 - val_accuracy: 0.9638\n",
            "Epoch 114/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0230 - accuracy: 0.9936 - val_loss: 0.1214 - val_accuracy: 0.9802\n",
            "Epoch 115/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.1383 - val_accuracy: 0.9811\n",
            "Epoch 116/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.1446 - val_accuracy: 0.9741\n",
            "Epoch 117/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.1623 - val_accuracy: 0.9763\n",
            "Epoch 118/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0194 - accuracy: 0.9950 - val_loss: 0.1574 - val_accuracy: 0.9766\n",
            "Epoch 119/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.3212 - val_accuracy: 0.9526\n",
            "Epoch 120/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.1592 - val_accuracy: 0.9738\n",
            "Epoch 121/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.1862 - val_accuracy: 0.9770\n",
            "Epoch 122/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0219 - accuracy: 0.9947 - val_loss: 0.1605 - val_accuracy: 0.9738\n",
            "Epoch 123/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0260 - accuracy: 0.9926 - val_loss: 0.1063 - val_accuracy: 0.9814\n",
            "Epoch 124/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 0.2526 - val_accuracy: 0.9578\n",
            "Epoch 125/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.1400 - val_accuracy: 0.9757\n",
            "Epoch 126/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.2541 - val_accuracy: 0.9597\n",
            "Epoch 127/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.1741 - val_accuracy: 0.9763\n",
            "Epoch 128/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.1745 - val_accuracy: 0.9731\n",
            "Epoch 129/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.2036 - val_accuracy: 0.9712\n",
            "Epoch 130/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.1831 - val_accuracy: 0.9722\n",
            "Epoch 131/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.1915 - val_accuracy: 0.9763\n",
            "Epoch 132/250\n",
            "9375/9375 [==============================] - 2s 179us/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.1586 - val_accuracy: 0.9776\n",
            "Epoch 133/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0132 - accuracy: 0.9961 - val_loss: 0.1742 - val_accuracy: 0.9728\n",
            "Epoch 134/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.2692 - val_accuracy: 0.9462\n",
            "Epoch 135/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.1517 - val_accuracy: 0.9696\n",
            "Epoch 136/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.2751 - val_accuracy: 0.9530\n",
            "Epoch 137/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.1731 - val_accuracy: 0.9795\n",
            "Epoch 138/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.1722 - val_accuracy: 0.9782\n",
            "Epoch 139/250\n",
            "9375/9375 [==============================] - 2s 179us/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.1646 - val_accuracy: 0.9818\n",
            "Epoch 140/250\n",
            "9375/9375 [==============================] - 2s 179us/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.1528 - val_accuracy: 0.9760\n",
            "Epoch 141/250\n",
            "9375/9375 [==============================] - 2s 179us/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1501 - val_accuracy: 0.9763\n",
            "Epoch 142/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.1783 - val_accuracy: 0.9702\n",
            "Epoch 143/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.1401 - val_accuracy: 0.9792\n",
            "Epoch 144/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.1725 - val_accuracy: 0.9776\n",
            "Epoch 145/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.3411 - val_accuracy: 0.9526\n",
            "Epoch 146/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.1436 - val_accuracy: 0.9830\n",
            "Epoch 147/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.2411 - val_accuracy: 0.9654\n",
            "Epoch 148/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1853 - val_accuracy: 0.9766\n",
            "Epoch 149/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.2236 - val_accuracy: 0.9651\n",
            "Epoch 150/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0261 - accuracy: 0.9943 - val_loss: 0.2272 - val_accuracy: 0.9693\n",
            "Epoch 151/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.2368 - val_accuracy: 0.9616\n",
            "Epoch 152/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.1960 - val_accuracy: 0.9690\n",
            "Epoch 153/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.2221 - val_accuracy: 0.9770\n",
            "Epoch 154/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.1257 - val_accuracy: 0.9808\n",
            "Epoch 155/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.1893 - val_accuracy: 0.9706\n",
            "Epoch 156/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.1663 - val_accuracy: 0.9747\n",
            "Epoch 157/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.1953 - val_accuracy: 0.9677\n",
            "Epoch 158/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1923 - val_accuracy: 0.9741\n",
            "Epoch 159/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 0.1899 - val_accuracy: 0.9757\n",
            "Epoch 160/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 0.1378 - val_accuracy: 0.9827\n",
            "Epoch 161/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1510 - val_accuracy: 0.9782\n",
            "Epoch 162/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.3174 - val_accuracy: 0.9613\n",
            "Epoch 163/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.1812 - val_accuracy: 0.9661\n",
            "Epoch 164/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.1933 - val_accuracy: 0.9677\n",
            "Epoch 165/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.2225 - val_accuracy: 0.9645\n",
            "Epoch 166/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.2420 - val_accuracy: 0.9690\n",
            "Epoch 167/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.2247 - val_accuracy: 0.9728\n",
            "Epoch 168/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.2503 - val_accuracy: 0.9677\n",
            "Epoch 169/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.1678 - val_accuracy: 0.9792\n",
            "Epoch 170/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.2769 - val_accuracy: 0.9616\n",
            "Epoch 171/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.1765 - val_accuracy: 0.9798\n",
            "Epoch 172/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.1614 - val_accuracy: 0.9808\n",
            "Epoch 173/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.2188 - val_accuracy: 0.9744\n",
            "Epoch 174/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.1866 - val_accuracy: 0.9792\n",
            "Epoch 175/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0068 - accuracy: 0.9971 - val_loss: 0.2615 - val_accuracy: 0.9658\n",
            "Epoch 176/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.1848 - val_accuracy: 0.9824\n",
            "Epoch 177/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 0.2113 - val_accuracy: 0.9651\n",
            "Epoch 178/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0104 - accuracy: 0.9980 - val_loss: 0.2701 - val_accuracy: 0.9683\n",
            "Epoch 179/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1792 - val_accuracy: 0.9776\n",
            "Epoch 180/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.2132 - val_accuracy: 0.9747\n",
            "Epoch 181/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1617 - val_accuracy: 0.9795\n",
            "Epoch 182/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.2841 - val_accuracy: 0.9626\n",
            "Epoch 183/250\n",
            "9375/9375 [==============================] - 2s 179us/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.1690 - val_accuracy: 0.9731\n",
            "Epoch 184/250\n",
            "9375/9375 [==============================] - 2s 181us/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.3624 - val_accuracy: 0.9466\n",
            "Epoch 185/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0596 - accuracy: 0.9867 - val_loss: 0.1616 - val_accuracy: 0.9779\n",
            "Epoch 186/250\n",
            "9375/9375 [==============================] - 2s 179us/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.1917 - val_accuracy: 0.9638\n",
            "Epoch 187/250\n",
            "9375/9375 [==============================] - 2s 180us/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.2000 - val_accuracy: 0.9696\n",
            "Epoch 188/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.2050 - val_accuracy: 0.9645\n",
            "Epoch 189/250\n",
            "9375/9375 [==============================] - 2s 180us/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.2650 - val_accuracy: 0.9619\n",
            "Epoch 190/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1712 - val_accuracy: 0.9776\n",
            "Epoch 191/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.2576 - val_accuracy: 0.9606\n",
            "Epoch 192/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.2692 - val_accuracy: 0.9619\n",
            "Epoch 193/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.1883 - val_accuracy: 0.9776\n",
            "Epoch 194/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.2200 - val_accuracy: 0.9734\n",
            "Epoch 195/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.1938 - val_accuracy: 0.9792\n",
            "Epoch 196/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.1989 - val_accuracy: 0.9789\n",
            "Epoch 197/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0126 - accuracy: 0.9970 - val_loss: 0.3462 - val_accuracy: 0.9581\n",
            "Epoch 198/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1802 - val_accuracy: 0.9770\n",
            "Epoch 199/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.2279 - val_accuracy: 0.9747\n",
            "Epoch 200/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.2157 - val_accuracy: 0.9670\n",
            "Epoch 201/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.1993 - val_accuracy: 0.9699\n",
            "Epoch 202/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.3211 - val_accuracy: 0.9571\n",
            "Epoch 203/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1887 - val_accuracy: 0.9802\n",
            "Epoch 204/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.1728 - val_accuracy: 0.9779\n",
            "Epoch 205/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.3174 - val_accuracy: 0.9546\n",
            "Epoch 206/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1848 - val_accuracy: 0.9830\n",
            "Epoch 207/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.2209 - val_accuracy: 0.9709\n",
            "Epoch 208/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1824 - val_accuracy: 0.9824\n",
            "Epoch 209/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0147 - accuracy: 0.9969 - val_loss: 0.2654 - val_accuracy: 0.9747\n",
            "Epoch 210/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.2499 - val_accuracy: 0.9706\n",
            "Epoch 211/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.2535 - val_accuracy: 0.9715\n",
            "Epoch 212/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.2306 - val_accuracy: 0.9757\n",
            "Epoch 213/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.2176 - val_accuracy: 0.9715\n",
            "Epoch 214/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.2168 - val_accuracy: 0.9782\n",
            "Epoch 215/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.2215 - val_accuracy: 0.9766\n",
            "Epoch 216/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.3230 - val_accuracy: 0.9667\n",
            "Epoch 217/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.1790 - val_accuracy: 0.9731\n",
            "Epoch 218/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.1892 - val_accuracy: 0.9699\n",
            "Epoch 219/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.2036 - val_accuracy: 0.9738\n",
            "Epoch 220/250\n",
            "9375/9375 [==============================] - 2s 186us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.2036 - val_accuracy: 0.9744\n",
            "Epoch 221/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.2127 - val_accuracy: 0.9779\n",
            "Epoch 222/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0101 - accuracy: 0.9971 - val_loss: 0.2342 - val_accuracy: 0.9747\n",
            "Epoch 223/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.2623 - val_accuracy: 0.9709\n",
            "Epoch 224/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0239 - accuracy: 0.9959 - val_loss: 0.2963 - val_accuracy: 0.9696\n",
            "Epoch 225/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.2212 - val_accuracy: 0.9702\n",
            "Epoch 226/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.2113 - val_accuracy: 0.9686\n",
            "Epoch 227/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1658 - val_accuracy: 0.9754\n",
            "Epoch 228/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.1944 - val_accuracy: 0.9766\n",
            "Epoch 229/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1772 - val_accuracy: 0.9824\n",
            "Epoch 230/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.3453 - val_accuracy: 0.9510\n",
            "Epoch 231/250\n",
            "9375/9375 [==============================] - 2s 178us/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.2900 - val_accuracy: 0.9763\n",
            "Epoch 232/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.2220 - val_accuracy: 0.9760\n",
            "Epoch 233/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.2945 - val_accuracy: 0.9533\n",
            "Epoch 234/250\n",
            "9375/9375 [==============================] - 2s 174us/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.1789 - val_accuracy: 0.9725\n",
            "Epoch 235/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.1848 - val_accuracy: 0.9725\n",
            "Epoch 236/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.2559 - val_accuracy: 0.9747\n",
            "Epoch 237/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.2263 - val_accuracy: 0.9702\n",
            "Epoch 238/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.2636 - val_accuracy: 0.9638\n",
            "Epoch 239/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.2265 - val_accuracy: 0.9715\n",
            "Epoch 240/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.2686 - val_accuracy: 0.9622\n",
            "Epoch 241/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.2539 - val_accuracy: 0.9686\n",
            "Epoch 242/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.2587 - val_accuracy: 0.9680\n",
            "Epoch 243/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.2087 - val_accuracy: 0.9773\n",
            "Epoch 244/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.2335 - val_accuracy: 0.9734\n",
            "Epoch 245/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0241 - accuracy: 0.9936 - val_loss: 0.3664 - val_accuracy: 0.9507\n",
            "Epoch 246/250\n",
            "9375/9375 [==============================] - 2s 176us/step - loss: 0.0658 - accuracy: 0.9825 - val_loss: 0.2340 - val_accuracy: 0.9642\n",
            "Epoch 247/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 0.2146 - val_accuracy: 0.9722\n",
            "Epoch 248/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.1847 - val_accuracy: 0.9798\n",
            "Epoch 249/250\n",
            "9375/9375 [==============================] - 2s 177us/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.2303 - val_accuracy: 0.9648\n",
            "Epoch 250/250\n",
            "9375/9375 [==============================] - 2s 175us/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.2098 - val_accuracy: 0.9728\n",
            "Time: \n",
            "413.65623354911804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0StnjUKSv4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9965083-741f-4b7e-a741-610a2d2edb9d"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 1K simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "\n",
        "x=np.concatenate((u1[0:1000,:,:],u2[0:1000,:,:],u3[0:1000,:,:],u4[0:1000,:,:],u5[0:1000,:,:]),axis=0)\n",
        "\n",
        "\n",
        "\n",
        "y=[0 for i in range(len(u1[0:1000,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:1000,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:1000,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:1000,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:1000,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest))\n",
        "print ('Time: ')\n",
        "print (time.time() - start)\n",
        "\n",
        "cnn.save(filepath='/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000 5000\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 214, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 213, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 212, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_5 (Average (None, 106, 125)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 106, 125)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 105, 125)          31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_6 (Average (None, 52, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 52, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6500)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 125)               812625    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 630       \n",
            "=================================================================\n",
            "Total params: 955,255\n",
            "Trainable params: 955,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 3750 samples, validate on 1250 samples\n",
            "Epoch 1/250\n",
            "3750/3750 [==============================] - 1s 226us/step - loss: 1.6411 - accuracy: 0.1923 - val_loss: 1.6018 - val_accuracy: 0.1872\n",
            "Epoch 2/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 1.5845 - accuracy: 0.2189 - val_loss: 1.5549 - val_accuracy: 0.3112\n",
            "Epoch 3/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 1.4549 - accuracy: 0.2952 - val_loss: 1.3868 - val_accuracy: 0.4080\n",
            "Epoch 4/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 1.2916 - accuracy: 0.4176 - val_loss: 1.1478 - val_accuracy: 0.4544\n",
            "Epoch 5/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 1.1713 - accuracy: 0.4325 - val_loss: 1.0594 - val_accuracy: 0.4504\n",
            "Epoch 6/250\n",
            "3750/3750 [==============================] - 1s 162us/step - loss: 1.0859 - accuracy: 0.4475 - val_loss: 0.9943 - val_accuracy: 0.5792\n",
            "Epoch 7/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 1.0414 - accuracy: 0.4827 - val_loss: 0.9700 - val_accuracy: 0.4936\n",
            "Epoch 8/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 1.0121 - accuracy: 0.5083 - val_loss: 0.9154 - val_accuracy: 0.5504\n",
            "Epoch 9/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.9588 - accuracy: 0.5424 - val_loss: 0.8971 - val_accuracy: 0.5552\n",
            "Epoch 10/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.8870 - accuracy: 0.5936 - val_loss: 0.8208 - val_accuracy: 0.5824\n",
            "Epoch 11/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.7847 - accuracy: 0.6525 - val_loss: 0.7114 - val_accuracy: 0.6728\n",
            "Epoch 12/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.6905 - accuracy: 0.7152 - val_loss: 0.6168 - val_accuracy: 0.7296\n",
            "Epoch 13/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.5512 - accuracy: 0.7904 - val_loss: 0.5416 - val_accuracy: 0.7976\n",
            "Epoch 14/250\n",
            "3750/3750 [==============================] - 1s 150us/step - loss: 0.4626 - accuracy: 0.8352 - val_loss: 0.4849 - val_accuracy: 0.8304\n",
            "Epoch 15/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.3852 - accuracy: 0.8773 - val_loss: 0.5125 - val_accuracy: 0.8296\n",
            "Epoch 16/250\n",
            "3750/3750 [==============================] - 1s 150us/step - loss: 0.3564 - accuracy: 0.8867 - val_loss: 0.3573 - val_accuracy: 0.8808\n",
            "Epoch 17/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.3144 - accuracy: 0.9024 - val_loss: 0.5254 - val_accuracy: 0.8448\n",
            "Epoch 18/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.2950 - accuracy: 0.9045 - val_loss: 0.2447 - val_accuracy: 0.9144\n",
            "Epoch 19/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.2630 - accuracy: 0.9189 - val_loss: 0.2272 - val_accuracy: 0.9248\n",
            "Epoch 20/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.2686 - accuracy: 0.9205 - val_loss: 0.1419 - val_accuracy: 0.9552\n",
            "Epoch 21/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.2447 - accuracy: 0.9288 - val_loss: 0.1372 - val_accuracy: 0.9608\n",
            "Epoch 22/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.2278 - accuracy: 0.9355 - val_loss: 0.1324 - val_accuracy: 0.9536\n",
            "Epoch 23/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1883 - accuracy: 0.9437 - val_loss: 0.3829 - val_accuracy: 0.8992\n",
            "Epoch 24/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1890 - accuracy: 0.9424 - val_loss: 0.2902 - val_accuracy: 0.9176\n",
            "Epoch 25/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1718 - accuracy: 0.9493 - val_loss: 0.4376 - val_accuracy: 0.8936\n",
            "Epoch 26/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.1606 - accuracy: 0.9523 - val_loss: 0.2983 - val_accuracy: 0.9240\n",
            "Epoch 27/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.1753 - accuracy: 0.9509 - val_loss: 0.2152 - val_accuracy: 0.9376\n",
            "Epoch 28/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.1497 - accuracy: 0.9571 - val_loss: 0.2299 - val_accuracy: 0.9352\n",
            "Epoch 29/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.1538 - accuracy: 0.9541 - val_loss: 0.1403 - val_accuracy: 0.9616\n",
            "Epoch 30/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.1605 - accuracy: 0.9504 - val_loss: 0.2446 - val_accuracy: 0.9328\n",
            "Epoch 31/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.1423 - accuracy: 0.9589 - val_loss: 0.1710 - val_accuracy: 0.9504\n",
            "Epoch 32/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.1249 - accuracy: 0.9600 - val_loss: 0.1363 - val_accuracy: 0.9608\n",
            "Epoch 33/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.1346 - accuracy: 0.9616 - val_loss: 0.2266 - val_accuracy: 0.9432\n",
            "Epoch 34/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.1285 - accuracy: 0.9645 - val_loss: 0.2466 - val_accuracy: 0.9368\n",
            "Epoch 35/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1301 - accuracy: 0.9621 - val_loss: 0.3862 - val_accuracy: 0.9248\n",
            "Epoch 36/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1255 - accuracy: 0.9611 - val_loss: 0.1702 - val_accuracy: 0.9552\n",
            "Epoch 37/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1222 - accuracy: 0.9621 - val_loss: 0.3649 - val_accuracy: 0.9240\n",
            "Epoch 38/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.1180 - accuracy: 0.9696 - val_loss: 0.3177 - val_accuracy: 0.9296\n",
            "Epoch 39/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1127 - accuracy: 0.9683 - val_loss: 0.2818 - val_accuracy: 0.9416\n",
            "Epoch 40/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1214 - accuracy: 0.9608 - val_loss: 0.4706 - val_accuracy: 0.9096\n",
            "Epoch 41/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1247 - accuracy: 0.9648 - val_loss: 0.4015 - val_accuracy: 0.9200\n",
            "Epoch 42/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.1084 - accuracy: 0.9680 - val_loss: 0.4349 - val_accuracy: 0.9240\n",
            "Epoch 43/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0886 - accuracy: 0.9731 - val_loss: 0.1466 - val_accuracy: 0.9616\n",
            "Epoch 44/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.1076 - accuracy: 0.9691 - val_loss: 0.3895 - val_accuracy: 0.9256\n",
            "Epoch 45/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.1172 - accuracy: 0.9653 - val_loss: 0.4245 - val_accuracy: 0.9184\n",
            "Epoch 46/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.1096 - accuracy: 0.9707 - val_loss: 0.1628 - val_accuracy: 0.9584\n",
            "Epoch 47/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0887 - accuracy: 0.9755 - val_loss: 0.2939 - val_accuracy: 0.9352\n",
            "Epoch 48/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0814 - accuracy: 0.9760 - val_loss: 0.1739 - val_accuracy: 0.9576\n",
            "Epoch 49/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0777 - accuracy: 0.9787 - val_loss: 0.3952 - val_accuracy: 0.9344\n",
            "Epoch 50/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0865 - accuracy: 0.9755 - val_loss: 0.5000 - val_accuracy: 0.9160\n",
            "Epoch 51/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0835 - accuracy: 0.9781 - val_loss: 0.1360 - val_accuracy: 0.9592\n",
            "Epoch 52/250\n",
            "3750/3750 [==============================] - 1s 150us/step - loss: 0.0907 - accuracy: 0.9768 - val_loss: 0.3726 - val_accuracy: 0.9328\n",
            "Epoch 53/250\n",
            "3750/3750 [==============================] - 1s 157us/step - loss: 0.0717 - accuracy: 0.9800 - val_loss: 0.2604 - val_accuracy: 0.9480\n",
            "Epoch 54/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.3185 - val_accuracy: 0.9400\n",
            "Epoch 55/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0645 - accuracy: 0.9795 - val_loss: 0.2035 - val_accuracy: 0.9544\n",
            "Epoch 56/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0665 - accuracy: 0.9829 - val_loss: 0.4277 - val_accuracy: 0.9336\n",
            "Epoch 57/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0821 - accuracy: 0.9768 - val_loss: 0.1614 - val_accuracy: 0.9592\n",
            "Epoch 58/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0559 - accuracy: 0.9848 - val_loss: 0.2839 - val_accuracy: 0.9424\n",
            "Epoch 59/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0528 - accuracy: 0.9861 - val_loss: 0.1553 - val_accuracy: 0.9632\n",
            "Epoch 60/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0759 - accuracy: 0.9800 - val_loss: 0.2487 - val_accuracy: 0.9520\n",
            "Epoch 61/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0808 - accuracy: 0.9757 - val_loss: 0.4100 - val_accuracy: 0.9280\n",
            "Epoch 62/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0752 - accuracy: 0.9779 - val_loss: 0.1738 - val_accuracy: 0.9568\n",
            "Epoch 63/250\n",
            "3750/3750 [==============================] - 1s 158us/step - loss: 0.0536 - accuracy: 0.9867 - val_loss: 0.1571 - val_accuracy: 0.9640\n",
            "Epoch 64/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0629 - accuracy: 0.9843 - val_loss: 0.2701 - val_accuracy: 0.9528\n",
            "Epoch 65/250\n",
            "3750/3750 [==============================] - 1s 158us/step - loss: 0.0761 - accuracy: 0.9792 - val_loss: 0.1871 - val_accuracy: 0.9568\n",
            "Epoch 66/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0740 - accuracy: 0.9795 - val_loss: 0.3824 - val_accuracy: 0.9296\n",
            "Epoch 67/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0652 - accuracy: 0.9803 - val_loss: 0.1968 - val_accuracy: 0.9544\n",
            "Epoch 68/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0586 - accuracy: 0.9832 - val_loss: 0.4298 - val_accuracy: 0.9320\n",
            "Epoch 69/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0609 - accuracy: 0.9853 - val_loss: 0.1001 - val_accuracy: 0.9752\n",
            "Epoch 70/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0717 - accuracy: 0.9803 - val_loss: 0.3450 - val_accuracy: 0.9264\n",
            "Epoch 71/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.2786 - val_accuracy: 0.9464\n",
            "Epoch 72/250\n",
            "3750/3750 [==============================] - 1s 157us/step - loss: 0.0582 - accuracy: 0.9859 - val_loss: 0.2493 - val_accuracy: 0.9544\n",
            "Epoch 73/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0526 - accuracy: 0.9856 - val_loss: 0.1676 - val_accuracy: 0.9656\n",
            "Epoch 74/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0443 - accuracy: 0.9861 - val_loss: 0.3615 - val_accuracy: 0.9440\n",
            "Epoch 75/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0481 - accuracy: 0.9869 - val_loss: 0.3674 - val_accuracy: 0.9424\n",
            "Epoch 76/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0456 - accuracy: 0.9885 - val_loss: 0.1814 - val_accuracy: 0.9672\n",
            "Epoch 77/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0515 - accuracy: 0.9861 - val_loss: 0.1620 - val_accuracy: 0.9672\n",
            "Epoch 78/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0836 - accuracy: 0.9773 - val_loss: 0.6794 - val_accuracy: 0.8904\n",
            "Epoch 79/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0986 - accuracy: 0.9693 - val_loss: 0.2833 - val_accuracy: 0.9352\n",
            "Epoch 80/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0530 - accuracy: 0.9845 - val_loss: 0.3983 - val_accuracy: 0.9248\n",
            "Epoch 81/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0484 - accuracy: 0.9848 - val_loss: 0.2245 - val_accuracy: 0.9544\n",
            "Epoch 82/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0572 - accuracy: 0.9848 - val_loss: 0.1380 - val_accuracy: 0.9648\n",
            "Epoch 83/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0486 - accuracy: 0.9875 - val_loss: 0.1075 - val_accuracy: 0.9776\n",
            "Epoch 84/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0498 - accuracy: 0.9859 - val_loss: 0.1848 - val_accuracy: 0.9536\n",
            "Epoch 85/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0437 - accuracy: 0.9872 - val_loss: 0.3563 - val_accuracy: 0.9376\n",
            "Epoch 86/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0462 - accuracy: 0.9875 - val_loss: 0.4368 - val_accuracy: 0.9248\n",
            "Epoch 87/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0407 - accuracy: 0.9901 - val_loss: 0.2138 - val_accuracy: 0.9520\n",
            "Epoch 88/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0396 - accuracy: 0.9888 - val_loss: 0.1972 - val_accuracy: 0.9544\n",
            "Epoch 89/250\n",
            "3750/3750 [==============================] - 1s 150us/step - loss: 0.0414 - accuracy: 0.9877 - val_loss: 0.6252 - val_accuracy: 0.9072\n",
            "Epoch 90/250\n",
            "3750/3750 [==============================] - 1s 157us/step - loss: 0.0490 - accuracy: 0.9867 - val_loss: 0.2019 - val_accuracy: 0.9616\n",
            "Epoch 91/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0559 - accuracy: 0.9853 - val_loss: 0.3709 - val_accuracy: 0.9400\n",
            "Epoch 92/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0461 - accuracy: 0.9891 - val_loss: 0.2271 - val_accuracy: 0.9568\n",
            "Epoch 93/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.2247 - val_accuracy: 0.9576\n",
            "Epoch 94/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0380 - accuracy: 0.9896 - val_loss: 0.1497 - val_accuracy: 0.9728\n",
            "Epoch 95/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0278 - accuracy: 0.9920 - val_loss: 0.2124 - val_accuracy: 0.9616\n",
            "Epoch 96/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.4699 - val_accuracy: 0.9360\n",
            "Epoch 97/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0298 - accuracy: 0.9901 - val_loss: 0.2859 - val_accuracy: 0.9528\n",
            "Epoch 98/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 0.2986 - val_accuracy: 0.9520\n",
            "Epoch 99/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0229 - accuracy: 0.9941 - val_loss: 0.4448 - val_accuracy: 0.9352\n",
            "Epoch 100/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0320 - accuracy: 0.9899 - val_loss: 0.3877 - val_accuracy: 0.9432\n",
            "Epoch 101/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 0.1345 - val_accuracy: 0.9752\n",
            "Epoch 102/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0321 - accuracy: 0.9904 - val_loss: 0.2077 - val_accuracy: 0.9584\n",
            "Epoch 103/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.5529 - val_accuracy: 0.9184\n",
            "Epoch 104/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.3057 - val_accuracy: 0.9528\n",
            "Epoch 105/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 0.2751 - val_accuracy: 0.9520\n",
            "Epoch 106/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0296 - accuracy: 0.9915 - val_loss: 0.3379 - val_accuracy: 0.9456\n",
            "Epoch 107/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.2090 - val_accuracy: 0.9632\n",
            "Epoch 108/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.1994 - val_accuracy: 0.9632\n",
            "Epoch 109/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0220 - accuracy: 0.9933 - val_loss: 0.1720 - val_accuracy: 0.9728\n",
            "Epoch 110/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0175 - accuracy: 0.9955 - val_loss: 0.3298 - val_accuracy: 0.9512\n",
            "Epoch 111/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.2628 - val_accuracy: 0.9600\n",
            "Epoch 112/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0307 - accuracy: 0.9936 - val_loss: 0.4877 - val_accuracy: 0.9376\n",
            "Epoch 113/250\n",
            "3750/3750 [==============================] - 1s 157us/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.2248 - val_accuracy: 0.9640\n",
            "Epoch 114/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0275 - accuracy: 0.9936 - val_loss: 0.2592 - val_accuracy: 0.9568\n",
            "Epoch 115/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.3323 - val_accuracy: 0.9480\n",
            "Epoch 116/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 0.2407 - val_accuracy: 0.9648\n",
            "Epoch 117/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0281 - accuracy: 0.9928 - val_loss: 0.3090 - val_accuracy: 0.9560\n",
            "Epoch 118/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.5547 - val_accuracy: 0.9312\n",
            "Epoch 119/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.5583 - val_accuracy: 0.9328\n",
            "Epoch 120/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.4386 - val_accuracy: 0.9472\n",
            "Epoch 121/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0477 - accuracy: 0.9861 - val_loss: 0.7533 - val_accuracy: 0.8984\n",
            "Epoch 122/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0568 - accuracy: 0.9832 - val_loss: 0.2944 - val_accuracy: 0.9384\n",
            "Epoch 123/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0334 - accuracy: 0.9923 - val_loss: 0.1701 - val_accuracy: 0.9688\n",
            "Epoch 124/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0256 - accuracy: 0.9939 - val_loss: 0.2162 - val_accuracy: 0.9624\n",
            "Epoch 125/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0320 - accuracy: 0.9917 - val_loss: 0.2896 - val_accuracy: 0.9520\n",
            "Epoch 126/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0166 - accuracy: 0.9971 - val_loss: 0.3014 - val_accuracy: 0.9512\n",
            "Epoch 127/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0207 - accuracy: 0.9955 - val_loss: 0.1772 - val_accuracy: 0.9728\n",
            "Epoch 128/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0143 - accuracy: 0.9960 - val_loss: 0.3599 - val_accuracy: 0.9496\n",
            "Epoch 129/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.2101 - val_accuracy: 0.9664\n",
            "Epoch 130/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.2093 - val_accuracy: 0.9672\n",
            "Epoch 131/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.3120 - val_accuracy: 0.9576\n",
            "Epoch 132/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.4253 - val_accuracy: 0.9464\n",
            "Epoch 133/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0288 - accuracy: 0.9944 - val_loss: 0.2585 - val_accuracy: 0.9616\n",
            "Epoch 134/250\n",
            "3750/3750 [==============================] - 1s 159us/step - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.3702 - val_accuracy: 0.9488\n",
            "Epoch 135/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.3495 - val_accuracy: 0.9512\n",
            "Epoch 136/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.2809 - val_accuracy: 0.9552\n",
            "Epoch 137/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.3885 - val_accuracy: 0.9440\n",
            "Epoch 138/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0263 - accuracy: 0.9939 - val_loss: 0.5787 - val_accuracy: 0.9312\n",
            "Epoch 139/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.2270 - val_accuracy: 0.9656\n",
            "Epoch 140/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.2109 - val_accuracy: 0.9680\n",
            "Epoch 141/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.3503 - val_accuracy: 0.9504\n",
            "Epoch 142/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.4941 - val_accuracy: 0.9376\n",
            "Epoch 143/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.4663 - val_accuracy: 0.9376\n",
            "Epoch 144/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0122 - accuracy: 0.9952 - val_loss: 0.3996 - val_accuracy: 0.9456\n",
            "Epoch 145/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.5458 - val_accuracy: 0.9328\n",
            "Epoch 146/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.3647 - val_accuracy: 0.9496\n",
            "Epoch 147/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.4582 - val_accuracy: 0.9400\n",
            "Epoch 148/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0180 - accuracy: 0.9963 - val_loss: 0.2486 - val_accuracy: 0.9672\n",
            "Epoch 149/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.2700 - val_accuracy: 0.9592\n",
            "Epoch 150/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.2017 - val_accuracy: 0.9720\n",
            "Epoch 151/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0275 - accuracy: 0.9944 - val_loss: 0.2557 - val_accuracy: 0.9480\n",
            "Epoch 152/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 0.2558 - val_accuracy: 0.9552\n",
            "Epoch 153/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0260 - accuracy: 0.9936 - val_loss: 0.3108 - val_accuracy: 0.9440\n",
            "Epoch 154/250\n",
            "3750/3750 [==============================] - 1s 150us/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.4701 - val_accuracy: 0.9344\n",
            "Epoch 155/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.2561 - val_accuracy: 0.9592\n",
            "Epoch 156/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0189 - accuracy: 0.9960 - val_loss: 0.2777 - val_accuracy: 0.9568\n",
            "Epoch 157/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0207 - accuracy: 0.9923 - val_loss: 0.2065 - val_accuracy: 0.9704\n",
            "Epoch 158/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.2424 - val_accuracy: 0.9664\n",
            "Epoch 159/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.4175 - val_accuracy: 0.9456\n",
            "Epoch 160/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0115 - accuracy: 0.9973 - val_loss: 0.5485 - val_accuracy: 0.9384\n",
            "Epoch 161/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.3474 - val_accuracy: 0.9544\n",
            "Epoch 162/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.4611 - val_accuracy: 0.9456\n",
            "Epoch 163/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.5166 - val_accuracy: 0.9384\n",
            "Epoch 164/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.5124 - val_accuracy: 0.9376\n",
            "Epoch 165/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.3899 - val_accuracy: 0.9544\n",
            "Epoch 166/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.2567 - val_accuracy: 0.9592\n",
            "Epoch 167/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.3327 - val_accuracy: 0.9536\n",
            "Epoch 168/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.3737 - val_accuracy: 0.9456\n",
            "Epoch 169/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0207 - accuracy: 0.9955 - val_loss: 0.3415 - val_accuracy: 0.9576\n",
            "Epoch 170/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.3661 - val_accuracy: 0.9504\n",
            "Epoch 171/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0117 - accuracy: 0.9976 - val_loss: 0.2528 - val_accuracy: 0.9664\n",
            "Epoch 172/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0186 - accuracy: 0.9952 - val_loss: 0.2808 - val_accuracy: 0.9584\n",
            "Epoch 173/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.3134 - val_accuracy: 0.9496\n",
            "Epoch 174/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.6532 - val_accuracy: 0.9184\n",
            "Epoch 175/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0253 - accuracy: 0.9944 - val_loss: 0.3202 - val_accuracy: 0.9528\n",
            "Epoch 176/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.2287 - val_accuracy: 0.9624\n",
            "Epoch 177/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.3762 - val_accuracy: 0.9456\n",
            "Epoch 178/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.2002 - val_accuracy: 0.9696\n",
            "Epoch 179/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.2550 - val_accuracy: 0.9608\n",
            "Epoch 180/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 0.5529 - val_accuracy: 0.9256\n",
            "Epoch 181/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.2140 - val_accuracy: 0.9672\n",
            "Epoch 182/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0192 - accuracy: 0.9960 - val_loss: 0.3090 - val_accuracy: 0.9512\n",
            "Epoch 183/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.1703 - val_accuracy: 0.9712\n",
            "Epoch 184/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.2006 - val_accuracy: 0.9696\n",
            "Epoch 185/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.2441 - val_accuracy: 0.9632\n",
            "Epoch 186/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.3463 - val_accuracy: 0.9536\n",
            "Epoch 187/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.5885 - val_accuracy: 0.9288\n",
            "Epoch 188/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.3038 - val_accuracy: 0.9608\n",
            "Epoch 189/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.3795 - val_accuracy: 0.9496\n",
            "Epoch 190/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.2845 - val_accuracy: 0.9624\n",
            "Epoch 191/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.2840 - val_accuracy: 0.9664\n",
            "Epoch 192/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.3179 - val_accuracy: 0.9560\n",
            "Epoch 193/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.4732 - val_accuracy: 0.9440\n",
            "Epoch 194/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.3612 - val_accuracy: 0.9528\n",
            "Epoch 195/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.3768 - val_accuracy: 0.9544\n",
            "Epoch 196/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0124 - accuracy: 0.9984 - val_loss: 0.3826 - val_accuracy: 0.9464\n",
            "Epoch 197/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.4072 - val_accuracy: 0.9496\n",
            "Epoch 198/250\n",
            "3750/3750 [==============================] - 1s 157us/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.3976 - val_accuracy: 0.9392\n",
            "Epoch 199/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.3398 - val_accuracy: 0.9520\n",
            "Epoch 200/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.2761 - val_accuracy: 0.9608\n",
            "Epoch 201/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0150 - accuracy: 0.9981 - val_loss: 0.4413 - val_accuracy: 0.9424\n",
            "Epoch 202/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.3788 - val_accuracy: 0.9464\n",
            "Epoch 203/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0221 - accuracy: 0.9949 - val_loss: 0.1887 - val_accuracy: 0.9728\n",
            "Epoch 204/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.3503 - val_accuracy: 0.9472\n",
            "Epoch 205/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.3970 - val_accuracy: 0.9448\n",
            "Epoch 206/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.3154 - val_accuracy: 0.9568\n",
            "Epoch 207/250\n",
            "3750/3750 [==============================] - 1s 158us/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.4068 - val_accuracy: 0.9496\n",
            "Epoch 208/250\n",
            "3750/3750 [==============================] - 1s 157us/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.2469 - val_accuracy: 0.9640\n",
            "Epoch 209/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.4154 - val_accuracy: 0.9488\n",
            "Epoch 210/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0129 - accuracy: 0.9973 - val_loss: 0.2752 - val_accuracy: 0.9632\n",
            "Epoch 211/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.2961 - val_accuracy: 0.9624\n",
            "Epoch 212/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.8347 - val_accuracy: 0.9072\n",
            "Epoch 213/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0264 - accuracy: 0.9949 - val_loss: 0.2921 - val_accuracy: 0.9616\n",
            "Epoch 214/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.2503 - val_accuracy: 0.9600\n",
            "Epoch 215/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.3354 - val_accuracy: 0.9464\n",
            "Epoch 216/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.3491 - val_accuracy: 0.9552\n",
            "Epoch 217/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.3289 - val_accuracy: 0.9512\n",
            "Epoch 218/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.5223 - val_accuracy: 0.9464\n",
            "Epoch 219/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.5491 - val_accuracy: 0.9312\n",
            "Epoch 220/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0179 - accuracy: 0.9965 - val_loss: 0.4950 - val_accuracy: 0.9392\n",
            "Epoch 221/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.3835 - val_accuracy: 0.9544\n",
            "Epoch 222/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.3387 - val_accuracy: 0.9552\n",
            "Epoch 223/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.3448 - val_accuracy: 0.9544\n",
            "Epoch 224/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0148 - accuracy: 0.9973 - val_loss: 0.2781 - val_accuracy: 0.9680\n",
            "Epoch 225/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0126 - accuracy: 0.9952 - val_loss: 0.4444 - val_accuracy: 0.9504\n",
            "Epoch 226/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0414 - accuracy: 0.9899 - val_loss: 0.3049 - val_accuracy: 0.9592\n",
            "Epoch 227/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.3369 - val_accuracy: 0.9504\n",
            "Epoch 228/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.5066 - val_accuracy: 0.9336\n",
            "Epoch 229/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.8034 - val_accuracy: 0.9104\n",
            "Epoch 230/250\n",
            "3750/3750 [==============================] - 1s 151us/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.5282 - val_accuracy: 0.9360\n",
            "Epoch 231/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0112 - accuracy: 0.9984 - val_loss: 0.4705 - val_accuracy: 0.9456\n",
            "Epoch 232/250\n",
            "3750/3750 [==============================] - 1s 150us/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.3021 - val_accuracy: 0.9624\n",
            "Epoch 233/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0040 - accuracy: 0.9984 - val_loss: 0.3848 - val_accuracy: 0.9504\n",
            "Epoch 234/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.2840 - val_accuracy: 0.9640\n",
            "Epoch 235/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.6516 - val_accuracy: 0.9336\n",
            "Epoch 236/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.6281 - val_accuracy: 0.9352\n",
            "Epoch 237/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.4330 - val_accuracy: 0.9496\n",
            "Epoch 238/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.2451 - val_accuracy: 0.9728\n",
            "Epoch 239/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0134 - accuracy: 0.9947 - val_loss: 0.2906 - val_accuracy: 0.9568\n",
            "Epoch 240/250\n",
            "3750/3750 [==============================] - 1s 153us/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.5424 - val_accuracy: 0.9304\n",
            "Epoch 241/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0156 - accuracy: 0.9973 - val_loss: 0.8255 - val_accuracy: 0.9056\n",
            "Epoch 242/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.3078 - val_accuracy: 0.9608\n",
            "Epoch 243/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.6424 - val_accuracy: 0.9304\n",
            "Epoch 244/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0124 - accuracy: 0.9963 - val_loss: 0.2621 - val_accuracy: 0.9624\n",
            "Epoch 245/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.2464 - val_accuracy: 0.9696\n",
            "Epoch 246/250\n",
            "3750/3750 [==============================] - 1s 150us/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 0.2736 - val_accuracy: 0.9656\n",
            "Epoch 247/250\n",
            "3750/3750 [==============================] - 1s 155us/step - loss: 0.0333 - accuracy: 0.9923 - val_loss: 0.5604 - val_accuracy: 0.9216\n",
            "Epoch 248/250\n",
            "3750/3750 [==============================] - 1s 154us/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.4980 - val_accuracy: 0.9296\n",
            "Epoch 249/250\n",
            "3750/3750 [==============================] - 1s 156us/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.3171 - val_accuracy: 0.9576\n",
            "Epoch 250/250\n",
            "3750/3750 [==============================] - 1s 152us/step - loss: 0.0211 - accuracy: 0.9944 - val_loss: 0.2357 - val_accuracy: 0.9680\n",
            "Time: \n",
            "145.871675491333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLLmpfmQnnck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee7bb914-5de2-4b38-9ad9-f3cdc5594131"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 500 simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "\n",
        "x=np.concatenate((u1[0:500,:,:],u2[0:500,:,:],u3[0:500,:,:],u4[0:500,:,:],u5[0:500,:,:]),axis=0)\n",
        "\n",
        "\n",
        "\n",
        "y=[0 for i in range(len(u1[0:500,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:500,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:500,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:500,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:500,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest))\n",
        "print ('Time: ')\n",
        "print (time.time() - start)\n",
        "\n",
        "cnn.save(filepath='/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2500 2500\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 214, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 213, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 212, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_7 (Average (None, 106, 125)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 106, 125)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 105, 125)          31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_8 (Average (None, 52, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 52, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 6500)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 125)               812625    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 5)                 630       \n",
            "=================================================================\n",
            "Total params: 955,255\n",
            "Trainable params: 955,255\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1875 samples, validate on 625 samples\n",
            "Epoch 1/250\n",
            "1875/1875 [==============================] - 1s 346us/step - loss: 1.6763 - accuracy: 0.2027 - val_loss: 1.6057 - val_accuracy: 0.2656\n",
            "Epoch 2/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 1.6091 - accuracy: 0.2139 - val_loss: 1.6043 - val_accuracy: 0.3328\n",
            "Epoch 3/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 1.5987 - accuracy: 0.2165 - val_loss: 1.5791 - val_accuracy: 0.2288\n",
            "Epoch 4/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 1.5618 - accuracy: 0.2245 - val_loss: 1.5233 - val_accuracy: 0.2816\n",
            "Epoch 5/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 1.4778 - accuracy: 0.2533 - val_loss: 1.4172 - val_accuracy: 0.4080\n",
            "Epoch 6/250\n",
            "1875/1875 [==============================] - 0s 196us/step - loss: 1.3842 - accuracy: 0.3979 - val_loss: 1.3258 - val_accuracy: 0.4416\n",
            "Epoch 7/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 1.3228 - accuracy: 0.4235 - val_loss: 1.3095 - val_accuracy: 0.4800\n",
            "Epoch 8/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 1.2882 - accuracy: 0.4373 - val_loss: 1.2762 - val_accuracy: 0.4736\n",
            "Epoch 9/250\n",
            "1875/1875 [==============================] - 0s 197us/step - loss: 1.2226 - accuracy: 0.4272 - val_loss: 1.1330 - val_accuracy: 0.4592\n",
            "Epoch 10/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 1.1673 - accuracy: 0.4267 - val_loss: 1.0638 - val_accuracy: 0.5056\n",
            "Epoch 11/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 1.1089 - accuracy: 0.4187 - val_loss: 1.0253 - val_accuracy: 0.4672\n",
            "Epoch 12/250\n",
            "1875/1875 [==============================] - 0s 197us/step - loss: 1.0799 - accuracy: 0.4453 - val_loss: 1.0070 - val_accuracy: 0.4624\n",
            "Epoch 13/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 1.0457 - accuracy: 0.4704 - val_loss: 0.9769 - val_accuracy: 0.5120\n",
            "Epoch 14/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 1.0199 - accuracy: 0.4875 - val_loss: 0.9794 - val_accuracy: 0.5136\n",
            "Epoch 15/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.9880 - accuracy: 0.5189 - val_loss: 0.9563 - val_accuracy: 0.5264\n",
            "Epoch 16/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.9931 - accuracy: 0.5275 - val_loss: 0.9814 - val_accuracy: 0.5392\n",
            "Epoch 17/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.9627 - accuracy: 0.5376 - val_loss: 0.9947 - val_accuracy: 0.5360\n",
            "Epoch 18/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.9349 - accuracy: 0.5531 - val_loss: 0.8870 - val_accuracy: 0.5856\n",
            "Epoch 19/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.8837 - accuracy: 0.5973 - val_loss: 0.9354 - val_accuracy: 0.5712\n",
            "Epoch 20/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.8422 - accuracy: 0.6224 - val_loss: 0.9283 - val_accuracy: 0.5824\n",
            "Epoch 21/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.8065 - accuracy: 0.6469 - val_loss: 0.7075 - val_accuracy: 0.6944\n",
            "Epoch 22/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.7476 - accuracy: 0.6875 - val_loss: 0.7063 - val_accuracy: 0.6832\n",
            "Epoch 23/250\n",
            "1875/1875 [==============================] - 0s 204us/step - loss: 0.6625 - accuracy: 0.7397 - val_loss: 0.7773 - val_accuracy: 0.6768\n",
            "Epoch 24/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.6012 - accuracy: 0.7728 - val_loss: 0.6712 - val_accuracy: 0.7264\n",
            "Epoch 25/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.4975 - accuracy: 0.8251 - val_loss: 0.6568 - val_accuracy: 0.7664\n",
            "Epoch 26/250\n",
            "1875/1875 [==============================] - 0s 198us/step - loss: 0.5061 - accuracy: 0.8171 - val_loss: 0.6491 - val_accuracy: 0.7936\n",
            "Epoch 27/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.4248 - accuracy: 0.8523 - val_loss: 0.6449 - val_accuracy: 0.7904\n",
            "Epoch 28/250\n",
            "1875/1875 [==============================] - 0s 203us/step - loss: 0.3973 - accuracy: 0.8709 - val_loss: 0.6248 - val_accuracy: 0.8304\n",
            "Epoch 29/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.3660 - accuracy: 0.8805 - val_loss: 0.4794 - val_accuracy: 0.8496\n",
            "Epoch 30/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.3075 - accuracy: 0.8960 - val_loss: 0.6937 - val_accuracy: 0.7968\n",
            "Epoch 31/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.3164 - accuracy: 0.8917 - val_loss: 0.5525 - val_accuracy: 0.8496\n",
            "Epoch 32/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.2612 - accuracy: 0.9200 - val_loss: 0.4181 - val_accuracy: 0.8736\n",
            "Epoch 33/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.2663 - accuracy: 0.9173 - val_loss: 0.3929 - val_accuracy: 0.8752\n",
            "Epoch 34/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.2471 - accuracy: 0.9392 - val_loss: 0.4016 - val_accuracy: 0.8784\n",
            "Epoch 35/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.2198 - accuracy: 0.9243 - val_loss: 0.5831 - val_accuracy: 0.8432\n",
            "Epoch 36/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.2412 - accuracy: 0.9173 - val_loss: 0.4902 - val_accuracy: 0.8688\n",
            "Epoch 37/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.2355 - accuracy: 0.9301 - val_loss: 0.5270 - val_accuracy: 0.8608\n",
            "Epoch 38/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.2215 - accuracy: 0.9339 - val_loss: 0.7895 - val_accuracy: 0.8224\n",
            "Epoch 39/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.2094 - accuracy: 0.9344 - val_loss: 0.6087 - val_accuracy: 0.8464\n",
            "Epoch 40/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.2317 - accuracy: 0.9259 - val_loss: 0.4005 - val_accuracy: 0.8832\n",
            "Epoch 41/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.2068 - accuracy: 0.9435 - val_loss: 0.3595 - val_accuracy: 0.8992\n",
            "Epoch 42/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.1716 - accuracy: 0.9499 - val_loss: 0.3484 - val_accuracy: 0.8976\n",
            "Epoch 43/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.1720 - accuracy: 0.9408 - val_loss: 0.4227 - val_accuracy: 0.8896\n",
            "Epoch 44/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.1594 - accuracy: 0.9488 - val_loss: 0.4760 - val_accuracy: 0.8832\n",
            "Epoch 45/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.1575 - accuracy: 0.9504 - val_loss: 0.7240 - val_accuracy: 0.8464\n",
            "Epoch 46/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.1629 - accuracy: 0.9483 - val_loss: 0.5941 - val_accuracy: 0.8672\n",
            "Epoch 47/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.1651 - accuracy: 0.9392 - val_loss: 0.3800 - val_accuracy: 0.8992\n",
            "Epoch 48/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.1700 - accuracy: 0.9472 - val_loss: 0.4124 - val_accuracy: 0.8960\n",
            "Epoch 49/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.1374 - accuracy: 0.9589 - val_loss: 0.3364 - val_accuracy: 0.9088\n",
            "Epoch 50/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.1397 - accuracy: 0.9584 - val_loss: 0.3125 - val_accuracy: 0.9120\n",
            "Epoch 51/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.1387 - accuracy: 0.9547 - val_loss: 0.3341 - val_accuracy: 0.9120\n",
            "Epoch 52/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.1411 - accuracy: 0.9515 - val_loss: 0.3036 - val_accuracy: 0.9232\n",
            "Epoch 53/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.1517 - accuracy: 0.9536 - val_loss: 0.3768 - val_accuracy: 0.9072\n",
            "Epoch 54/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.1530 - accuracy: 0.9509 - val_loss: 0.4069 - val_accuracy: 0.8992\n",
            "Epoch 55/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.1319 - accuracy: 0.9595 - val_loss: 0.4695 - val_accuracy: 0.8928\n",
            "Epoch 56/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.1183 - accuracy: 0.9664 - val_loss: 0.4964 - val_accuracy: 0.8880\n",
            "Epoch 57/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.1156 - accuracy: 0.9648 - val_loss: 0.3282 - val_accuracy: 0.9168\n",
            "Epoch 58/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.1000 - accuracy: 0.9680 - val_loss: 0.5345 - val_accuracy: 0.8880\n",
            "Epoch 59/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.1114 - accuracy: 0.9664 - val_loss: 0.8632 - val_accuracy: 0.8512\n",
            "Epoch 60/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.1142 - accuracy: 0.9664 - val_loss: 0.6914 - val_accuracy: 0.8704\n",
            "Epoch 61/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.1169 - accuracy: 0.9616 - val_loss: 0.5703 - val_accuracy: 0.8880\n",
            "Epoch 62/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.1149 - accuracy: 0.9627 - val_loss: 0.8019 - val_accuracy: 0.8608\n",
            "Epoch 63/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0907 - accuracy: 0.9712 - val_loss: 0.4699 - val_accuracy: 0.9056\n",
            "Epoch 64/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.1014 - accuracy: 0.9701 - val_loss: 0.3991 - val_accuracy: 0.9136\n",
            "Epoch 65/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.1082 - accuracy: 0.9675 - val_loss: 0.5528 - val_accuracy: 0.8944\n",
            "Epoch 66/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.1058 - accuracy: 0.9696 - val_loss: 0.6723 - val_accuracy: 0.8800\n",
            "Epoch 67/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.1000 - accuracy: 0.9723 - val_loss: 0.7338 - val_accuracy: 0.8752\n",
            "Epoch 68/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0818 - accuracy: 0.9765 - val_loss: 0.5871 - val_accuracy: 0.8944\n",
            "Epoch 69/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0749 - accuracy: 0.9755 - val_loss: 0.9258 - val_accuracy: 0.8592\n",
            "Epoch 70/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0942 - accuracy: 0.9717 - val_loss: 0.6013 - val_accuracy: 0.8944\n",
            "Epoch 71/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0885 - accuracy: 0.9728 - val_loss: 0.4251 - val_accuracy: 0.9056\n",
            "Epoch 72/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0769 - accuracy: 0.9755 - val_loss: 0.4214 - val_accuracy: 0.9088\n",
            "Epoch 73/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0898 - accuracy: 0.9717 - val_loss: 0.7084 - val_accuracy: 0.8816\n",
            "Epoch 74/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.1128 - accuracy: 0.9643 - val_loss: 0.8954 - val_accuracy: 0.8672\n",
            "Epoch 75/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0999 - accuracy: 0.9712 - val_loss: 0.4853 - val_accuracy: 0.9072\n",
            "Epoch 76/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0787 - accuracy: 0.9760 - val_loss: 0.4654 - val_accuracy: 0.9072\n",
            "Epoch 77/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0702 - accuracy: 0.9803 - val_loss: 0.3152 - val_accuracy: 0.9312\n",
            "Epoch 78/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0824 - accuracy: 0.9760 - val_loss: 0.7174 - val_accuracy: 0.8752\n",
            "Epoch 79/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.1391 - accuracy: 0.9579 - val_loss: 0.3528 - val_accuracy: 0.9216\n",
            "Epoch 80/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0998 - accuracy: 0.9723 - val_loss: 0.3601 - val_accuracy: 0.9184\n",
            "Epoch 81/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0866 - accuracy: 0.9728 - val_loss: 0.2478 - val_accuracy: 0.9392\n",
            "Epoch 82/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0891 - accuracy: 0.9749 - val_loss: 0.4138 - val_accuracy: 0.9120\n",
            "Epoch 83/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.0701 - accuracy: 0.9813 - val_loss: 0.6404 - val_accuracy: 0.8896\n",
            "Epoch 84/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0725 - accuracy: 0.9733 - val_loss: 0.7596 - val_accuracy: 0.8784\n",
            "Epoch 85/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0930 - accuracy: 0.9680 - val_loss: 0.4877 - val_accuracy: 0.9136\n",
            "Epoch 86/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0748 - accuracy: 0.9765 - val_loss: 0.7433 - val_accuracy: 0.8848\n",
            "Epoch 87/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0724 - accuracy: 0.9744 - val_loss: 0.4809 - val_accuracy: 0.9152\n",
            "Epoch 88/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0612 - accuracy: 0.9792 - val_loss: 0.4814 - val_accuracy: 0.9152\n",
            "Epoch 89/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0716 - accuracy: 0.9797 - val_loss: 0.2870 - val_accuracy: 0.9344\n",
            "Epoch 90/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0667 - accuracy: 0.9803 - val_loss: 0.3631 - val_accuracy: 0.9264\n",
            "Epoch 91/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0631 - accuracy: 0.9808 - val_loss: 1.0064 - val_accuracy: 0.8560\n",
            "Epoch 92/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0530 - accuracy: 0.9840 - val_loss: 0.4896 - val_accuracy: 0.9136\n",
            "Epoch 93/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0511 - accuracy: 0.9851 - val_loss: 0.5246 - val_accuracy: 0.9088\n",
            "Epoch 94/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.6459 - val_accuracy: 0.8992\n",
            "Epoch 95/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0551 - accuracy: 0.9851 - val_loss: 0.5475 - val_accuracy: 0.9072\n",
            "Epoch 96/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0514 - accuracy: 0.9851 - val_loss: 0.5370 - val_accuracy: 0.9056\n",
            "Epoch 97/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0557 - accuracy: 0.9819 - val_loss: 0.4492 - val_accuracy: 0.9200\n",
            "Epoch 98/250\n",
            "1875/1875 [==============================] - 0s 197us/step - loss: 0.0656 - accuracy: 0.9803 - val_loss: 0.6834 - val_accuracy: 0.8944\n",
            "Epoch 99/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0499 - accuracy: 0.9851 - val_loss: 0.6995 - val_accuracy: 0.8928\n",
            "Epoch 100/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0642 - accuracy: 0.9792 - val_loss: 0.5010 - val_accuracy: 0.9104\n",
            "Epoch 101/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0457 - accuracy: 0.9893 - val_loss: 0.5467 - val_accuracy: 0.9088\n",
            "Epoch 102/250\n",
            "1875/1875 [==============================] - 0s 186us/step - loss: 0.0567 - accuracy: 0.9851 - val_loss: 0.7913 - val_accuracy: 0.8832\n",
            "Epoch 103/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0562 - accuracy: 0.9851 - val_loss: 0.4948 - val_accuracy: 0.9168\n",
            "Epoch 104/250\n",
            "1875/1875 [==============================] - 0s 196us/step - loss: 0.0471 - accuracy: 0.9877 - val_loss: 0.5291 - val_accuracy: 0.9152\n",
            "Epoch 105/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0621 - accuracy: 0.9845 - val_loss: 0.5403 - val_accuracy: 0.9104\n",
            "Epoch 106/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0507 - accuracy: 0.9829 - val_loss: 0.6190 - val_accuracy: 0.9088\n",
            "Epoch 107/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0512 - accuracy: 0.9845 - val_loss: 0.5002 - val_accuracy: 0.9232\n",
            "Epoch 108/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0456 - accuracy: 0.9867 - val_loss: 0.3717 - val_accuracy: 0.9328\n",
            "Epoch 109/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0566 - accuracy: 0.9792 - val_loss: 0.3735 - val_accuracy: 0.9312\n",
            "Epoch 110/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0541 - accuracy: 0.9861 - val_loss: 0.5993 - val_accuracy: 0.9040\n",
            "Epoch 111/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0399 - accuracy: 0.9899 - val_loss: 0.6417 - val_accuracy: 0.9024\n",
            "Epoch 112/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0535 - accuracy: 0.9851 - val_loss: 0.9097 - val_accuracy: 0.8784\n",
            "Epoch 113/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0453 - accuracy: 0.9867 - val_loss: 0.4698 - val_accuracy: 0.9168\n",
            "Epoch 114/250\n",
            "1875/1875 [==============================] - 0s 198us/step - loss: 0.0420 - accuracy: 0.9856 - val_loss: 0.5883 - val_accuracy: 0.9120\n",
            "Epoch 115/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 0.6062 - val_accuracy: 0.9056\n",
            "Epoch 116/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.5695 - val_accuracy: 0.9152\n",
            "Epoch 117/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.7532 - val_accuracy: 0.8992\n",
            "Epoch 118/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.5998 - val_accuracy: 0.9136\n",
            "Epoch 119/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.7125 - val_accuracy: 0.8976\n",
            "Epoch 120/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0630 - accuracy: 0.9813 - val_loss: 0.5020 - val_accuracy: 0.9184\n",
            "Epoch 121/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0468 - accuracy: 0.9867 - val_loss: 0.5945 - val_accuracy: 0.9104\n",
            "Epoch 122/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0533 - accuracy: 0.9813 - val_loss: 0.7336 - val_accuracy: 0.8976\n",
            "Epoch 123/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0410 - accuracy: 0.9856 - val_loss: 0.4675 - val_accuracy: 0.9184\n",
            "Epoch 124/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0334 - accuracy: 0.9904 - val_loss: 0.8685 - val_accuracy: 0.8832\n",
            "Epoch 125/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0530 - accuracy: 0.9845 - val_loss: 1.1044 - val_accuracy: 0.8640\n",
            "Epoch 126/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 0.6007 - val_accuracy: 0.9072\n",
            "Epoch 127/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0578 - accuracy: 0.9856 - val_loss: 0.5297 - val_accuracy: 0.9152\n",
            "Epoch 128/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.1053 - accuracy: 0.9712 - val_loss: 0.6764 - val_accuracy: 0.8976\n",
            "Epoch 129/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0674 - accuracy: 0.9813 - val_loss: 0.4374 - val_accuracy: 0.9104\n",
            "Epoch 130/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0572 - accuracy: 0.9845 - val_loss: 0.4217 - val_accuracy: 0.9248\n",
            "Epoch 131/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0640 - accuracy: 0.9824 - val_loss: 1.0910 - val_accuracy: 0.8528\n",
            "Epoch 132/250\n",
            "1875/1875 [==============================] - 0s 186us/step - loss: 0.0662 - accuracy: 0.9755 - val_loss: 0.4717 - val_accuracy: 0.9232\n",
            "Epoch 133/250\n",
            "1875/1875 [==============================] - 0s 186us/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.3804 - val_accuracy: 0.9360\n",
            "Epoch 134/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0612 - accuracy: 0.9840 - val_loss: 0.8459 - val_accuracy: 0.8736\n",
            "Epoch 135/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0551 - accuracy: 0.9867 - val_loss: 0.4866 - val_accuracy: 0.9168\n",
            "Epoch 136/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0450 - accuracy: 0.9877 - val_loss: 0.8311 - val_accuracy: 0.8832\n",
            "Epoch 137/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0321 - accuracy: 0.9909 - val_loss: 0.7249 - val_accuracy: 0.8992\n",
            "Epoch 138/250\n",
            "1875/1875 [==============================] - 0s 196us/step - loss: 0.0279 - accuracy: 0.9915 - val_loss: 0.4890 - val_accuracy: 0.9232\n",
            "Epoch 139/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0363 - accuracy: 0.9899 - val_loss: 0.8105 - val_accuracy: 0.8912\n",
            "Epoch 140/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.5961 - val_accuracy: 0.9136\n",
            "Epoch 141/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0375 - accuracy: 0.9893 - val_loss: 0.5895 - val_accuracy: 0.9120\n",
            "Epoch 142/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 1.0192 - val_accuracy: 0.8720\n",
            "Epoch 143/250\n",
            "1875/1875 [==============================] - 0s 203us/step - loss: 0.0187 - accuracy: 0.9957 - val_loss: 0.4413 - val_accuracy: 0.9312\n",
            "Epoch 144/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0312 - accuracy: 0.9899 - val_loss: 0.7142 - val_accuracy: 0.9072\n",
            "Epoch 145/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.9918 - val_accuracy: 0.8736\n",
            "Epoch 146/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0289 - accuracy: 0.9877 - val_loss: 0.6990 - val_accuracy: 0.9024\n",
            "Epoch 147/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0303 - accuracy: 0.9931 - val_loss: 0.7592 - val_accuracy: 0.8960\n",
            "Epoch 148/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0304 - accuracy: 0.9925 - val_loss: 0.5399 - val_accuracy: 0.9152\n",
            "Epoch 149/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0295 - accuracy: 0.9920 - val_loss: 0.9436 - val_accuracy: 0.8800\n",
            "Epoch 150/250\n",
            "1875/1875 [==============================] - 0s 196us/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.9901 - val_accuracy: 0.8800\n",
            "Epoch 151/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.0257 - accuracy: 0.9931 - val_loss: 0.4704 - val_accuracy: 0.9248\n",
            "Epoch 152/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.0224 - accuracy: 0.9952 - val_loss: 0.5962 - val_accuracy: 0.9136\n",
            "Epoch 153/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0161 - accuracy: 0.9936 - val_loss: 0.9009 - val_accuracy: 0.8944\n",
            "Epoch 154/250\n",
            "1875/1875 [==============================] - 0s 197us/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.4048 - val_accuracy: 0.9392\n",
            "Epoch 155/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0418 - accuracy: 0.9915 - val_loss: 0.5679 - val_accuracy: 0.9200\n",
            "Epoch 156/250\n",
            "1875/1875 [==============================] - 0s 200us/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 1.0221 - val_accuracy: 0.8816\n",
            "Epoch 157/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.5566 - val_accuracy: 0.9168\n",
            "Epoch 158/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.6778 - val_accuracy: 0.9120\n",
            "Epoch 159/250\n",
            "1875/1875 [==============================] - 0s 196us/step - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.5638 - val_accuracy: 0.9216\n",
            "Epoch 160/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0148 - accuracy: 0.9968 - val_loss: 1.1746 - val_accuracy: 0.8688\n",
            "Epoch 161/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0310 - accuracy: 0.9925 - val_loss: 0.4581 - val_accuracy: 0.9360\n",
            "Epoch 162/250\n",
            "1875/1875 [==============================] - 0s 196us/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 0.5942 - val_accuracy: 0.9184\n",
            "Epoch 163/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.9252 - val_accuracy: 0.8848\n",
            "Epoch 164/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 0.3194 - val_accuracy: 0.9440\n",
            "Epoch 165/250\n",
            "1875/1875 [==============================] - 0s 198us/step - loss: 0.0289 - accuracy: 0.9931 - val_loss: 0.9285 - val_accuracy: 0.8848\n",
            "Epoch 166/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0367 - accuracy: 0.9877 - val_loss: 0.5557 - val_accuracy: 0.9232\n",
            "Epoch 167/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0471 - accuracy: 0.9888 - val_loss: 0.5082 - val_accuracy: 0.9216\n",
            "Epoch 168/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0316 - accuracy: 0.9877 - val_loss: 1.1098 - val_accuracy: 0.8688\n",
            "Epoch 169/250\n",
            "1875/1875 [==============================] - 0s 186us/step - loss: 0.0675 - accuracy: 0.9792 - val_loss: 0.9471 - val_accuracy: 0.8816\n",
            "Epoch 170/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0549 - accuracy: 0.9856 - val_loss: 0.7143 - val_accuracy: 0.9024\n",
            "Epoch 171/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 0.4122 - val_accuracy: 0.9280\n",
            "Epoch 172/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0484 - accuracy: 0.9835 - val_loss: 0.2694 - val_accuracy: 0.9520\n",
            "Epoch 173/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0527 - accuracy: 0.9813 - val_loss: 0.7574 - val_accuracy: 0.9072\n",
            "Epoch 174/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0766 - accuracy: 0.9781 - val_loss: 0.7403 - val_accuracy: 0.8960\n",
            "Epoch 175/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0363 - accuracy: 0.9893 - val_loss: 0.3526 - val_accuracy: 0.9408\n",
            "Epoch 176/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.4508 - val_accuracy: 0.9216\n",
            "Epoch 177/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.7108 - val_accuracy: 0.8992\n",
            "Epoch 178/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.5655 - val_accuracy: 0.9152\n",
            "Epoch 179/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 0.9210 - val_accuracy: 0.8864\n",
            "Epoch 180/250\n",
            "1875/1875 [==============================] - 0s 185us/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.6560 - val_accuracy: 0.9072\n",
            "Epoch 181/250\n",
            "1875/1875 [==============================] - 0s 186us/step - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.9312 - val_accuracy: 0.8928\n",
            "Epoch 182/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0271 - accuracy: 0.9947 - val_loss: 0.4310 - val_accuracy: 0.9376\n",
            "Epoch 183/250\n",
            "1875/1875 [==============================] - 0s 186us/step - loss: 0.0242 - accuracy: 0.9936 - val_loss: 0.5942 - val_accuracy: 0.9120\n",
            "Epoch 184/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0200 - accuracy: 0.9941 - val_loss: 0.7122 - val_accuracy: 0.8992\n",
            "Epoch 185/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0274 - accuracy: 0.9936 - val_loss: 0.3889 - val_accuracy: 0.9504\n",
            "Epoch 186/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.6582 - val_accuracy: 0.9120\n",
            "Epoch 187/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.8164 - val_accuracy: 0.8976\n",
            "Epoch 188/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.6660 - val_accuracy: 0.9072\n",
            "Epoch 189/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0265 - accuracy: 0.9952 - val_loss: 0.7756 - val_accuracy: 0.8992\n",
            "Epoch 190/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.3837 - val_accuracy: 0.9392\n",
            "Epoch 191/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.9033 - val_accuracy: 0.8912\n",
            "Epoch 192/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0314 - accuracy: 0.9941 - val_loss: 0.5921 - val_accuracy: 0.9200\n",
            "Epoch 193/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0191 - accuracy: 0.9957 - val_loss: 0.6483 - val_accuracy: 0.9136\n",
            "Epoch 194/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0243 - accuracy: 0.9909 - val_loss: 0.7784 - val_accuracy: 0.8976\n",
            "Epoch 195/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0164 - accuracy: 0.9968 - val_loss: 0.5319 - val_accuracy: 0.9232\n",
            "Epoch 196/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.7849 - val_accuracy: 0.8896\n",
            "Epoch 197/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.3766 - val_accuracy: 0.9472\n",
            "Epoch 198/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 1.0574 - val_accuracy: 0.8816\n",
            "Epoch 199/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.4089 - val_accuracy: 0.9456\n",
            "Epoch 200/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.5017 - val_accuracy: 0.9280\n",
            "Epoch 201/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.5115 - val_accuracy: 0.9312\n",
            "Epoch 202/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.7245 - val_accuracy: 0.9088\n",
            "Epoch 203/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.5927 - val_accuracy: 0.9104\n",
            "Epoch 204/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0346 - accuracy: 0.9909 - val_loss: 0.5828 - val_accuracy: 0.9200\n",
            "Epoch 205/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.9212 - val_accuracy: 0.8944\n",
            "Epoch 206/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0251 - accuracy: 0.9904 - val_loss: 0.6214 - val_accuracy: 0.9120\n",
            "Epoch 207/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.6799 - val_accuracy: 0.9088\n",
            "Epoch 208/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0207 - accuracy: 0.9963 - val_loss: 0.6386 - val_accuracy: 0.9152\n",
            "Epoch 209/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.7504 - val_accuracy: 0.8992\n",
            "Epoch 210/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.7293 - val_accuracy: 0.9072\n",
            "Epoch 211/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.9185 - val_accuracy: 0.8960\n",
            "Epoch 212/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0420 - accuracy: 0.9899 - val_loss: 0.6329 - val_accuracy: 0.9120\n",
            "Epoch 213/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0623 - accuracy: 0.9851 - val_loss: 0.4854 - val_accuracy: 0.9264\n",
            "Epoch 214/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0381 - accuracy: 0.9904 - val_loss: 0.4705 - val_accuracy: 0.9280\n",
            "Epoch 215/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.5480 - val_accuracy: 0.9104\n",
            "Epoch 216/250\n",
            "1875/1875 [==============================] - 0s 194us/step - loss: 0.0234 - accuracy: 0.9947 - val_loss: 0.6233 - val_accuracy: 0.9040\n",
            "Epoch 217/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.5276 - val_accuracy: 0.9232\n",
            "Epoch 218/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 0.9420 - val_accuracy: 0.8800\n",
            "Epoch 219/250\n",
            "1875/1875 [==============================] - 0s 196us/step - loss: 0.0359 - accuracy: 0.9877 - val_loss: 0.4414 - val_accuracy: 0.9408\n",
            "Epoch 220/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 0.6540 - val_accuracy: 0.9072\n",
            "Epoch 221/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 0.7097 - val_accuracy: 0.8944\n",
            "Epoch 222/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.0261 - accuracy: 0.9957 - val_loss: 0.4582 - val_accuracy: 0.9392\n",
            "Epoch 223/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 0.7372 - val_accuracy: 0.8928\n",
            "Epoch 224/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.5643 - val_accuracy: 0.9216\n",
            "Epoch 225/250\n",
            "1875/1875 [==============================] - 0s 197us/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.5610 - val_accuracy: 0.9120\n",
            "Epoch 226/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0210 - accuracy: 0.9952 - val_loss: 0.6808 - val_accuracy: 0.9152\n",
            "Epoch 227/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.5410 - val_accuracy: 0.9184\n",
            "Epoch 228/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 1.0969 - val_accuracy: 0.8720\n",
            "Epoch 229/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.5367 - val_accuracy: 0.9248\n",
            "Epoch 230/250\n",
            "1875/1875 [==============================] - 0s 200us/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.5677 - val_accuracy: 0.9248\n",
            "Epoch 231/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 0.8041 - val_accuracy: 0.9024\n",
            "Epoch 232/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.5961 - val_accuracy: 0.9232\n",
            "Epoch 233/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.7277 - val_accuracy: 0.9136\n",
            "Epoch 234/250\n",
            "1875/1875 [==============================] - 0s 186us/step - loss: 0.0147 - accuracy: 0.9979 - val_loss: 0.7849 - val_accuracy: 0.9104\n",
            "Epoch 235/250\n",
            "1875/1875 [==============================] - 0s 189us/step - loss: 0.0039 - accuracy: 0.9984 - val_loss: 0.5829 - val_accuracy: 0.9264\n",
            "Epoch 236/250\n",
            "1875/1875 [==============================] - 0s 195us/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.9962 - val_accuracy: 0.8912\n",
            "Epoch 237/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.5076 - val_accuracy: 0.9408\n",
            "Epoch 238/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0087 - accuracy: 0.9957 - val_loss: 1.3040 - val_accuracy: 0.8656\n",
            "Epoch 239/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.6980 - val_accuracy: 0.9216\n",
            "Epoch 240/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 1.3507 - val_accuracy: 0.8624\n",
            "Epoch 241/250\n",
            "1875/1875 [==============================] - 0s 191us/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.4669 - val_accuracy: 0.9408\n",
            "Epoch 242/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0220 - accuracy: 0.9936 - val_loss: 0.9095 - val_accuracy: 0.8848\n",
            "Epoch 243/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0216 - accuracy: 0.9952 - val_loss: 0.7183 - val_accuracy: 0.8960\n",
            "Epoch 244/250\n",
            "1875/1875 [==============================] - 0s 190us/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 0.8714 - val_accuracy: 0.8928\n",
            "Epoch 245/250\n",
            "1875/1875 [==============================] - 0s 192us/step - loss: 0.0108 - accuracy: 0.9957 - val_loss: 0.7373 - val_accuracy: 0.9040\n",
            "Epoch 246/250\n",
            "1875/1875 [==============================] - 0s 196us/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 0.4430 - val_accuracy: 0.9376\n",
            "Epoch 247/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.7900 - val_accuracy: 0.8976\n",
            "Epoch 248/250\n",
            "1875/1875 [==============================] - 0s 187us/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.8024 - val_accuracy: 0.8976\n",
            "Epoch 249/250\n",
            "1875/1875 [==============================] - 0s 188us/step - loss: 0.0169 - accuracy: 0.9952 - val_loss: 1.3186 - val_accuracy: 0.8624\n",
            "Epoch 250/250\n",
            "1875/1875 [==============================] - 0s 193us/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.4474 - val_accuracy: 0.9360\n",
            "Time: \n",
            "91.9037868976593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYlMXO8wiOai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c5f25215-7604-40e2-db53-3b7ca86813ce"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 2.5K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "t1 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel1.npz\")\n",
        "t2 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel2.npz\")\n",
        "t3 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel3.npz\")\n",
        "t4 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel4.npz\")\n",
        "t5 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel5.npz\")\n",
        "t1 = t1[\"simModel1\"]\n",
        "t2 = t2[\"simModel2\"]\n",
        "t3 = t3[\"simModel3\"]\n",
        "t4 = t4[\"simModel4\"]\n",
        "t5 = t5[\"simModel5\"]\n",
        "x=np.concatenate((t1,t2,t3,t4,t5),axis=0)\n",
        "\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y = np.array(y)\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/Trained_2.5KSims.acc.mod')\n",
        "pred = model.predict(x)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))\n",
        "print (confusion_matrix(y, pred_cat) / float(len(y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 966    0   34    0    0]\n",
            " [   0  972    0   14   14]\n",
            " [   0    0  996    4    0]\n",
            " [   0    0   28  914   58]\n",
            " [   0    0    0    0 1000]]\n",
            "[[0.1932 0.     0.0068 0.     0.    ]\n",
            " [0.     0.1944 0.     0.0028 0.0028]\n",
            " [0.     0.     0.1992 0.0008 0.    ]\n",
            " [0.     0.     0.0056 0.1828 0.0116]\n",
            " [0.     0.     0.     0.     0.2   ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfN2JKeeQpwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "28ad52ba-5b85-4c06-e255-ce6cc1c6ad5d"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 1K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "t1 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel1.npz\")\n",
        "t2 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel2.npz\")\n",
        "t3 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel3.npz\")\n",
        "t4 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel4.npz\")\n",
        "t5 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel5.npz\")\n",
        "t1 = t1[\"simModel1\"]\n",
        "t2 = t2[\"simModel2\"]\n",
        "t3 = t3[\"simModel3\"]\n",
        "t4 = t4[\"simModel4\"]\n",
        "t5 = t5[\"simModel5\"]\n",
        "x=np.concatenate((t1,t2,t3,t4,t5),axis=0)\n",
        "\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y = np.array(y)\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/Trained_1KSims.acc.mod')\n",
        "pred = model.predict(x)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))\n",
        "print (confusion_matrix(y, pred_cat) / float(len(y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[959   0  41   0   0]\n",
            " [  4 967   0  20   9]\n",
            " [  0   0 998   2   0]\n",
            " [  0   0  43 928  29]\n",
            " [  0   1   0   3 996]]\n",
            "[[0.1918 0.     0.0082 0.     0.    ]\n",
            " [0.0008 0.1934 0.     0.004  0.0018]\n",
            " [0.     0.     0.1996 0.0004 0.    ]\n",
            " [0.     0.     0.0086 0.1856 0.0058]\n",
            " [0.     0.0002 0.     0.0006 0.1992]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYKdCeqPT5Q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dcc02e79-161c-4521-f035-2b049138a9cb"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 500 simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "t1 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel1.npz\")\n",
        "t2 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel2.npz\")\n",
        "t3 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel3.npz\")\n",
        "t4 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel4.npz\")\n",
        "t5 = np.load(\"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/TestData/Piloso/simModel5.npz\")\n",
        "t1 = t1[\"simModel1\"]\n",
        "t2 = t2[\"simModel2\"]\n",
        "t3 = t3[\"simModel3\"]\n",
        "t4 = t4[\"simModel4\"]\n",
        "t5 = t5[\"simModel5\"]\n",
        "x=np.concatenate((t1,t2,t3,t4,t5),axis=0)\n",
        "\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y = np.array(y)\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation/Trained_0.5KSims.acc.mod')\n",
        "pred = model.predict(x)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))\n",
        "print (confusion_matrix(y, pred_cat) / float(len(y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[962   0  38   0   0]\n",
            " [  6 966   0  12  16]\n",
            " [  0   0 998   2   0]\n",
            " [  0   6  55 869  70]\n",
            " [  0   2   0   0 998]]\n",
            "[[0.1924 0.     0.0076 0.     0.    ]\n",
            " [0.0012 0.1932 0.     0.0024 0.0032]\n",
            " [0.     0.     0.1996 0.0004 0.    ]\n",
            " [0.     0.0012 0.011  0.1738 0.014 ]\n",
            " [0.     0.0004 0.     0.     0.1996]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}