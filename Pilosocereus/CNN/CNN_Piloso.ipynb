{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CÃ³pia de Train_CNN_Piloso",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELhRS0fu2b6T"
      },
      "source": [
        "## **Notebook containing scripts and outputs of the training, cross-validation and empirical data prediction for *Pilosocereus aurisetus***\n",
        "From the manuscript Perez et al. \"Species Delimitation Meets Deep Learning: Insights from a Highly Fragmented Cactus System\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffjZgEDIRlld",
        "outputId": "5e348f44-a948-4437-8550-dc3f0c476f0b"
      },
      "source": [
        "#mount google drive to load files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgc_VfbydhlW"
      },
      "source": [
        "# Import all required modules.\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.pooling import  AveragePooling1D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from random import shuffle\n",
        "import time\n",
        "\n",
        "# Define parameters for the CNN run.\n",
        "batch_size = 250\n",
        "epochs = 250\n",
        "num_classes = 7\n",
        "\n",
        "# Define the CNN architecture.\n",
        "def create_cnn(xtest, regularizer=None):\n",
        "\tinputShape = (xtest.shape[1], xtest.shape[2])\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = inputs\n",
        "\tx = Conv1D(250, kernel_size=2, activation='relu',input_shape=(xtest.shape[1], xtest.shape[2]))(x)\n",
        "\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n",
        "\tx = AveragePooling1D(pool_size=2)(x)\n",
        "\tx = Dropout(0.75)(x)\n",
        "\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n",
        "\tx = AveragePooling1D(pool_size=2)(x)\n",
        "\tx = Dropout(0.75)(x)\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(125, activation='relu')(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\tx = Dense(125, activation='relu')(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "  # The final fully-connected layer head will have a softmax dense layer.\n",
        "\tx = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\t# Construct the CNN.\n",
        "\tmodel = Model(inputs, x)\n",
        "\t# Return the CNN.\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_ohKNkh4Ki-"
      },
      "source": [
        "# **Train the network with 10,000 simulations from each model**\n",
        "Here we will use the full simulated dataset to train the network, by splitting the data with 75% of simulations for training and 25% for validation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIM8vGTaaxRx",
        "outputId": "179d0ce4-e1f6-4f3b-bcc4-352753cad2b3"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/training10ksims.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Piloso/training10ksims.zip\n",
            "  inflating: simModel1.npy           \n",
            "  inflating: simModel2.npy           \n",
            "  inflating: simModel3.npy           \n",
            "  inflating: simModel4.npy           \n",
            "  inflating: simModel5.npy           \n",
            "  inflating: simModel6.npy           \n",
            "  inflating: simModel7.npy           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJgkHTL9Tddn",
        "outputId": "9c171531-1e45-4a5a-a0a7-1e9dbd8a40d4"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train a network using 10K simulations per model.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing simulations.\n",
        "u1 = np.load(\"/content/simModel1.npy\",mmap_mode='r')\n",
        "u2 = np.load(\"/content/simModel2.npy\",mmap_mode='r')\n",
        "u3 = np.load(\"/content/simModel3.npy\",mmap_mode='r')\n",
        "u4 = np.load(\"/content/simModel4.npy\",mmap_mode='r')\n",
        "u5 = np.load(\"/content/simModel5.npy\",mmap_mode='r')\n",
        "u6 = np.load(\"/content/simModel6.npy\",mmap_mode='r')\n",
        "u7 = np.load(\"/content/simModel7.npy\",mmap_mode='r')\n",
        "\n",
        "# Combine all arrays.\n",
        "x=np.concatenate((u1,u2,u3,u4,u5,u6,u7),axis=0)\n",
        "\n",
        "# Label each simulated array.\n",
        "y=[0 for i in range(len(u1))]\n",
        "y.extend([1 for i in range(len(u2))])\n",
        "y.extend([2 for i in range(len(u3))])\n",
        "y.extend([3 for i in range(len(u4))])\n",
        "y.extend([4 for i in range(len(u5))])\n",
        "y.extend([5 for i in range(len(u6))])\n",
        "y.extend([6 for i in range(len(u7))])\n",
        "y = np.array(y)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "\n",
        "x=x.astype(np.uint8)\n",
        "\n",
        "# Print label and simulations length, these should be the same.\n",
        "print (len(x), len(y))\n",
        "\n",
        "# Shuffle the arrays for training, keeping the labels in the same order.\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "# Separate train (75%) and validate (25%) sets.\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "del(x)\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network, using the architecture defined above.\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "# Compile the CNN.\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n",
        "print (f'Time: {time.time() - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70000 70000\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 195, 64)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 194, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 193, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d (AveragePo (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 95, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_1 (Average (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5875)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 125)               734500    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 882       \n",
            "=================================================================\n",
            "Total params: 877,382\n",
            "Trainable params: 877,382\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            "  1/210 [..............................] - ETA: 0s - loss: 2.1267 - accuracy: 0.1040WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0084s vs `on_train_batch_end` time: 0.0232s). Check your callbacks.\n",
            "210/210 [==============================] - ETA: 0s - loss: 1.3060 - accuracy: 0.4074WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0055s). Check your callbacks.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 30ms/step - loss: 1.3060 - accuracy: 0.4074 - val_loss: 0.6038 - val_accuracy: 0.6900\n",
            "Epoch 2/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.6377 - accuracy: 0.6720INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.6371 - accuracy: 0.6722 - val_loss: 0.5028 - val_accuracy: 0.7269\n",
            "Epoch 3/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.5595 - accuracy: 0.7011INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 28ms/step - loss: 0.5590 - accuracy: 0.7012 - val_loss: 0.4850 - val_accuracy: 0.7345\n",
            "Epoch 4/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.7162INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.5233 - accuracy: 0.7161 - val_loss: 0.4823 - val_accuracy: 0.7423\n",
            "Epoch 5/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.5045 - accuracy: 0.7259 - val_loss: 0.4621 - val_accuracy: 0.7402\n",
            "Epoch 6/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.4911 - accuracy: 0.7363INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.4914 - accuracy: 0.7361 - val_loss: 0.4564 - val_accuracy: 0.7585\n",
            "Epoch 7/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.7479INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.4767 - accuracy: 0.7478 - val_loss: 0.4403 - val_accuracy: 0.7626\n",
            "Epoch 8/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.4572 - accuracy: 0.7685INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 30ms/step - loss: 0.4570 - accuracy: 0.7687 - val_loss: 0.4188 - val_accuracy: 0.7834\n",
            "Epoch 9/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.4093 - accuracy: 0.8200INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.4086 - accuracy: 0.8204 - val_loss: 0.3236 - val_accuracy: 0.8791\n",
            "Epoch 10/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.3167 - accuracy: 0.8826INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.3170 - accuracy: 0.8826 - val_loss: 0.2365 - val_accuracy: 0.9137\n",
            "Epoch 11/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.2824 - accuracy: 0.8981 - val_loss: 0.2617 - val_accuracy: 0.8994\n",
            "Epoch 12/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.2733 - accuracy: 0.9025INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 30ms/step - loss: 0.2734 - accuracy: 0.9024 - val_loss: 0.2424 - val_accuracy: 0.9145\n",
            "Epoch 13/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9080INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.2656 - accuracy: 0.9080 - val_loss: 0.2439 - val_accuracy: 0.9149\n",
            "Epoch 14/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.2548 - accuracy: 0.9104INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.2546 - accuracy: 0.9105 - val_loss: 0.2209 - val_accuracy: 0.9215\n",
            "Epoch 15/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.2447 - accuracy: 0.9134 - val_loss: 0.2688 - val_accuracy: 0.9121\n",
            "Epoch 16/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.2337 - accuracy: 0.9192 - val_loss: 0.2439 - val_accuracy: 0.9190\n",
            "Epoch 17/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.2318 - accuracy: 0.9194INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.2316 - accuracy: 0.9195 - val_loss: 0.2195 - val_accuracy: 0.9238\n",
            "Epoch 18/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9198INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 30ms/step - loss: 0.2265 - accuracy: 0.9200 - val_loss: 0.2175 - val_accuracy: 0.9239\n",
            "Epoch 19/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.2212 - accuracy: 0.9226 - val_loss: 0.2242 - val_accuracy: 0.9160\n",
            "Epoch 20/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.2173 - accuracy: 0.9236 - val_loss: 0.2677 - val_accuracy: 0.9124\n",
            "Epoch 21/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.9258INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.2133 - accuracy: 0.9258 - val_loss: 0.1962 - val_accuracy: 0.9283\n",
            "Epoch 22/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9266INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 30ms/step - loss: 0.2060 - accuracy: 0.9267 - val_loss: 0.2010 - val_accuracy: 0.9298\n",
            "Epoch 23/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.2021 - accuracy: 0.9286 - val_loss: 0.2595 - val_accuracy: 0.9141\n",
            "Epoch 24/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.2069 - accuracy: 0.9269 - val_loss: 0.2901 - val_accuracy: 0.9027\n",
            "Epoch 25/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.2041 - accuracy: 0.9287 - val_loss: 0.2151 - val_accuracy: 0.9270\n",
            "Epoch 26/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1986 - accuracy: 0.9296 - val_loss: 0.3052 - val_accuracy: 0.8945\n",
            "Epoch 27/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9314INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.1947 - accuracy: 0.9315 - val_loss: 0.1991 - val_accuracy: 0.9309\n",
            "Epoch 28/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1921 - accuracy: 0.9331 - val_loss: 0.2142 - val_accuracy: 0.9284\n",
            "Epoch 29/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1926 - accuracy: 0.9327 - val_loss: 0.2161 - val_accuracy: 0.9265\n",
            "Epoch 30/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1813 - accuracy: 0.9356 - val_loss: 0.2162 - val_accuracy: 0.9272\n",
            "Epoch 31/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1845 - accuracy: 0.9354 - val_loss: 0.2935 - val_accuracy: 0.9083\n",
            "Epoch 32/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1858 - accuracy: 0.9352 - val_loss: 0.2389 - val_accuracy: 0.9189\n",
            "Epoch 33/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1804 - accuracy: 0.9366 - val_loss: 0.2198 - val_accuracy: 0.9275\n",
            "Epoch 34/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.1750 - accuracy: 0.9381INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod/assets\n",
            "210/210 [==============================] - 6s 29ms/step - loss: 0.1756 - accuracy: 0.9380 - val_loss: 0.1913 - val_accuracy: 0.9343\n",
            "Epoch 35/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1760 - accuracy: 0.9374 - val_loss: 0.2376 - val_accuracy: 0.9101\n",
            "Epoch 36/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1711 - accuracy: 0.9395 - val_loss: 0.2119 - val_accuracy: 0.9286\n",
            "Epoch 37/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1748 - accuracy: 0.9373 - val_loss: 0.3051 - val_accuracy: 0.9109\n",
            "Epoch 38/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1737 - accuracy: 0.9386 - val_loss: 0.2008 - val_accuracy: 0.9306\n",
            "Epoch 39/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1710 - accuracy: 0.9411 - val_loss: 0.2454 - val_accuracy: 0.9227\n",
            "Epoch 40/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1668 - accuracy: 0.9418 - val_loss: 0.2532 - val_accuracy: 0.9242\n",
            "Epoch 41/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1705 - accuracy: 0.9400 - val_loss: 0.3898 - val_accuracy: 0.8951\n",
            "Epoch 42/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1669 - accuracy: 0.9403 - val_loss: 0.2018 - val_accuracy: 0.9297\n",
            "Epoch 43/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1630 - accuracy: 0.9434 - val_loss: 0.2671 - val_accuracy: 0.9178\n",
            "Epoch 44/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1606 - accuracy: 0.9434 - val_loss: 0.2641 - val_accuracy: 0.9201\n",
            "Epoch 45/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1563 - accuracy: 0.9451 - val_loss: 0.2434 - val_accuracy: 0.9233\n",
            "Epoch 46/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1561 - accuracy: 0.9455 - val_loss: 0.2834 - val_accuracy: 0.9178\n",
            "Epoch 47/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1627 - accuracy: 0.9445 - val_loss: 0.2285 - val_accuracy: 0.9258\n",
            "Epoch 48/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1600 - accuracy: 0.9452 - val_loss: 0.2305 - val_accuracy: 0.9262\n",
            "Epoch 49/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1498 - accuracy: 0.9470 - val_loss: 0.2596 - val_accuracy: 0.9211\n",
            "Epoch 50/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1542 - accuracy: 0.9467 - val_loss: 0.2086 - val_accuracy: 0.9302\n",
            "Epoch 51/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1506 - accuracy: 0.9469 - val_loss: 0.2600 - val_accuracy: 0.9222\n",
            "Epoch 52/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1467 - accuracy: 0.9489 - val_loss: 0.2340 - val_accuracy: 0.9179\n",
            "Epoch 53/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1556 - accuracy: 0.9470 - val_loss: 0.2266 - val_accuracy: 0.9257\n",
            "Epoch 54/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.1468 - accuracy: 0.9476\n",
            "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1468 - accuracy: 0.9477 - val_loss: 0.2670 - val_accuracy: 0.9167\n",
            "Epoch 55/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1289 - accuracy: 0.9534 - val_loss: 0.2523 - val_accuracy: 0.9259\n",
            "Epoch 56/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1239 - accuracy: 0.9568 - val_loss: 0.2334 - val_accuracy: 0.9290\n",
            "Epoch 57/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1232 - accuracy: 0.9566 - val_loss: 0.2326 - val_accuracy: 0.9288\n",
            "Epoch 58/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1224 - accuracy: 0.9572 - val_loss: 0.2290 - val_accuracy: 0.9295\n",
            "Epoch 59/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1196 - accuracy: 0.9586 - val_loss: 0.2414 - val_accuracy: 0.9286\n",
            "Epoch 60/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1193 - accuracy: 0.9574 - val_loss: 0.2553 - val_accuracy: 0.9253\n",
            "Epoch 61/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1174 - accuracy: 0.9586 - val_loss: 0.2681 - val_accuracy: 0.9250\n",
            "Epoch 62/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1169 - accuracy: 0.9593 - val_loss: 0.2333 - val_accuracy: 0.9295\n",
            "Epoch 63/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1150 - accuracy: 0.9598 - val_loss: 0.2375 - val_accuracy: 0.9296\n",
            "Epoch 64/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1119 - accuracy: 0.9614 - val_loss: 0.2699 - val_accuracy: 0.9260\n",
            "Epoch 65/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1124 - accuracy: 0.9614 - val_loss: 0.2440 - val_accuracy: 0.9283\n",
            "Epoch 66/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1094 - accuracy: 0.9614 - val_loss: 0.2751 - val_accuracy: 0.9241\n",
            "Epoch 67/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1095 - accuracy: 0.9616 - val_loss: 0.2490 - val_accuracy: 0.9282\n",
            "Epoch 68/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1094 - accuracy: 0.9615 - val_loss: 0.2765 - val_accuracy: 0.9255\n",
            "Epoch 69/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1072 - accuracy: 0.9622 - val_loss: 0.2650 - val_accuracy: 0.9275\n",
            "Epoch 70/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1059 - accuracy: 0.9622 - val_loss: 0.2756 - val_accuracy: 0.9261\n",
            "Epoch 71/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1090 - accuracy: 0.9614 - val_loss: 0.2697 - val_accuracy: 0.9229\n",
            "Epoch 72/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1103 - accuracy: 0.9611 - val_loss: 0.2887 - val_accuracy: 0.9233\n",
            "Epoch 73/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1063 - accuracy: 0.9626 - val_loss: 0.2584 - val_accuracy: 0.9269\n",
            "Epoch 74/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9641\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1033 - accuracy: 0.9640 - val_loss: 0.2652 - val_accuracy: 0.9269\n",
            "Epoch 75/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1012 - accuracy: 0.9643 - val_loss: 0.2627 - val_accuracy: 0.9280\n",
            "Epoch 76/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0990 - accuracy: 0.9653 - val_loss: 0.2620 - val_accuracy: 0.9277\n",
            "Epoch 77/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0995 - accuracy: 0.9653 - val_loss: 0.2655 - val_accuracy: 0.9282\n",
            "Epoch 78/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0977 - accuracy: 0.9651 - val_loss: 0.2833 - val_accuracy: 0.9250\n",
            "Epoch 79/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.1010 - accuracy: 0.9653 - val_loss: 0.2701 - val_accuracy: 0.9272\n",
            "Epoch 80/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0976 - accuracy: 0.9656 - val_loss: 0.2683 - val_accuracy: 0.9281\n",
            "Epoch 81/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0963 - accuracy: 0.9663 - val_loss: 0.2639 - val_accuracy: 0.9282\n",
            "Epoch 82/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0985 - accuracy: 0.9649 - val_loss: 0.2644 - val_accuracy: 0.9285\n",
            "Epoch 83/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0978 - accuracy: 0.9654 - val_loss: 0.2791 - val_accuracy: 0.9266\n",
            "Epoch 84/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0963 - accuracy: 0.9661 - val_loss: 0.2690 - val_accuracy: 0.9278\n",
            "Epoch 85/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0961 - accuracy: 0.9665 - val_loss: 0.2862 - val_accuracy: 0.9249\n",
            "Epoch 86/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0966 - accuracy: 0.9664 - val_loss: 0.2876 - val_accuracy: 0.9258\n",
            "Epoch 87/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0946 - accuracy: 0.9671 - val_loss: 0.2770 - val_accuracy: 0.9271\n",
            "Epoch 88/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0962 - accuracy: 0.9661 - val_loss: 0.2725 - val_accuracy: 0.9275\n",
            "Epoch 89/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0974 - accuracy: 0.9650 - val_loss: 0.2677 - val_accuracy: 0.9287\n",
            "Epoch 90/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0959 - accuracy: 0.9672 - val_loss: 0.2751 - val_accuracy: 0.9275\n",
            "Epoch 91/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0932 - accuracy: 0.9669 - val_loss: 0.2784 - val_accuracy: 0.9274\n",
            "Epoch 92/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0946 - accuracy: 0.9664 - val_loss: 0.2775 - val_accuracy: 0.9278\n",
            "Epoch 93/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0941 - accuracy: 0.9666 - val_loss: 0.2857 - val_accuracy: 0.9257\n",
            "Epoch 94/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.0943 - accuracy: 0.9661\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0944 - accuracy: 0.9661 - val_loss: 0.2714 - val_accuracy: 0.9279\n",
            "Epoch 95/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0923 - accuracy: 0.9678 - val_loss: 0.2850 - val_accuracy: 0.9263\n",
            "Epoch 96/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0937 - accuracy: 0.9663 - val_loss: 0.2795 - val_accuracy: 0.9269\n",
            "Epoch 97/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0910 - accuracy: 0.9673 - val_loss: 0.2852 - val_accuracy: 0.9269\n",
            "Epoch 98/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0962 - accuracy: 0.9671 - val_loss: 0.2795 - val_accuracy: 0.9271\n",
            "Epoch 99/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0951 - accuracy: 0.9661 - val_loss: 0.2817 - val_accuracy: 0.9268\n",
            "Epoch 100/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0951 - accuracy: 0.9669 - val_loss: 0.2797 - val_accuracy: 0.9271\n",
            "Epoch 101/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0954 - accuracy: 0.9669 - val_loss: 0.2763 - val_accuracy: 0.9274\n",
            "Epoch 102/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0944 - accuracy: 0.9670 - val_loss: 0.2749 - val_accuracy: 0.9273\n",
            "Epoch 103/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0942 - accuracy: 0.9669 - val_loss: 0.2787 - val_accuracy: 0.9268\n",
            "Epoch 104/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0940 - accuracy: 0.9669 - val_loss: 0.2755 - val_accuracy: 0.9273\n",
            "Epoch 105/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0944 - accuracy: 0.9673 - val_loss: 0.2799 - val_accuracy: 0.9270\n",
            "Epoch 106/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0912 - accuracy: 0.9671 - val_loss: 0.2818 - val_accuracy: 0.9270\n",
            "Epoch 107/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0941 - accuracy: 0.9667 - val_loss: 0.2762 - val_accuracy: 0.9273\n",
            "Epoch 108/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0942 - accuracy: 0.9671 - val_loss: 0.2792 - val_accuracy: 0.9266\n",
            "Epoch 109/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0921 - accuracy: 0.9683 - val_loss: 0.2766 - val_accuracy: 0.9275\n",
            "Epoch 110/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0937 - accuracy: 0.9672 - val_loss: 0.2862 - val_accuracy: 0.9261\n",
            "Epoch 111/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0938 - accuracy: 0.9672 - val_loss: 0.2789 - val_accuracy: 0.9268\n",
            "Epoch 112/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0935 - accuracy: 0.9674 - val_loss: 0.2797 - val_accuracy: 0.9275\n",
            "Epoch 113/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0929 - accuracy: 0.9677 - val_loss: 0.2748 - val_accuracy: 0.9276\n",
            "Epoch 114/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9677\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0927 - accuracy: 0.9677 - val_loss: 0.2844 - val_accuracy: 0.9263\n",
            "Epoch 115/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0919 - accuracy: 0.9680 - val_loss: 0.2837 - val_accuracy: 0.9265\n",
            "Epoch 116/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0933 - accuracy: 0.9670 - val_loss: 0.2833 - val_accuracy: 0.9265\n",
            "Epoch 117/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0927 - accuracy: 0.9672 - val_loss: 0.2813 - val_accuracy: 0.9269\n",
            "Epoch 118/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0937 - accuracy: 0.9677 - val_loss: 0.2802 - val_accuracy: 0.9271\n",
            "Epoch 119/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0922 - accuracy: 0.9682 - val_loss: 0.2807 - val_accuracy: 0.9269\n",
            "Epoch 120/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0938 - accuracy: 0.9671 - val_loss: 0.2795 - val_accuracy: 0.9271\n",
            "Epoch 121/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0934 - accuracy: 0.9668 - val_loss: 0.2825 - val_accuracy: 0.9271\n",
            "Epoch 122/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0930 - accuracy: 0.9671 - val_loss: 0.2805 - val_accuracy: 0.9269\n",
            "Epoch 123/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0925 - accuracy: 0.9675 - val_loss: 0.2793 - val_accuracy: 0.9270\n",
            "Epoch 124/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0948 - accuracy: 0.9675 - val_loss: 0.2811 - val_accuracy: 0.9269\n",
            "Epoch 125/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0915 - accuracy: 0.9682 - val_loss: 0.2819 - val_accuracy: 0.9270\n",
            "Epoch 126/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0947 - accuracy: 0.9668 - val_loss: 0.2802 - val_accuracy: 0.9270\n",
            "Epoch 127/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0944 - accuracy: 0.9667 - val_loss: 0.2797 - val_accuracy: 0.9269\n",
            "Epoch 128/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0941 - accuracy: 0.9667 - val_loss: 0.2800 - val_accuracy: 0.9271\n",
            "Epoch 129/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0928 - accuracy: 0.9674 - val_loss: 0.2797 - val_accuracy: 0.9273\n",
            "Epoch 130/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0929 - accuracy: 0.9667 - val_loss: 0.2804 - val_accuracy: 0.9270\n",
            "Epoch 131/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0936 - accuracy: 0.9669 - val_loss: 0.2807 - val_accuracy: 0.9270\n",
            "Epoch 132/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0949 - accuracy: 0.9662 - val_loss: 0.2799 - val_accuracy: 0.9270\n",
            "Epoch 133/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0917 - accuracy: 0.9675 - val_loss: 0.2791 - val_accuracy: 0.9272\n",
            "Epoch 134/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9673\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0917 - accuracy: 0.9675 - val_loss: 0.2788 - val_accuracy: 0.9273\n",
            "Epoch 135/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0910 - accuracy: 0.9673 - val_loss: 0.2790 - val_accuracy: 0.9271\n",
            "Epoch 136/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0910 - accuracy: 0.9678 - val_loss: 0.2787 - val_accuracy: 0.9273\n",
            "Epoch 137/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0901 - accuracy: 0.9684 - val_loss: 0.2791 - val_accuracy: 0.9271\n",
            "Epoch 138/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0914 - accuracy: 0.9675 - val_loss: 0.2793 - val_accuracy: 0.9271\n",
            "Epoch 139/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0937 - accuracy: 0.9669 - val_loss: 0.2794 - val_accuracy: 0.9271\n",
            "Epoch 140/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0925 - accuracy: 0.9673 - val_loss: 0.2797 - val_accuracy: 0.9270\n",
            "Epoch 141/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0911 - accuracy: 0.9685 - val_loss: 0.2795 - val_accuracy: 0.9270\n",
            "Epoch 142/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0915 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 143/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0933 - accuracy: 0.9669 - val_loss: 0.2797 - val_accuracy: 0.9270\n",
            "Epoch 144/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0935 - accuracy: 0.9669 - val_loss: 0.2794 - val_accuracy: 0.9271\n",
            "Epoch 145/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0913 - accuracy: 0.9678 - val_loss: 0.2794 - val_accuracy: 0.9271\n",
            "Epoch 146/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0932 - accuracy: 0.9676 - val_loss: 0.2792 - val_accuracy: 0.9272\n",
            "Epoch 147/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0930 - accuracy: 0.9665 - val_loss: 0.2791 - val_accuracy: 0.9271\n",
            "Epoch 148/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0914 - accuracy: 0.9676 - val_loss: 0.2788 - val_accuracy: 0.9273\n",
            "Epoch 149/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0918 - accuracy: 0.9670 - val_loss: 0.2792 - val_accuracy: 0.9271\n",
            "Epoch 150/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0910 - accuracy: 0.9677 - val_loss: 0.2794 - val_accuracy: 0.9271\n",
            "Epoch 151/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0932 - accuracy: 0.9671 - val_loss: 0.2794 - val_accuracy: 0.9271\n",
            "Epoch 152/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0913 - accuracy: 0.9677 - val_loss: 0.2795 - val_accuracy: 0.9270\n",
            "Epoch 153/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0931 - accuracy: 0.9676 - val_loss: 0.2796 - val_accuracy: 0.9270\n",
            "Epoch 154/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.0949 - accuracy: 0.9670\n",
            "Epoch 00154: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0948 - accuracy: 0.9670 - val_loss: 0.2798 - val_accuracy: 0.9270\n",
            "Epoch 155/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0918 - accuracy: 0.9678 - val_loss: 0.2797 - val_accuracy: 0.9270\n",
            "Epoch 156/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0921 - accuracy: 0.9668 - val_loss: 0.2796 - val_accuracy: 0.9270\n",
            "Epoch 157/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0926 - accuracy: 0.9673 - val_loss: 0.2796 - val_accuracy: 0.9270\n",
            "Epoch 158/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0912 - accuracy: 0.9674 - val_loss: 0.2796 - val_accuracy: 0.9270\n",
            "Epoch 159/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0907 - accuracy: 0.9672 - val_loss: 0.2797 - val_accuracy: 0.9270\n",
            "Epoch 160/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0897 - accuracy: 0.9674 - val_loss: 0.2796 - val_accuracy: 0.9270\n",
            "Epoch 161/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0913 - accuracy: 0.9681 - val_loss: 0.2796 - val_accuracy: 0.9270\n",
            "Epoch 162/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0918 - accuracy: 0.9670 - val_loss: 0.2796 - val_accuracy: 0.9270\n",
            "Epoch 163/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0925 - accuracy: 0.9675 - val_loss: 0.2797 - val_accuracy: 0.9270\n",
            "Epoch 164/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0919 - accuracy: 0.9680 - val_loss: 0.2797 - val_accuracy: 0.9270\n",
            "Epoch 165/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0933 - accuracy: 0.9666 - val_loss: 0.2797 - val_accuracy: 0.9270\n",
            "Epoch 166/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0919 - accuracy: 0.9674 - val_loss: 0.2797 - val_accuracy: 0.9271\n",
            "Epoch 167/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0913 - accuracy: 0.9675 - val_loss: 0.2797 - val_accuracy: 0.9271\n",
            "Epoch 168/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0918 - accuracy: 0.9677 - val_loss: 0.2796 - val_accuracy: 0.9271\n",
            "Epoch 169/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0936 - accuracy: 0.9670 - val_loss: 0.2796 - val_accuracy: 0.9272\n",
            "Epoch 170/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0929 - accuracy: 0.9674 - val_loss: 0.2796 - val_accuracy: 0.9271\n",
            "Epoch 171/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0939 - accuracy: 0.9673 - val_loss: 0.2796 - val_accuracy: 0.9272\n",
            "Epoch 172/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0931 - accuracy: 0.9670 - val_loss: 0.2797 - val_accuracy: 0.9272\n",
            "Epoch 173/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0931 - accuracy: 0.9676 - val_loss: 0.2797 - val_accuracy: 0.9272\n",
            "Epoch 174/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9672\n",
            "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0927 - accuracy: 0.9671 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 175/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0935 - accuracy: 0.9668 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 176/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0932 - accuracy: 0.9670 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 177/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0940 - accuracy: 0.9676 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 178/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0940 - accuracy: 0.9669 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 179/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0917 - accuracy: 0.9676 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 180/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0936 - accuracy: 0.9670 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 181/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0933 - accuracy: 0.9674 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 182/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0916 - accuracy: 0.9683 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 183/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0927 - accuracy: 0.9679 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 184/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0924 - accuracy: 0.9678 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 185/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0924 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 186/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0935 - accuracy: 0.9669 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 187/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0926 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 188/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0926 - accuracy: 0.9674 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 189/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0906 - accuracy: 0.9685 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 190/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0941 - accuracy: 0.9674 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 191/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0920 - accuracy: 0.9679 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 192/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0916 - accuracy: 0.9680 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 193/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0954 - accuracy: 0.9668 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 194/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9679\n",
            "Epoch 00194: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0929 - accuracy: 0.9679 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 195/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0903 - accuracy: 0.9682 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 196/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0926 - accuracy: 0.9678 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 197/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0926 - accuracy: 0.9680 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 198/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0929 - accuracy: 0.9672 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 199/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0933 - accuracy: 0.9670 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 200/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0923 - accuracy: 0.9677 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 201/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0939 - accuracy: 0.9669 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 202/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0939 - accuracy: 0.9671 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 203/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0917 - accuracy: 0.9677 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 204/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0939 - accuracy: 0.9678 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 205/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0919 - accuracy: 0.9684 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 206/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0930 - accuracy: 0.9683 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 207/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0916 - accuracy: 0.9676 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 208/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0922 - accuracy: 0.9680 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 209/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0933 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 210/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0900 - accuracy: 0.9682 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 211/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0910 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 212/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0944 - accuracy: 0.9662 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 213/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0941 - accuracy: 0.9669 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 214/250\n",
            "209/210 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9673\n",
            "Epoch 00214: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0934 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 215/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0933 - accuracy: 0.9666 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 216/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0923 - accuracy: 0.9681 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 217/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0905 - accuracy: 0.9683 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 218/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0910 - accuracy: 0.9677 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 219/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0919 - accuracy: 0.9679 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 220/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0918 - accuracy: 0.9681 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 221/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0916 - accuracy: 0.9671 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 222/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0921 - accuracy: 0.9674 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 223/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0912 - accuracy: 0.9677 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 224/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0931 - accuracy: 0.9668 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 225/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0927 - accuracy: 0.9675 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 226/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0926 - accuracy: 0.9680 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 227/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0901 - accuracy: 0.9688 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 228/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0903 - accuracy: 0.9688 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 229/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0934 - accuracy: 0.9676 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 230/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0924 - accuracy: 0.9682 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 231/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0913 - accuracy: 0.9679 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 232/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0938 - accuracy: 0.9680 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 233/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0917 - accuracy: 0.9681 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 234/250\n",
            "208/210 [============================>.] - ETA: 0s - loss: 0.0927 - accuracy: 0.9673\n",
            "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0925 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 235/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0937 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 236/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0926 - accuracy: 0.9671 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 237/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0924 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 238/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0896 - accuracy: 0.9683 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 239/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0938 - accuracy: 0.9676 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 240/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0943 - accuracy: 0.9678 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 241/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0923 - accuracy: 0.9676 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 242/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0930 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 243/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0943 - accuracy: 0.9666 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 244/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0914 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 245/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0913 - accuracy: 0.9686 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 246/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0941 - accuracy: 0.9671 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 247/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0938 - accuracy: 0.9673 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 248/250\n",
            "210/210 [==============================] - 5s 24ms/step - loss: 0.0917 - accuracy: 0.9682 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 249/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0913 - accuracy: 0.9686 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Epoch 250/250\n",
            "210/210 [==============================] - 5s 23ms/step - loss: 0.0924 - accuracy: 0.9678 - val_loss: 0.2798 - val_accuracy: 0.9271\n",
            "Time: 1256.3284544944763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz0oGxt9B9C4",
        "outputId": "62f9a97f-eba0-4e05-8889-6a1ec1db5aa7"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/test1ksims.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Piloso/test1ksims.zip\n",
            "replace simModel1.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel1.npy           \n",
            "replace __MACOSX/._simModel1.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._simModel1.npy  \n",
            "replace simModel2.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel2.npy           \n",
            "replace __MACOSX/._simModel2.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._simModel2.npy  \n",
            "replace simModel3.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel3.npy           \n",
            "replace __MACOSX/._simModel3.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._simModel3.npy  \n",
            "replace simModel4.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel4.npy           \n",
            "replace __MACOSX/._simModel4.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._simModel4.npy  \n",
            "replace simModel5.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel5.npy           \n",
            "replace __MACOSX/._simModel5.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._simModel5.npy  \n",
            "replace simModel6.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel6.npy           \n",
            "replace __MACOSX/._simModel6.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._simModel6.npy  \n",
            "replace simModel7.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: simModel7.npy           \n",
            "replace __MACOSX/._simModel7.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: __MACOSX/._simModel7.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYZM0kNZQUfR",
        "outputId": "3a183ada-dbcb-45e9-8149-26ecb640ee45"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 10K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing test set simulations.\n",
        "t1 = np.load(\"/content/simModel1.npy\",mmap_mode='r')\n",
        "t2 = np.load(\"/content/simModel2.npy\",mmap_mode='r')\n",
        "t3 = np.load(\"/content/simModel3.npy\",mmap_mode='r')\n",
        "t4 = np.load(\"/content/simModel4.npy\",mmap_mode='r')\n",
        "t5 = np.load(\"/content/simModel5.npy\",mmap_mode='r')\n",
        "t6 = np.load(\"/content/simModel6.npy\",mmap_mode='r')\n",
        "t7 = np.load(\"/content/simModel7.npy\",mmap_mode='r')\n",
        "t=np.concatenate((t1,t2,t3,t4,t5,t6,t7),axis=0)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(t):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      t[arr][idx][t[arr][idx] == 0] = -1\n",
        "      t[arr][idx][t[arr][idx] == 1] = 0\n",
        "      t[arr][idx][t[arr][idx] == -1] = 1\n",
        "\n",
        "t=t.astype(np.uint8)\n",
        "\n",
        "# Label simulations from the test set.\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y.extend([5 for i in range(len(t6))])\n",
        "y.extend([6 for i in range(len(t7))])\n",
        "y = np.array(y)\n",
        "\n",
        "# Load the trained model.\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod')\n",
        "\n",
        "# Predict and export a confusion matrix.\n",
        "pred = model.predict(t)\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[867   0  23   0   0 110   0]\n",
            " [  4 876   0  12   5   0 103]\n",
            " [  0   0 995   5   0   0   0]\n",
            " [  0   0  46 913  41   0   0]\n",
            " [  0   1   0   0 999   0   0]\n",
            " [ 35   0   9   0   0 956   0]\n",
            " [  0  78   0  13   6   1 902]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "0PGIawyJEDo0",
        "outputId": "1be09650-4f0a-4e4a-9ca2-e2dd0309ebc6"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Predict the most likely model for the empirical data, using the CNN trained with 10K simulations per model.\n",
        "################################################################################################################################################\n",
        "# Load the trained network.\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims.acc.mod')\n",
        "# Load empirical data and transpose it.\n",
        "infile=np.loadtxt(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Input_Piloso.txt\")\n",
        "inp=[]\n",
        "inp.append(np.array(infile).T)\n",
        "inp = np.array(inp)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for idx,row in enumerate(inp[0]):\n",
        "  if np.count_nonzero(row) > len(row)/2:\n",
        "    inp[0][idx][inp[0][idx] == 0] = -1\n",
        "    inp[0][idx][inp[0][idx] == 1] = 0\n",
        "    inp[0][idx][inp[0][idx] == -1] = 1\n",
        "\n",
        "inp=inp.astype(np.uint8)\n",
        "\n",
        "#Export an image from the empirical data, to visualize its appearance\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(inp[0],cmap='gray', vmin=0, vmax=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb82ce51da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG8AAAD8CAYAAAB5N/qNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO19eXQUVdr+c6uX7FuHrATIpBuInaZVwtEokaOfLEaITMZhO64cAT8P+QB/iqAIog7qMI5HnZFhVHQUEBxnRFBcBsVhibITkihEiGBCQhKyQEL2pN/fH73Y3em9q7qqQ55z3tNdt27d+1a9dW/d5V0YEWEQwQlObAYG4TsGhRfEGBReEGNQeEGMQeEFMQaFF8QQTHiMsTsYY+WMsTOMseVC1XM1gwkxz2OMyQD8BGASgPMADgOYQ0Q/8l7ZVQyhWt4NAM4Q0c9E1A1gK4DpAtV11UIuULlDAVRZHZ8HcKOzzIwxSS7zaLVa1NTU4NKlS2Kz0kBECfaJog1YGGMLGGNHGGNHxOLBHSorK3HlyhWfruU4Ds3Nzbh06RIyMzP9ZeUXh3X4W6oTVAMYZnWcZkqzgIjeJKJxRDTO/uLCwkK88sorAICYmBj88MMPYIwJxKpzXLlyBb29vSgsLMTJkyexbds2j681GAy46aabkJOTg7NnzwrDIBHxTjB2xz8D+A0AJYATALJc5CdrGjVqFI0dO5YAkEKhoKlTp5J9Hr7onnvuoWXLlrnMM2rUKJo2bRpNmDBBMD7c0BGHz00I4ZkEcieMI84KACvc5BXrodD48eMpPz/fq2sYY7R27VoKDQ0VVXhCDVhARJ8D+Fyo8s2Ii4vD9OnGgew//vEPr68vKiryqd4hQ4aI0pVbQ5B5ntdM+DHa1Gg0eO+992AwGDBhwgT4cj/x8fEYPXo0AOO36sCBA76yIxSOOhobCNZtetnF+tylyOVySklJ8atbys/Pp6qqKqqqqqLKykoyvUxSosB+8wIlPJ1ORxcuXBD04clkMlIqlaRQKCQlvKBfmC4rK0NKSoqgdaxatQpdXV04ckRiU1KxW511yzt69ChNnz5d7C4qaFqe6IKzFl5iYmIgh9+SpszMTCotLQ0e4UmV5s2bR0VFRfTee+95fA1jjPbt20dFRUWUkZHhdZ3h4eF0ww03uBSeYPO8gYLCwkLEx8fjrbfeQnNzs8fXERE2bNgAAGhqavK63vb2dhw6dMh9JWITJNC6nNH9999PEydOJACUkJBAhYWFYvAx2G36S+np6bRlyxaH5wRe/xyYwgsJCaHMzEzKzMwUVbCFhYV08uRJ2rZt26DwnFFkZCTFxMRQSEgIAcZJ+qVLl6ipqUmKKyNXh/DMD54x5pDMN1JaWkpERKtWrep3k/Z57ct1lNfZNY7SHdXn6tjdtZ6SM+FJYoUlOzsbfX190Ol0+Oijj9DX12dD3d3dblfwOY5DT0+PpRwAWL16NbZs2QK9Xo+LFy/a5D9x4oSl/C1btjgsp6+vDwUFBU7rbGxs7FeXJ9Dr9f3u0RU5gyR2FeRyOUVGRqK1tRWhoaFQKBT98ly+fBkAEBUVBY7j0NnZia6uLps8MTExAIDW1lYYDAaEhobi7rvvRmFhIWbPno0TJ05Y8k6ePBnl5eUAgJ6eHrS3t/crBzAO2Xt6egAAWVlZKCoqgsFgQHx8PKKionDlyhVLXRzH2ZTjDBzHISoqytPHg8uXLzvcVZCE8IRUQIqOjsaQIUNw7tw5G12SioqKfsJ3h5CQEKjVajDGsHXrVtx8881obW3lm2VHGJhbQunp6bRjxw765JNPAjpgyc/PJ7lcLuqAJehXWNra2rB//37rF4F3TJo0CRMnTsSFCxfw6quvAgA+/fRTQeryCmK3On9bXiDo2WefJSKiEydOiMUDvy2PMTYMwPsAkkwVvElErzHGVgOYD8A8vHuKjPoskkV8fDxGjhxpObZXg6iqqsKBAwdw+vTpQLPmGn60lhQAY03/o2DUFNMCWA3g8WBqefn5+VRdXU3V1dVUVVUl6mQ/KiqK4uLiSC6XU2pqKqWmpjpteXx2fdthNCwJqPAYY6RUKkmpVIr6AvBFq1atos2bN5NOp6Ouri7q6uoSVngA0gFUAog2Ce8cgBIA7wCIE1J4er2eiIj6+voGl8d8EFwkgKMAfmc6TgIgg1GVfg2Ad5xctwDAERP5fGOMMQoJCbGsdQpBK1eupM7OTjp8+PDAER4ABYCvAPw/Fy2yzF05Y8aMsaje3XHHHRam7VQBRKPo6GhKS0ujxMTEgSE8AAzG0eardukpVv8fBbDVXVkRERE0fvx4Gj9+PMXHx1uYDg8PpxtvvFGQB/L++++LaXsguvByTQWXACg20Z0ANgIoNaXvsBamEN88X6mgoIBGjBjh07WMMXr77bcpLCwsOIXHJwl98wkJCbRw4ULeymOM0Z/+9CfRDU0ksSVkD41Gg+uuu4638iIiInDLLbfwVh4RYenSpejs7OStTF8gSeHl5eXhgQceQEhICDQajd/lnTt3DrNnz+aBs18xevRocJzIj0/sLtNVt6nT6ejcuXOB6po8Jo7j6NKlSxQdHe3wXFRUVEC6TdEF5+03T+oTcb1eTw0NDQERniS7TVcoLi5GQUEBVq9eja1bt/pdHl/lmFFSUoKEhH6OG4SB2K3O25YXFRVFCoWCQkNDKSIiwmGeoqIiam5upieeeMJtea7KkRBJt9vUarVUWlpKGo2Gl5tVq9WUlZVFCQkJYj90j2nbtm1UWlpKjzzySHAJLyYmhqZPny7Ehz5gNGfOHFq6dKnP19922200ffp0Gj16tMfCGzAKSIwxrFmzBowxvPrqq6irq+ODNY+Rm5uL+Ph4bN++XYjiB6b2WFxcHKZNmwaO4/Duu++CMYYxY8agrKyMTxbFhkPhSUIBKSIiAjqdDiUlJejo6EBaWhqGDh0KAOjt7cXRo0edXhsfH4+FCxcCgMUkSqPRICIiAoBRMfbMmTMe8SGTyTBu3DgcPHjQbd4bbzS6UjPzbEZ4eDjGjBkDAJZydDqdDT81NTW45pprbO5Lp9OhurraKzMy0b93RAS9Xk81NTUWY5HHH3+campqqKamhn788Uevvx+7d++mmpoaam1tpR07dlBKSopHlJmZSQaDgVJTU23SIyMjCfjV80RqaipVV1fb8GwmrVZLNTU1NuoUZn5qampo/fr1pNVq+93X7t27KS8vz9k9SXfA4olAFAqFDXEc5/K8QqGgZ599lrq7u/2mFStWEGBc8enu7qaOjg4KCQlxWKc1mXmTy+Uu8ygUCmKM2eSz0wkNXuFxHEcGg4GsYW1oolKpyBEcGaPwQY74sYe1WobZOMZZnkuXLpFOp6OPP/7Ycs5OzXBgrLCYsXLlSnR0dKCjowM1NTVis8MLZs2ahRdeeMHj/EEz2kxLS/Pa19fly5fR0tLiM1/+8ENEOH/+PAAgOTnZofEMYwz79u3DlClTsH79erz00kv47rvvEBMTY3HLBQDDhw8fmLYKwUhqtZp27txJACg3N5dkMhmNHTvWRgUkIiKCcnNzKTc312m3KYmWl56eTitXrnR63mAwYMGCBQHkSFioVCrceeed2LRpk6eXSHee19fX57J7MxgMAeSmP3JycnDTTTehoaEBGzdu9Lu8pqYmbwTnFH4LjzF2DkArgD4AvUQ0jjGmAvAhjKp/5wDMJCKns8+Wlhbs2rXLaR1i9w4ajQaTJk3C2bNneREeX/C72zQJbxwRNVilrQXQREQvmQJixBHRMmdlmIbJTuswGAzQarVeCzE+Ph7x8fFeXeMIjY2NaGxsREhICEaMGAEA+Omnn/wu1wsIM2CBsWUNsUsrh0nlD0aDlHIxBixPPvkktbS0eE1ERK2trZZjsw9qnU5HLS0tdOnSpUDv6Aum7n4WwDEYVd4XmNIuWZ1n1sdSH21yHEd9fX0UExMjOi+BEN5Q028ijF7cJ9gLC0Czg+t4sVUQSoD2aTNmzKDjx48PLOHZCWQ1gMchkW6TT1IoFJSTk0MVFRWSEZ5fy2OMsQjGWJT5P4DJAMpgVHN/wJTtARht9ySJhQsX4uWXX3abr6enB8XFxZg6dWoAuPIQfra0DBi7yhMAfoApfgKAeADfADgN4GsAKim0PMYYffzxxxQeHm5Jy8zMpHHjxonest2QdFdYAhUIiuM49Pb2Ii4uzuKUJ0gg3RUWT3DPPfeAMYbPPvvM56haRIRNmzZZPBp5Cr1eD71ej+bmZuzcudOnugUBnwMWP7pft93dgQMH6ODBgz65/PWXFixYQAcPHqSNGzfyUl5YWJglVpKHFLybsQONtFotnTx5kgBQcnIyJScnW3bOIyMjKTY2dlB4ZmKM9VNNkAJxHEednZ3U3d1NWVlZBPzqDWJQeCYaAB4jBpYahCcwq0q49ZIepAiKqQJjDGfPngVjzMZPpjvExMTY+M4kIlRVVbm4QrIIbjWI3NxcmjBhgs0EO1A0d+5c2rNnD73zzjuS6jYlMc8bMWIE6uvrbTSP7bF///4AcmSLkpISbNq0CQ0NDe4zBxCS6DaHDRtGDQ0Nohvo+4OcnBzExcXhiy++EKJ4h92mJAYs58+fD2rBAcDIkSPderDQaDS49tpreatTEi1PqLVNlUoFlUplk+ap0YlarUZVVRW6u7sdntdoNPj555+9Uo5atGgRMjIysGTJEnAch4yMDE/5Ce4BizPiOI4iIyMtZH1uxYoV1NraaiFv1BeqqqpIq9U6rfPy5cv9dtvlcrnHA6q4uDhv+BmYk3TzBNwMMdUXZs6cScXFxQEbbQ6IbtPamY3QOp4qlQp1dXVQKpVw9Ow4jhOCB+kOWPyFwWCwkNBobm5GUlKSQ8GZeQGMCwsNDQ1obGy0iefAK8TuMv3tNoWioqIiv71T6HQ60ul0fDhyle4kXYrIyspCaGioX2UIbRc/KDwneP755/3yKMEYw3PPPQcA+Otf/yqIdwp/4iqMhtEewYwMAKsAxMLLuAoqlQpTpkxxWZ+nEbJ8RWxsLPLy8ix1/fnPf3abxx3S09PBcZxD2zw+wMtokzEmA1AN4EYAcwFcISL3+nQmXHPNNfT+++/bpKlUKqSmpqKsrAxEhJycHKeDBD6g0WjwwQcfOKwrNTUVqampSEtLw1NPPRUQfuwg3CQdRn3NItP/1eAhrsJdd91Fu3fvFn3gAoCWLl1KtbW1HvEjl8spKSmJkpKS+ORB0LgK7wAotBLeOQQorgKfxIeqhNljRGdnJ5+79oLZKigBNABIMh0HNK4CXyRxVQnBhDcdwH+cnEuHB3EVJPBwiDFGYWFhgfTY7pCefvppam9vtyEhhbcVwFyrY6/jKji6ialTp9IXX3whulADTTExMTRixAgbEkR4ACIANAKIsUrjJa5CQkICZWdnu71ZtVpNO3bsEP2hC0wDc1dBpVLRAw884PBcfn4+zZ8/33LMGKP169fT+vXrzaHNLDR06FB65ZVXxBaSV8IL+hWWpqYmi7MZe/T29vazS+js7ARjzPzSWEBEvO/mL1q0CACwefNmNDY28lo2MMB30vmCWq2GWq1GS0tLv6iWzsAYwxdffAHGGB5++GGcO3fOHxak6yw1NDSUhg0b5jKPp+oLQmDx4sUoLCzEqVOnkJ+fLwYL0hXe2LFjae/evU7PGwwGxMbG9uvqpI7IyEgAQHt7u797jQNTh0WqZPYqQUSk0+kG7oAlOzvbpWtgg8GAkJCQoGp5BoMBSqUSgNE9lxCQRLcpl8spNjbW6XkiQlNTUwA5Eh9ZWVnYvn27ORDWYLfpKz3yyCO0du3agNYZGhpqsdmDlLvNjIwMrF271ul5IsLMmTNF6zaTk5MxZ84cyGQyPPbYYwGps7OzEz/88IPLPJIQXkdHB4qLi52et2qhvKGwsBBJSUn45ptv8N///tdl3t27d6Onpwf19fW88uAvJCG8rq4uVFRUOD0vRIsbNmwYhg0bhmPHjrnNu2fPHuzZs4d3HvyFJAYsWq2WXPmxNBgMuPHGG70WYmpqKlJSUvxlDzU1Nbhw4QLCwsKg1WoBwBLQQqvVoqamxuJeJCwsDKNHj7bpSezz+ICrb8DyxBNPUF1dnd/02GOPEWD04lBXV0cXLlywbNju2bPHJpiFVqulU6dOEQBKTEwkxli/PD5QcKq7y+Vy9Pb2BpIdXsBxHDo6OpCYmMiHt6XgU3fX6/UBj8bFF8wLC0K6yZK08EpLS5GWliZI2YcPH0Z7ezuefPJJQcoPCMT+3ok1SU9NTaX09HTeTcIyMzOFcKoanN88d8jIyMCGDRts0ubOnevv/pnPiIiIwPXXX8+3A4Tg++Z5gsuXL+PDDz+0IXOMhmnTpmHevHkur7fPwxjDunXrEBYWhpUrV+Jvf/ubRcXdkzyxsbG45557sG7dOkv+lStXurVX9wUeTdIZY+8AmAagnoh0pjSHsROYMcDOawDuBNAO4EEicj8T9hGNjY1Yv369w3NE5HZF31Ee83Fvb6/Tka6rPNbH8+fPF24v0sNv0gQAY2GlgwlgLYDlpv/LAfzR9P9OAF/A6NU9B8BBKX7zfKHIyEi6/fbb6fbbb/f4mk8++YTS09MF+eZ5M6hItxOeQyfgAP4OYI6jfEIIT6lUUkZGhoUceWbnizIzM6miooJOnz4dXHEVHAjPYewEAJ8ByLU69w2MEU/sy+NF3V2n01FbW5uF7EePMpmMQkND+10XFhZG4eHhknPj6I3weBmwkFEa5OU1bxLROEejKG9QVlaGiIgIC9lPiu+++26HGl+HDh1CW1vb1THPQwC6zeLiYurt7aWnn36at7eWMUYymaxfukwmI5lM5lH398wzz1Bvby8dO3bMJr2hocF6w9Qp8XBfvHebf4LtgGWt6f9U2A5YDnk6YImLi6MhQ4ZYHNFkZWXRTz/9JHaXReHh4TRkyJB+7oPj4+Mdvhj2ZH9fARUegC0ALgDoAXAewENwEjvBJLQ3AFTAaLPQ73vn6YAlLCzMJ82rf/7zn3TbbbeJLnQeaWDaKjiiKVOm0NChQ8V+4E5pxIgRtGHDBr+FJ4mddL7x1VdfYdasWaitrZXkDnhnZyfKy8vBGMOqVavcBjJevXq1w/QBKTzAGE1Z7H3AGTNmgDGGL7/80iasal1dHdauXQvGGK655hqvo1BbIHaXKUS3KSaZv9OMMTp69CgdO3aM1Gq1v+VePd88vsnZaNMRCTRCHhjC83Ru5g05mwuaydk8L4A0MIRXWlpKBQUFvD4cAf1kCiq8oN/P4ws+DxrEhNitztuWl5aWxntshYiICJfzwiVLllBFRQXt3LnTJr24uJhGjRrlUR3r1q2j//u//+O15QXdVOH8+fO8l9nW1oa2tjan5+Pi4pCRkYErV67YpC9evBjV1dUe1bF+/Xqb6QIfCDrhiYGdO3eivr6+X1AMVwsAjDG8/vrrAIAXXngBJSUl/DMmdpfpbbcZLMRxHBkMBiIa4JaxAxFEhN27d4Mx1q+7tcZtt92Gffv2+bYaJHarG6gtDwClp6dTenq60916xhhVVFRQVFSUTy1PdMENFOEpFApSKpWWY47jqLW1ldra2pwG1/CCBrtNIfH0008jMzMTs2bNAmC0VYiKihK2UrFbXTC0vGeeeYY++OADl3k4jrPRXOM4jrq7u6mnp8cjVQk3NNht+krh4eEUHR3t9XUJCQmUkJDgdN2UMUa1tbVUX19PmZmZNue0Wi3V19dTfX39oPD4JMYYHTlypF/gKU9Jo9FY/FWPHTuWxo4d20890RxL3RRPfWALjzFGW7ZsCVhY0lmzZvms8xkbG+vt4rpvVkJO7BT+BCAfQDeMikZziegSYywdwEkY1f0A4AAR/a/LCuCflVBSUhIefvhhAIBMJsOLL74Y9IEUHcChlZAno81/APgrAOvAB7sAPElEvYyxPwJ4EsAy07kKIuLfJMYJQkNDMWbMGBgMBsyePRvuXkap4fe//z0A4D//+Y/N2mdMTAwmTZoEAPjXv/7l+GIPu7V0OHH0DaAAwGZ3+YL5m5ecnGz29cwrMcbo2LFjdPz48X5Bp0aNGkXHjx83G2r6pbfpSnifArjXKl8bgOMA9gC4xUWZftkqhIeHe7IywQstW7aM3n77bTFfIP6FB2AFgG341Z9LCIB40/9sAFUAooVoec888wxt2bLF7Zstk8kEtRwKSuEBeBDA9wDCXVz3X/ihMe0vPfvss0REUldxCKzwANwB4EcACXb5EgDITP8zYAwOpRJLeAqFgiIiIkQJdMFxHLW0tFBra6tga5ueCM6RncIZGLvEYhOtN+W9G8APprRjAPI9fDnEfrMFIbVaTWq12mbB2hl9/vnndObMGSosLCTAaMh55swZOnPmjO/CCwSJ/ZABUEZGBv373/8Wrf6cnByaNGkSZWRkEGA0oZ40aRJNmjRpUHjuKD4+3iaAhj1dd911tGzZMsH5yMvLo9dff92+rsEtIWvMnDkTKpXKctzY2Ii33nrLYZ7Dhw8DMK7mzJ07F++++65gfMlkMigUCsjlHohG7Fbnacu79dZbSS6X8/aGb9iwgb799lsLOZrHmfPcf//9BBi71u3bt4vRMwSvByTGGCoqKnDttdeitbU1UGwFBCNGjLAo/NbX10OpVMLeWfq5c+ekGxRDCuFoGGOW0NodHR0BqZPjOFy+fBkymQwAMHv2bOj1ejz11FM2+cLDw68+Z6neUDBGrhy0VTChpKQECoXC6+Abx48fx29/+1sBOXMBsVudVFqer6RSqSgkJMRy7MiVMQ80OM9zRA8//DAdOXLErYKRpxQWFkbZ2dkeRd30V3hX7TzPjKKiIrS0tDj0vP7HP/4RH330EY4cOeJxeR0dHRbP70JDEsJLSUlBU1MTurq6Al53WVkZysrKHJ6rqqpyqaouNiQxVVCr1VRbW4v29naxWQk4CgoKwHEcdu3a5coE7Oqb5yUlJSEpKckmzWxqNWrUKMu8DjD6Rvnpp59s8prz1NXVCeJlnjGGY8eOgeM43H333a6ic15987xly5ZRQ0ODherr6y0jwH379tmcKyoqovj4eFKpVJbrzXmWLl0q2oAKwTDa5DjOoSc+c5rQD0iv11Nvby91d3d7NcQ38y3wxF7ak/TGxkaLv+aVK1cCMAbF6O3tRXd3t+AG/yUlJZDL5VAqleYXyiMUFxfb8BxQiN3qzC0vIiKCIiMjKTIy0rLzzHGcJQ0idlsrVqyg1tZW+v777/udCw8Pt+HZG/JCVUK63aZOp6OoqCjauXMnTZ48mRYvXkynT5+mTz/91K+HvnjxYnrttdcoMzOTTp8+TeXl5T51byqVijQaDQ0bNoz3F0Oj0ZBGo3EnfJ91WN4BUA9bBaTVMCoXmXVY7rQ69ySMOi7lAKZ4Irzo6GiSy+V08803U2JiIqnVapo8eTLl5OT49WDUajXp9XqKjIykyZMn05QpU+jLL7+kr776ig+P64Ekn4XnyC3/agCPO8irBXACRv3N38BoxyDzpNsMFC1atIgWLVpE8fHxARdCXl4ePfjgg7wJz+0KCxHtNRmQeILpALYSUReAs4yxMwBugFG/0y1mzJiBw4cPY8iQIYiNjcXXX3/tYbWew+xeQwzI5XIoFAr+yvPj2kLG2P0wqqs/RkTNAIYCsHalft6U5hHuvPNOXLhwASNHjsTw4cNdCi89PR3h4eH48ccffWQ/8Pj000/5LdDD0WA6bLvNJAAyGGMRrQHwjin9rzDZLZiONwD4vZMy/bJVePTRR+mNN94gwDhqGz58uNjfJSFJMEMTyzkYBytPWp37CsBNQn/z4uLiqLW1VXI74GFhYRQWFsYHX/xN0hlj1lF0CwCYl+V3AJjNGAthjP0GwEgAh3ypwxs0NzcjKirK/CJIAhzHoa2tDe3t7cjKyhKmEg9ahSN1940wut0vgVFgKVb5V8A4yiwHkOdhy6aLFy/285qg0+morq4uoK2F4zjq6uqi7u5up14czHncBU5UKBR8hbuR7iQdMHpOsNfLlMvllJCQEPDuLikpiZKSkmjfvn1UW1tLjz76KAFGFYfa2lqqqamh5OTkQHbT0hZeoGnLli106NAhmjdvntM8WVlZNG7cOEpNTSXA+A0bN24cjRs3LtD8Slt4b775JqWlpdkwPXz4cPr73/8uyAOZOnUqzZkzp59HPsYYbdy4kTZv3tyPH2/yWNNLL73kr8ClrcNSWVmJnp4em7Tu7m5UVlaCMYbly5eD434dX+3Zswf79+9HYmIi5s+fD4PBgBdffBGAMVrk3r17UV5eblOedTlvvvkmLl68iAkTJmDFihU2+czxZh988EEQUb+6rPPY8+yIn+rqarS3t2PChAm45ZZbUFdXh7ffftu/BwaJ6LAAwB/+8Id+abW1tVizZg0YY8jOzrYRnnnXOywsDNnZ2TAYDGCMgYig1WqdOic1lxMWFgYASE1NRXZ2tuU8EWHTpk0AgPz8fMTGxjqsa8aMGeZewwaO+PnLX/4CwKgRnZ2dzVswYkmoQYSFhZFGo8Hp06fR1dWFpKQkJCQkoLOz05VqgFuYy7GGM2UjMxhjKC4uBmMMv/vd7/yqn0dIVw3i2muvpcbGRov/reXLl1NjYyPt3bvXr++auRwzXbx4UXITeZVK5ZYQzFZCAtdt2aU3GAwBrZvjOHR1ddl8DhxBJpMNzDjp/mL16tXo6+vDsWOCRQN3CoPBAIVCAZlM5pKcQuwuU6x5npmUSiVFRkby7nCO4zi6fPmyoN4gJDPaFAvd3d3o7u72u5xFixYhIyMDS5YsAWBsVeZRbGVlpd/lO8JV/83zF+vXr8f777+P+vp6RERE4MSJE0JUM/jNEwL79+/H1KlTkZGR4VJwc+fOxeTJk3mte1B4fmLTpk04f/48lEqly3yhoaGWPCqVCvfff7//lYs9WBF7wCIG6fV6amxs9HvActW3vJiYGMTHxwe0zu7ubl4CWl31A5aVK1di1KhRuO+++5zmkcvlkMvlICJRbAgh5eUxSKArc0Vm148nTpwQiwdp7+dJmTiOI4VCwasHJnek0+motrbWpfAk8c3T6/WIjo7Gt99+i7y8PEu6VqvFyZMnReTMCIPBgJ6enoDGXT916hT0er3rTKvyeVUAAAakSURBVB60Cke2Ch/iVzuFcwCKTenpADpg54fTHYWHh5NMJiOdTkdxcXGWt88cGAICvuELFiygNWvWiN663RB/tgp25/8MYJWV8ILKu7ter6fc3NyA1FVQUGBxhsqH8PyyVWDGvZSZAP7HXTmeYN68edi7d28/23AhIUg4UCdoaWlBSEgIb+X5uzB9C4A6IjptlfYbxthxAC0AniaifZ4WNmbMGJSVlSEzMxORkZFe+T8JBnzzzTf8Fuhht5YOx675/wajkYn52GPX/HBhq7Bw4UJ6+eWXbdJ0Op2kXewnJiaSTqfrF9yCJ+LdNb8cQB2ANBfX/Rc8uObnOI4aGxt9CoMWKFq+fDk1NTX5rbphTYwx8wCOd+HdAWCPXZqkXPMLQYFs/SqVivr6+pwKz+08jzG2BUbjyNGMsfOMsYdMp2bDaMdgjQkAShhjxQD+BeB/iajJXR3BAr1ej/r6+oDV19TU5NrXtLfDeiEIVm/bxo0bA+JF3Rcye6cQoe7gWB5LTU11ai9++PBhy4Bg0aJFVF5eLpbDbp8pLy+PysvL6eDBgwNPeK5o4sSJljdfo9FQXl4ejR8/XnSBAKB7772XPv/8c4u1rjNKTk6mvLw8mjhxot/CC/otoZSUFCxdutQmbe3ataitrfWbL2+Qk5ODm266CQ0NDdi4cSPfxfscuVLSkMlkiI6O7pcWaBw4cAAHDhxwn9GEkJAQ3HvvvdiwYYPPdQZNy8vNzcX333+Pvr4+AMDw4cMRHh6OqqoqjBkzxqsH5ynGjh2L8PBwVFZWorKyEhEREbj++utt8hw7dswnP6FRUVH47LPPcOutt8JaBub7OnXqlHV26W/GJicnOwyXxhijX375xWaS/uijj9K6desoMzOTSkpKBPmO7dq1iyorK2nJkiUEGCNrVVZW2tDo0aN5rdN8X3bp0v/mHTlyBM8//zy2b9/eL09ISAi6urqgVCrR29sLjuPcxtvp6emxtFQPeIBSqbRRc1AqlW7tCOxhMBgsSrxmns0wq1PY57H3aNjX14fe3l5rfqTf8pwRx3FkMBgoJiaGSktLqaCgwKKa4AqrVq3y+I13pNFVWlrqtg57mFUlrHk2l2evTmHOY48PP/zQnh/ptzxXUCgU6OnpgVwuR19fHziOc9sq+vr6PLb8YYxBLpfbWLrK5XKv/XwSkWXH3cyzGTKZDBzH9ctjD4PBAIPBgMTERFRVVUGpVAZvy7Om3bt3U15eHgGg/Px8+vrrry3fxerqaqqpqaGamhpLnmAmxhilpKQ4bXlBMVVgjOG7777DpEmTkJCQgNDQUMyfPx9PPPEEUlNTLSPN1NRUyzWvvfYakpOTPY51p9FosG7dOhuV9M2bN0OtVnvF6+nTp3HffffZ8Gx27z9//nw89NBD/fLYt+5du3bhvffe68ePPYJCeESEdevWoaurC0899RROnDiBhx56CE1NTXjuuecs+d544w2b67wx+mhsbOw359q6dWu/cGju0Nzc3I9nMw4dOoTOzs5+eezxyy+/OOSnH8TuMr3tNs00ceJEmjNnjtfd0LJly2xi/wQJBf/apjNSKBR01113eSS8bdu28W5I6Q/dddddNH36dIqKiro6hWeeQnjjLECtVvd7YDKZjA8rVo+JMUalpaVUWlrqTn1C+sKLioriy9GaWyoqKqJp06bZpMXFxVFjY6PkPEYEhfDME3AJPCypkaQn6RcBtAFoEJsXATEEvt/fCCJKsE+UhPAAgDF2hBytIgwQCHF/kjA0GYRvGBReEENKwntTbAYEBu/3J5lv3iC8h5Ra3iC8hOjCY4zdwRgrZ4ydYYwtF5sfPsAYO8cYK2WMFTPGjpjSVIyxXYyx06bfOH/rEVV4jDEZgDcA5MEYRGoOY0wrJk884jYius5qerAcwDdENBLAN6ZjvyB2y7sBwBki+pmIugFshTGY1EDEdADvmf6/B+C3/hYotvCGwmjDZ4ZXgaMkDALwH8bYUcbYAlNaEhFdMP2vhTEek18Iis3YIEQuEVUzxhIB7GKM2ShhEpF58dsviN3yqgEMszpOM6UFNYio2vRbD2AbjJ+HOnMMJtOv37ZiYgvvMICRjLHfMMaUMNr87RCZJ7/AGItgjEWZ/wOYDGOgrB0AHjBlewBAf+VULyFqt0lEvYyxQhhDtclgjMP3g5g88YAkANtMSkVyAB8Q0ZeMscMA/mkyTv0FRi8afmFwhSWIIXa3OQg/MCi8IMag8IIYg8ILYgwKL4gxKLwgxqDwghiDwgti/H8bbFYZzshPrgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "BjhAI6Z694j3",
        "outputId": "860c5e07-b626-459f-fe88-9fccde20e0e6"
      },
      "source": [
        "#now plot 1 images from each model to see their appearance\n",
        "f, axarr = plt.subplots(1,7) \n",
        "#model 1\n",
        "#ax.set_title(str(\"model 1\")\n",
        "axarr[0].imshow(t[0],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[1].imshow(t[1000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[2].imshow(t[2000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[3].imshow(t[3000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[4].imshow(t[4000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[5].imshow(t[5000],cmap='gray', vmin=0, vmax=1)\n",
        "axarr[6].imshow(t[6000],cmap='gray', vmin=0, vmax=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f26d427ff98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhRSPczX7F92",
        "outputId": "842c39e7-c7e4-4a62-93a0-5e5d1f3afc41"
      },
      "source": [
        "# Predict the most likely model with the empirical data.\n",
        "pred = model.predict(inp)\n",
        "print(pred)\n",
        "\n",
        "#Repeat the predictions more 4 times after shuffling the order of rows (SNPs)\n",
        "#shuffle rows\n",
        "perm = np.arange(inp.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "inp = inp[perm]\n",
        "\n",
        "#and predict\n",
        "pred = model.predict(inp)\n",
        "print(pred)\n",
        "\n",
        "#shuffle rows\n",
        "perm = np.arange(inp.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "inp = inp[perm]\n",
        "\n",
        "#and predict\n",
        "pred = model.predict(inp)\n",
        "print(pred)\n",
        "\n",
        "#shuffle rows\n",
        "perm = np.arange(inp.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "inp = inp[perm]\n",
        "\n",
        "#and predict\n",
        "pred = model.predict(inp)\n",
        "print(pred)\n",
        "\n",
        "#shuffle rows\n",
        "perm = np.arange(inp.shape[0])\n",
        "np.random.shuffle(perm)\n",
        "inp = inp[perm]\n",
        "\n",
        "#and predict\n",
        "pred = model.predict(inp)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9798101e-01 1.4918201e-03 3.4714853e-10 5.5235150e-10 2.0285301e-13\n",
            "  5.2705599e-04 6.7712250e-08]]\n",
            "[[9.9798101e-01 1.4918201e-03 3.4714853e-10 5.5235150e-10 2.0285301e-13\n",
            "  5.2705599e-04 6.7712250e-08]]\n",
            "[[9.9798101e-01 1.4918201e-03 3.4714853e-10 5.5235150e-10 2.0285301e-13\n",
            "  5.2705599e-04 6.7712250e-08]]\n",
            "[[9.9798101e-01 1.4918201e-03 3.4714853e-10 5.5235150e-10 2.0285301e-13\n",
            "  5.2705599e-04 6.7712250e-08]]\n",
            "[[9.9798101e-01 1.4918201e-03 3.4714853e-10 5.5235150e-10 2.0285301e-13\n",
            "  5.2705599e-04 6.7712250e-08]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ne-JFcm9eMw"
      },
      "source": [
        "# **Evaluate the impact of using different number of simulations to train the network**\n",
        "Below, we repeat the procedures of training and evalutating the CNN, with varying number of simulations (2,500; 1,000 and 500) per model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx3iXPj0Y_n4",
        "outputId": "7aea0125-58a8-4651-decb-a0c811043519"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 2.5K simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "x=np.concatenate((u1[0:2500,:,:],u2[0:2500,:,:],u3[0:2500,:,:],u4[0:2500,:,:],u5[0:2500,:,:],u6[0:2500,:,:],u7[0:2500,:,:]),axis=0)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "\n",
        "x=x.astype(np.uint8)\n",
        "\n",
        "y=[0 for i in range(len(u1[0:2500,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:2500,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:2500,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:2500,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:2500,:,:]))])\n",
        "y.extend([5 for i in range(len(u6[0:2500,:,:]))])\n",
        "y.extend([6 for i in range(len(u7[0:2500,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n",
        "print (f'Time: {time.time() - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17500 17500\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 195, 64)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 194, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 193, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_2 (Average (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 95, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_3 (Average (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 5875)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 125)               734500    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 7)                 882       \n",
            "=================================================================\n",
            "Total params: 877,382\n",
            "Trainable params: 877,382\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            "53/53 [==============================] - ETA: 0s - loss: 1.8073 - accuracy: 0.2290INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 64ms/step - loss: 1.8073 - accuracy: 0.2290 - val_loss: 1.4645 - val_accuracy: 0.2965\n",
            "Epoch 2/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 1.3825 - accuracy: 0.3543INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 1.3804 - accuracy: 0.3555 - val_loss: 1.1606 - val_accuracy: 0.4283\n",
            "Epoch 3/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 1.1173 - accuracy: 0.4847INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 47ms/step - loss: 1.1163 - accuracy: 0.4847 - val_loss: 0.8677 - val_accuracy: 0.5582\n",
            "Epoch 4/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.8379 - accuracy: 0.5998INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.8372 - accuracy: 0.5998 - val_loss: 0.6187 - val_accuracy: 0.6871\n",
            "Epoch 5/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.6906 - accuracy: 0.6510 - val_loss: 0.5757 - val_accuracy: 0.6825\n",
            "Epoch 6/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.6159 - accuracy: 0.6795 - val_loss: 0.6149 - val_accuracy: 0.6709\n",
            "Epoch 7/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.5816 - accuracy: 0.6915INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 52ms/step - loss: 0.5812 - accuracy: 0.6914 - val_loss: 0.5177 - val_accuracy: 0.7106\n",
            "Epoch 8/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.7003INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 0.5604 - accuracy: 0.7003 - val_loss: 0.4933 - val_accuracy: 0.7198\n",
            "Epoch 9/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.5382 - accuracy: 0.7060 - val_loss: 0.5325 - val_accuracy: 0.7106\n",
            "Epoch 10/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.5247 - accuracy: 0.7145INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.5241 - accuracy: 0.7146 - val_loss: 0.5135 - val_accuracy: 0.7214\n",
            "Epoch 11/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.5162 - accuracy: 0.7131 - val_loss: 0.5495 - val_accuracy: 0.7029\n",
            "Epoch 12/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.5122 - accuracy: 0.7183 - val_loss: 0.5816 - val_accuracy: 0.6985\n",
            "Epoch 13/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.5021 - accuracy: 0.7227INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 49ms/step - loss: 0.5009 - accuracy: 0.7236 - val_loss: 0.4878 - val_accuracy: 0.7285\n",
            "Epoch 14/250\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.4946 - accuracy: 0.7300 - val_loss: 0.5190 - val_accuracy: 0.7195\n",
            "Epoch 15/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.4838 - accuracy: 0.7335 - val_loss: 0.6056 - val_accuracy: 0.7029\n",
            "Epoch 16/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.5020 - accuracy: 0.7255 - val_loss: 0.5010 - val_accuracy: 0.7275\n",
            "Epoch 17/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.4673 - accuracy: 0.7425INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.4672 - accuracy: 0.7426 - val_loss: 0.4967 - val_accuracy: 0.7383\n",
            "Epoch 18/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.4672 - accuracy: 0.7389INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 50ms/step - loss: 0.4674 - accuracy: 0.7387 - val_loss: 0.4852 - val_accuracy: 0.7477\n",
            "Epoch 19/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.4658 - accuracy: 0.7381 - val_loss: 0.4793 - val_accuracy: 0.7365\n",
            "Epoch 20/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.4672 - accuracy: 0.7482 - val_loss: 0.4922 - val_accuracy: 0.7381\n",
            "Epoch 21/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.4500 - accuracy: 0.7558 - val_loss: 0.4965 - val_accuracy: 0.7381\n",
            "Epoch 22/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.4588 - accuracy: 0.7537 - val_loss: 0.5385 - val_accuracy: 0.7239\n",
            "Epoch 23/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.4409 - accuracy: 0.7586 - val_loss: 0.5308 - val_accuracy: 0.7365\n",
            "Epoch 24/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.4330 - accuracy: 0.7638INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 51ms/step - loss: 0.4326 - accuracy: 0.7637 - val_loss: 0.4724 - val_accuracy: 0.7687\n",
            "Epoch 25/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.4142 - accuracy: 0.7801INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.4136 - accuracy: 0.7803 - val_loss: 0.4486 - val_accuracy: 0.7790\n",
            "Epoch 26/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.4266 - accuracy: 0.7813 - val_loss: 0.4504 - val_accuracy: 0.7694\n",
            "Epoch 27/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.4059 - accuracy: 0.7963 - val_loss: 0.6516 - val_accuracy: 0.7506\n",
            "Epoch 28/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.7983INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.3985 - accuracy: 0.7983 - val_loss: 0.4737 - val_accuracy: 0.7792\n",
            "Epoch 29/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.3936 - accuracy: 0.8059INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.3935 - accuracy: 0.8059 - val_loss: 0.4352 - val_accuracy: 0.8263\n",
            "Epoch 30/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.3845 - accuracy: 0.8136 - val_loss: 0.4372 - val_accuracy: 0.8062\n",
            "Epoch 31/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.3728 - accuracy: 0.8313INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 51ms/step - loss: 0.3719 - accuracy: 0.8318 - val_loss: 0.4349 - val_accuracy: 0.8347\n",
            "Epoch 32/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.3487 - accuracy: 0.8444 - val_loss: 0.5293 - val_accuracy: 0.8258\n",
            "Epoch 33/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.8662INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 47ms/step - loss: 0.3279 - accuracy: 0.8661 - val_loss: 0.3417 - val_accuracy: 0.8674\n",
            "Epoch 34/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.8803INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.2988 - accuracy: 0.8804 - val_loss: 0.3105 - val_accuracy: 0.8894\n",
            "Epoch 35/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.2750 - accuracy: 0.8923INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.2751 - accuracy: 0.8922 - val_loss: 0.3258 - val_accuracy: 0.8946\n",
            "Epoch 36/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.2626 - accuracy: 0.9001 - val_loss: 0.3779 - val_accuracy: 0.8910\n",
            "Epoch 37/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.2509 - accuracy: 0.9038 - val_loss: 0.4686 - val_accuracy: 0.8571\n",
            "Epoch 38/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9052INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 46ms/step - loss: 0.2515 - accuracy: 0.9051 - val_loss: 0.2910 - val_accuracy: 0.8955\n",
            "Epoch 39/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.2524 - accuracy: 0.9026 - val_loss: 0.3717 - val_accuracy: 0.8702\n",
            "Epoch 40/250\n",
            "51/53 [===========================>..] - ETA: 0s - loss: 0.2365 - accuracy: 0.9107INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.2348 - accuracy: 0.9112 - val_loss: 0.2884 - val_accuracy: 0.9022\n",
            "Epoch 41/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.2177 - accuracy: 0.9198 - val_loss: 0.3261 - val_accuracy: 0.9003\n",
            "Epoch 42/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.2187 - accuracy: 0.9208 - val_loss: 0.3112 - val_accuracy: 0.8873\n",
            "Epoch 43/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.9223INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 53ms/step - loss: 0.2097 - accuracy: 0.9218 - val_loss: 0.2861 - val_accuracy: 0.9033\n",
            "Epoch 44/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1951 - accuracy: 0.9293 - val_loss: 0.3249 - val_accuracy: 0.9022\n",
            "Epoch 45/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1955 - accuracy: 0.9291 - val_loss: 0.3396 - val_accuracy: 0.8939\n",
            "Epoch 46/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.1976 - accuracy: 0.9284INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.1972 - accuracy: 0.9287 - val_loss: 0.2841 - val_accuracy: 0.9070\n",
            "Epoch 47/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1881 - accuracy: 0.9317 - val_loss: 0.2790 - val_accuracy: 0.9035\n",
            "Epoch 48/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.2272 - accuracy: 0.9208 - val_loss: 0.3909 - val_accuracy: 0.8914\n",
            "Epoch 49/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1891 - accuracy: 0.9303 - val_loss: 0.3255 - val_accuracy: 0.9042\n",
            "Epoch 50/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1991 - accuracy: 0.9301 - val_loss: 0.4143 - val_accuracy: 0.8809\n",
            "Epoch 51/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1859 - accuracy: 0.9324 - val_loss: 0.2900 - val_accuracy: 0.9017\n",
            "Epoch 52/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1847 - accuracy: 0.9313 - val_loss: 0.3708 - val_accuracy: 0.8894\n",
            "Epoch 53/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1677 - accuracy: 0.9419 - val_loss: 0.3137 - val_accuracy: 0.9042\n",
            "Epoch 54/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1753 - accuracy: 0.9363 - val_loss: 0.3704 - val_accuracy: 0.8896\n",
            "Epoch 55/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1721 - accuracy: 0.9404 - val_loss: 0.4145 - val_accuracy: 0.8791\n",
            "Epoch 56/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1733 - accuracy: 0.9381 - val_loss: 0.3358 - val_accuracy: 0.9001\n",
            "Epoch 57/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1535 - accuracy: 0.9479 - val_loss: 0.3324 - val_accuracy: 0.9013\n",
            "Epoch 58/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1551 - accuracy: 0.9432 - val_loss: 0.3725 - val_accuracy: 0.8990\n",
            "Epoch 59/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1536 - accuracy: 0.9429 - val_loss: 0.3300 - val_accuracy: 0.8974\n",
            "Epoch 60/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1516 - accuracy: 0.9453 - val_loss: 0.3946 - val_accuracy: 0.9001\n",
            "Epoch 61/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1506 - accuracy: 0.9475 - val_loss: 0.3735 - val_accuracy: 0.8983\n",
            "Epoch 62/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1553 - accuracy: 0.9423 - val_loss: 0.3866 - val_accuracy: 0.8914\n",
            "Epoch 63/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1668 - accuracy: 0.9415 - val_loss: 0.2976 - val_accuracy: 0.9026\n",
            "Epoch 64/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1377 - accuracy: 0.9488 - val_loss: 0.3435 - val_accuracy: 0.9042\n",
            "Epoch 65/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1354 - accuracy: 0.9509 - val_loss: 0.3410 - val_accuracy: 0.9045\n",
            "Epoch 66/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9481\n",
            "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1455 - accuracy: 0.9483 - val_loss: 0.3959 - val_accuracy: 0.8878\n",
            "Epoch 67/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1238 - accuracy: 0.9561 - val_loss: 0.3345 - val_accuracy: 0.9026\n",
            "Epoch 68/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1168 - accuracy: 0.9582 - val_loss: 0.3636 - val_accuracy: 0.8992\n",
            "Epoch 69/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1132 - accuracy: 0.9614 - val_loss: 0.3499 - val_accuracy: 0.9056\n",
            "Epoch 70/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1124 - accuracy: 0.9586 - val_loss: 0.3858 - val_accuracy: 0.9019\n",
            "Epoch 71/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.9612INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 2s 47ms/step - loss: 0.1098 - accuracy: 0.9612 - val_loss: 0.3491 - val_accuracy: 0.9072\n",
            "Epoch 72/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1046 - accuracy: 0.9615 - val_loss: 0.3674 - val_accuracy: 0.9063\n",
            "Epoch 73/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1062 - accuracy: 0.9610 - val_loss: 0.4068 - val_accuracy: 0.9031\n",
            "Epoch 74/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.1050 - accuracy: 0.9630INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 48ms/step - loss: 0.1046 - accuracy: 0.9631 - val_loss: 0.3544 - val_accuracy: 0.9079\n",
            "Epoch 75/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.9602INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod/assets\n",
            "53/53 [==============================] - 3s 51ms/step - loss: 0.1097 - accuracy: 0.9602 - val_loss: 0.3455 - val_accuracy: 0.9120\n",
            "Epoch 76/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1010 - accuracy: 0.9640 - val_loss: 0.4028 - val_accuracy: 0.9019\n",
            "Epoch 77/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1008 - accuracy: 0.9636 - val_loss: 0.3502 - val_accuracy: 0.9102\n",
            "Epoch 78/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.1030 - accuracy: 0.9635 - val_loss: 0.3967 - val_accuracy: 0.9033\n",
            "Epoch 79/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0999 - accuracy: 0.9635 - val_loss: 0.4116 - val_accuracy: 0.9003\n",
            "Epoch 80/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0991 - accuracy: 0.9637 - val_loss: 0.3640 - val_accuracy: 0.9083\n",
            "Epoch 81/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0990 - accuracy: 0.9639 - val_loss: 0.3674 - val_accuracy: 0.9061\n",
            "Epoch 82/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0998 - accuracy: 0.9650 - val_loss: 0.3762 - val_accuracy: 0.9083\n",
            "Epoch 83/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0973 - accuracy: 0.9656 - val_loss: 0.3852 - val_accuracy: 0.9083\n",
            "Epoch 84/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0977 - accuracy: 0.9660 - val_loss: 0.3838 - val_accuracy: 0.9070\n",
            "Epoch 85/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0932 - accuracy: 0.9657 - val_loss: 0.3820 - val_accuracy: 0.9079\n",
            "Epoch 86/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0960 - accuracy: 0.9653 - val_loss: 0.4373 - val_accuracy: 0.9010\n",
            "Epoch 87/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0958 - accuracy: 0.9665 - val_loss: 0.3779 - val_accuracy: 0.9065\n",
            "Epoch 88/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0884 - accuracy: 0.9688 - val_loss: 0.4295 - val_accuracy: 0.9042\n",
            "Epoch 89/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0980 - accuracy: 0.9659 - val_loss: 0.4481 - val_accuracy: 0.9017\n",
            "Epoch 90/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0932 - accuracy: 0.9668 - val_loss: 0.4063 - val_accuracy: 0.9029\n",
            "Epoch 91/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0915 - accuracy: 0.9685 - val_loss: 0.4147 - val_accuracy: 0.9029\n",
            "Epoch 92/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0910 - accuracy: 0.9672 - val_loss: 0.3974 - val_accuracy: 0.9033\n",
            "Epoch 93/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0881 - accuracy: 0.9678 - val_loss: 0.4390 - val_accuracy: 0.9035\n",
            "Epoch 94/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0902 - accuracy: 0.9682 - val_loss: 0.4316 - val_accuracy: 0.9035\n",
            "Epoch 95/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.0907 - accuracy: 0.9662\n",
            "Epoch 00095: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0912 - accuracy: 0.9662 - val_loss: 0.3912 - val_accuracy: 0.9077\n",
            "Epoch 96/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0871 - accuracy: 0.9679 - val_loss: 0.4147 - val_accuracy: 0.9065\n",
            "Epoch 97/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0818 - accuracy: 0.9716 - val_loss: 0.3997 - val_accuracy: 0.9093\n",
            "Epoch 98/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0868 - accuracy: 0.9686 - val_loss: 0.4252 - val_accuracy: 0.9031\n",
            "Epoch 99/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0816 - accuracy: 0.9699 - val_loss: 0.4217 - val_accuracy: 0.9047\n",
            "Epoch 100/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0847 - accuracy: 0.9688 - val_loss: 0.4140 - val_accuracy: 0.9065\n",
            "Epoch 101/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0837 - accuracy: 0.9701 - val_loss: 0.4321 - val_accuracy: 0.9063\n",
            "Epoch 102/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0863 - accuracy: 0.9696 - val_loss: 0.4345 - val_accuracy: 0.9054\n",
            "Epoch 103/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0859 - accuracy: 0.9688 - val_loss: 0.4059 - val_accuracy: 0.9079\n",
            "Epoch 104/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0822 - accuracy: 0.9704 - val_loss: 0.4277 - val_accuracy: 0.9058\n",
            "Epoch 105/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0791 - accuracy: 0.9708 - val_loss: 0.4062 - val_accuracy: 0.9090\n",
            "Epoch 106/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0802 - accuracy: 0.9722 - val_loss: 0.4169 - val_accuracy: 0.9072\n",
            "Epoch 107/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0781 - accuracy: 0.9723 - val_loss: 0.4170 - val_accuracy: 0.9070\n",
            "Epoch 108/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0807 - accuracy: 0.9714 - val_loss: 0.4382 - val_accuracy: 0.9047\n",
            "Epoch 109/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0817 - accuracy: 0.9706 - val_loss: 0.4039 - val_accuracy: 0.9086\n",
            "Epoch 110/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0795 - accuracy: 0.9717 - val_loss: 0.4453 - val_accuracy: 0.9063\n",
            "Epoch 111/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0826 - accuracy: 0.9698 - val_loss: 0.4239 - val_accuracy: 0.9081\n",
            "Epoch 112/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0847 - accuracy: 0.9699 - val_loss: 0.4251 - val_accuracy: 0.9074\n",
            "Epoch 113/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0779 - accuracy: 0.9712 - val_loss: 0.4315 - val_accuracy: 0.9077\n",
            "Epoch 114/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0783 - accuracy: 0.9715 - val_loss: 0.4278 - val_accuracy: 0.9074\n",
            "Epoch 115/250\n",
            "51/53 [===========================>..] - ETA: 0s - loss: 0.0831 - accuracy: 0.9721\n",
            "Epoch 00115: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0828 - accuracy: 0.9719 - val_loss: 0.4270 - val_accuracy: 0.9083\n",
            "Epoch 116/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0770 - accuracy: 0.9723 - val_loss: 0.4349 - val_accuracy: 0.9054\n",
            "Epoch 117/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0802 - accuracy: 0.9718 - val_loss: 0.4251 - val_accuracy: 0.9086\n",
            "Epoch 118/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0802 - accuracy: 0.9717 - val_loss: 0.4292 - val_accuracy: 0.9067\n",
            "Epoch 119/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0805 - accuracy: 0.9688 - val_loss: 0.4363 - val_accuracy: 0.9063\n",
            "Epoch 120/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0810 - accuracy: 0.9696 - val_loss: 0.4267 - val_accuracy: 0.9061\n",
            "Epoch 121/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0785 - accuracy: 0.9713 - val_loss: 0.4283 - val_accuracy: 0.9065\n",
            "Epoch 122/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0805 - accuracy: 0.9699 - val_loss: 0.4241 - val_accuracy: 0.9083\n",
            "Epoch 123/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0776 - accuracy: 0.9726 - val_loss: 0.4256 - val_accuracy: 0.9090\n",
            "Epoch 124/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0815 - accuracy: 0.9712 - val_loss: 0.4281 - val_accuracy: 0.9090\n",
            "Epoch 125/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0758 - accuracy: 0.9710 - val_loss: 0.4233 - val_accuracy: 0.9088\n",
            "Epoch 126/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0789 - accuracy: 0.9710 - val_loss: 0.4373 - val_accuracy: 0.9067\n",
            "Epoch 127/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0774 - accuracy: 0.9720 - val_loss: 0.4275 - val_accuracy: 0.9079\n",
            "Epoch 128/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0794 - accuracy: 0.9715 - val_loss: 0.4275 - val_accuracy: 0.9090\n",
            "Epoch 129/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0801 - accuracy: 0.9710 - val_loss: 0.4256 - val_accuracy: 0.9081\n",
            "Epoch 130/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0780 - accuracy: 0.9717 - val_loss: 0.4223 - val_accuracy: 0.9086\n",
            "Epoch 131/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0744 - accuracy: 0.9730 - val_loss: 0.4356 - val_accuracy: 0.9067\n",
            "Epoch 132/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0759 - accuracy: 0.9723 - val_loss: 0.4318 - val_accuracy: 0.9065\n",
            "Epoch 133/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0775 - accuracy: 0.9718 - val_loss: 0.4331 - val_accuracy: 0.9058\n",
            "Epoch 134/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0781 - accuracy: 0.9713 - val_loss: 0.4289 - val_accuracy: 0.9086\n",
            "Epoch 135/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.0794 - accuracy: 0.9722\n",
            "Epoch 00135: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0796 - accuracy: 0.9723 - val_loss: 0.4275 - val_accuracy: 0.9086\n",
            "Epoch 136/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0775 - accuracy: 0.9722 - val_loss: 0.4252 - val_accuracy: 0.9095\n",
            "Epoch 137/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0750 - accuracy: 0.9722 - val_loss: 0.4298 - val_accuracy: 0.9065\n",
            "Epoch 138/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0764 - accuracy: 0.9711 - val_loss: 0.4295 - val_accuracy: 0.9070\n",
            "Epoch 139/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0798 - accuracy: 0.9726 - val_loss: 0.4261 - val_accuracy: 0.9093\n",
            "Epoch 140/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0791 - accuracy: 0.9718 - val_loss: 0.4297 - val_accuracy: 0.9086\n",
            "Epoch 141/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0804 - accuracy: 0.9715 - val_loss: 0.4291 - val_accuracy: 0.9086\n",
            "Epoch 142/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0763 - accuracy: 0.9703 - val_loss: 0.4300 - val_accuracy: 0.9077\n",
            "Epoch 143/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0785 - accuracy: 0.9727 - val_loss: 0.4305 - val_accuracy: 0.9077\n",
            "Epoch 144/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0754 - accuracy: 0.9731 - val_loss: 0.4281 - val_accuracy: 0.9088\n",
            "Epoch 145/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0789 - accuracy: 0.9712 - val_loss: 0.4275 - val_accuracy: 0.9086\n",
            "Epoch 146/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0732 - accuracy: 0.9740 - val_loss: 0.4304 - val_accuracy: 0.9074\n",
            "Epoch 147/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0788 - accuracy: 0.9707 - val_loss: 0.4268 - val_accuracy: 0.9088\n",
            "Epoch 148/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0735 - accuracy: 0.9739 - val_loss: 0.4248 - val_accuracy: 0.9090\n",
            "Epoch 149/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0808 - accuracy: 0.9731 - val_loss: 0.4270 - val_accuracy: 0.9090\n",
            "Epoch 150/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0820 - accuracy: 0.9698 - val_loss: 0.4306 - val_accuracy: 0.9081\n",
            "Epoch 151/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0772 - accuracy: 0.9708 - val_loss: 0.4298 - val_accuracy: 0.9088\n",
            "Epoch 152/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0822 - accuracy: 0.9701 - val_loss: 0.4272 - val_accuracy: 0.9090\n",
            "Epoch 153/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0753 - accuracy: 0.9735 - val_loss: 0.4255 - val_accuracy: 0.9086\n",
            "Epoch 154/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0750 - accuracy: 0.9727 - val_loss: 0.4255 - val_accuracy: 0.9088\n",
            "Epoch 155/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9725\n",
            "Epoch 00155: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0813 - accuracy: 0.9723 - val_loss: 0.4257 - val_accuracy: 0.9088\n",
            "Epoch 156/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0750 - accuracy: 0.9730 - val_loss: 0.4257 - val_accuracy: 0.9088\n",
            "Epoch 157/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0789 - accuracy: 0.9713 - val_loss: 0.4259 - val_accuracy: 0.9090\n",
            "Epoch 158/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0818 - accuracy: 0.9694 - val_loss: 0.4255 - val_accuracy: 0.9090\n",
            "Epoch 159/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0779 - accuracy: 0.9720 - val_loss: 0.4256 - val_accuracy: 0.9088\n",
            "Epoch 160/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0775 - accuracy: 0.9702 - val_loss: 0.4264 - val_accuracy: 0.9088\n",
            "Epoch 161/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0805 - accuracy: 0.9704 - val_loss: 0.4271 - val_accuracy: 0.9095\n",
            "Epoch 162/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0801 - accuracy: 0.9710 - val_loss: 0.4278 - val_accuracy: 0.9093\n",
            "Epoch 163/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0794 - accuracy: 0.9710 - val_loss: 0.4278 - val_accuracy: 0.9093\n",
            "Epoch 164/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0781 - accuracy: 0.9720 - val_loss: 0.4282 - val_accuracy: 0.9093\n",
            "Epoch 165/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0730 - accuracy: 0.9738 - val_loss: 0.4284 - val_accuracy: 0.9090\n",
            "Epoch 166/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0791 - accuracy: 0.9730 - val_loss: 0.4284 - val_accuracy: 0.9093\n",
            "Epoch 167/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0769 - accuracy: 0.9729 - val_loss: 0.4282 - val_accuracy: 0.9093\n",
            "Epoch 168/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0791 - accuracy: 0.9712 - val_loss: 0.4277 - val_accuracy: 0.9095\n",
            "Epoch 169/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0764 - accuracy: 0.9721 - val_loss: 0.4278 - val_accuracy: 0.9093\n",
            "Epoch 170/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0764 - accuracy: 0.9734 - val_loss: 0.4284 - val_accuracy: 0.9090\n",
            "Epoch 171/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0779 - accuracy: 0.9719 - val_loss: 0.4293 - val_accuracy: 0.9086\n",
            "Epoch 172/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0749 - accuracy: 0.9726 - val_loss: 0.4300 - val_accuracy: 0.9083\n",
            "Epoch 173/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0774 - accuracy: 0.9719 - val_loss: 0.4302 - val_accuracy: 0.9079\n",
            "Epoch 174/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0739 - accuracy: 0.9743 - val_loss: 0.4298 - val_accuracy: 0.9083\n",
            "Epoch 175/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9735\n",
            "Epoch 00175: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0730 - accuracy: 0.9737 - val_loss: 0.4298 - val_accuracy: 0.9081\n",
            "Epoch 176/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0781 - accuracy: 0.9721 - val_loss: 0.4297 - val_accuracy: 0.9081\n",
            "Epoch 177/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0806 - accuracy: 0.9732 - val_loss: 0.4296 - val_accuracy: 0.9083\n",
            "Epoch 178/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0770 - accuracy: 0.9737 - val_loss: 0.4296 - val_accuracy: 0.9086\n",
            "Epoch 179/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0761 - accuracy: 0.9718 - val_loss: 0.4296 - val_accuracy: 0.9086\n",
            "Epoch 180/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0823 - accuracy: 0.9703 - val_loss: 0.4297 - val_accuracy: 0.9086\n",
            "Epoch 181/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0781 - accuracy: 0.9717 - val_loss: 0.4297 - val_accuracy: 0.9083\n",
            "Epoch 182/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0797 - accuracy: 0.9720 - val_loss: 0.4298 - val_accuracy: 0.9083\n",
            "Epoch 183/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0754 - accuracy: 0.9719 - val_loss: 0.4301 - val_accuracy: 0.9083\n",
            "Epoch 184/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0788 - accuracy: 0.9725 - val_loss: 0.4301 - val_accuracy: 0.9083\n",
            "Epoch 185/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0789 - accuracy: 0.9716 - val_loss: 0.4303 - val_accuracy: 0.9083\n",
            "Epoch 186/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0789 - accuracy: 0.9722 - val_loss: 0.4304 - val_accuracy: 0.9083\n",
            "Epoch 187/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0777 - accuracy: 0.9713 - val_loss: 0.4304 - val_accuracy: 0.9081\n",
            "Epoch 188/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0776 - accuracy: 0.9714 - val_loss: 0.4303 - val_accuracy: 0.9083\n",
            "Epoch 189/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0756 - accuracy: 0.9727 - val_loss: 0.4303 - val_accuracy: 0.9083\n",
            "Epoch 190/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0777 - accuracy: 0.9723 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 191/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0763 - accuracy: 0.9716 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 192/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0742 - accuracy: 0.9742 - val_loss: 0.4301 - val_accuracy: 0.9083\n",
            "Epoch 193/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0801 - accuracy: 0.9711 - val_loss: 0.4301 - val_accuracy: 0.9083\n",
            "Epoch 194/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0785 - accuracy: 0.9728 - val_loss: 0.4301 - val_accuracy: 0.9083\n",
            "Epoch 195/250\n",
            "52/53 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.9730\n",
            "Epoch 00195: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0794 - accuracy: 0.9730 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 196/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0788 - accuracy: 0.9707 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 197/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0791 - accuracy: 0.9700 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 198/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0760 - accuracy: 0.9723 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 199/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0726 - accuracy: 0.9735 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 200/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0733 - accuracy: 0.9740 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 201/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0786 - accuracy: 0.9716 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 202/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0772 - accuracy: 0.9717 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 203/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0765 - accuracy: 0.9724 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 204/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0761 - accuracy: 0.9726 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 205/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0831 - accuracy: 0.9702 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 206/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0788 - accuracy: 0.9727 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 207/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0775 - accuracy: 0.9723 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 208/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0771 - accuracy: 0.9737 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 209/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0757 - accuracy: 0.9733 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 210/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0797 - accuracy: 0.9715 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 211/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0780 - accuracy: 0.9723 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 212/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0723 - accuracy: 0.9730 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 213/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0783 - accuracy: 0.9723 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 214/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0762 - accuracy: 0.9730 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 215/250\n",
            "51/53 [===========================>..] - ETA: 0s - loss: 0.0796 - accuracy: 0.9715\n",
            "Epoch 00215: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0794 - accuracy: 0.9715 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 216/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0764 - accuracy: 0.9723 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 217/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0764 - accuracy: 0.9707 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 218/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0761 - accuracy: 0.9720 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 219/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0801 - accuracy: 0.9716 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 220/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0780 - accuracy: 0.9727 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 221/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0802 - accuracy: 0.9717 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 222/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0815 - accuracy: 0.9710 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 223/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0781 - accuracy: 0.9717 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 224/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0775 - accuracy: 0.9718 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 225/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0795 - accuracy: 0.9719 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 226/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0779 - accuracy: 0.9714 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 227/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0785 - accuracy: 0.9707 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 228/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0740 - accuracy: 0.9724 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 229/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0800 - accuracy: 0.9714 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 230/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0794 - accuracy: 0.9712 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 231/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0798 - accuracy: 0.9698 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 232/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0780 - accuracy: 0.9717 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 233/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0742 - accuracy: 0.9722 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 234/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0785 - accuracy: 0.9715 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 235/250\n",
            "51/53 [===========================>..] - ETA: 0s - loss: 0.0789 - accuracy: 0.9718\n",
            "Epoch 00235: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0781 - accuracy: 0.9722 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 236/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0740 - accuracy: 0.9732 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 237/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0808 - accuracy: 0.9719 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 238/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0833 - accuracy: 0.9714 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 239/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0785 - accuracy: 0.9710 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 240/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0803 - accuracy: 0.9707 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 241/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0767 - accuracy: 0.9717 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 242/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0818 - accuracy: 0.9710 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 243/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0729 - accuracy: 0.9739 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 244/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0778 - accuracy: 0.9710 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 245/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0756 - accuracy: 0.9729 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 246/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0814 - accuracy: 0.9716 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 247/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0780 - accuracy: 0.9732 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 248/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0775 - accuracy: 0.9719 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 249/250\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0775 - accuracy: 0.9725 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Epoch 250/250\n",
            "53/53 [==============================] - 1s 24ms/step - loss: 0.0760 - accuracy: 0.9727 - val_loss: 0.4302 - val_accuracy: 0.9083\n",
            "Time: 362.7172381877899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0StnjUKSv4R",
        "outputId": "25807559-8301-481d-d6ca-7cc39f07d2b7"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 1K simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "x=np.concatenate((u1[0:1000,:,:],u2[0:1000,:,:],u3[0:1000,:,:],u4[0:1000,:,:],u5[0:1000,:,:],u6[0:1000,:,:],u7[0:1000,:,:]),axis=0)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "\n",
        "y=[0 for i in range(len(u1[0:1000,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:1000,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:1000,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:1000,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:1000,:,:]))])\n",
        "y.extend([5 for i in range(len(u6[0:1000,:,:]))])\n",
        "y.extend([6 for i in range(len(u7[0:1000,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n",
        "print (f'Time: {time.time() - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7000 7000\n",
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 195, 64)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 194, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 193, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_4 (Average (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 95, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_5 (Average (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 5875)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 125)               734500    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 7)                 882       \n",
            "=================================================================\n",
            "Total params: 877,382\n",
            "Trainable params: 877,382\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 2.0733 - accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0089s vs `on_train_batch_end` time: 0.0229s). Check your callbacks.\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 1.9592 - accuracy: 0.1484INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 1.9549 - accuracy: 0.1558 - val_loss: 1.9135 - val_accuracy: 0.2640\n",
            "Epoch 2/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 1.7683 - accuracy: 0.2596INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 1.7546 - accuracy: 0.2602 - val_loss: 1.5269 - val_accuracy: 0.2994\n",
            "Epoch 3/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 1.5395 - accuracy: 0.3105INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 1.5343 - accuracy: 0.3090 - val_loss: 1.3820 - val_accuracy: 0.3126\n",
            "Epoch 4/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 1.4185 - accuracy: 0.3228INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 98ms/step - loss: 1.4164 - accuracy: 0.3242 - val_loss: 1.3339 - val_accuracy: 0.3337\n",
            "Epoch 5/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 1.3508 - accuracy: 0.3506INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 1.3501 - accuracy: 0.3518 - val_loss: 1.2632 - val_accuracy: 0.3971\n",
            "Epoch 6/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 1.2626 - accuracy: 0.4017INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 94ms/step - loss: 1.2531 - accuracy: 0.4057 - val_loss: 1.1471 - val_accuracy: 0.4154\n",
            "Epoch 7/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 1.1602 - accuracy: 0.4608INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 92ms/step - loss: 1.1553 - accuracy: 0.4670 - val_loss: 1.0428 - val_accuracy: 0.4863\n",
            "Epoch 8/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 1.0635 - accuracy: 0.5154INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 1.0616 - accuracy: 0.5158 - val_loss: 0.8981 - val_accuracy: 0.6229\n",
            "Epoch 9/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.9632 - accuracy: 0.5625 - val_loss: 0.7909 - val_accuracy: 0.5880\n",
            "Epoch 10/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.8364 - accuracy: 0.6004INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 101ms/step - loss: 0.8280 - accuracy: 0.6023 - val_loss: 0.6599 - val_accuracy: 0.6509\n",
            "Epoch 11/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.7381 - accuracy: 0.6303INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 84ms/step - loss: 0.7380 - accuracy: 0.6307 - val_loss: 0.5822 - val_accuracy: 0.6937\n",
            "Epoch 12/250\n",
            "21/21 [==============================] - 1s 26ms/step - loss: 0.7179 - accuracy: 0.6379 - val_loss: 0.7695 - val_accuracy: 0.5949\n",
            "Epoch 13/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.6633 - accuracy: 0.6539INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.6590 - accuracy: 0.6556 - val_loss: 0.5858 - val_accuracy: 0.6983\n",
            "Epoch 14/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.6119 - accuracy: 0.6779 - val_loss: 0.5748 - val_accuracy: 0.6760\n",
            "Epoch 15/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.6931INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 93ms/step - loss: 0.5845 - accuracy: 0.6931 - val_loss: 0.5394 - val_accuracy: 0.7034\n",
            "Epoch 16/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.6836INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.5772 - accuracy: 0.6836 - val_loss: 0.5193 - val_accuracy: 0.7137\n",
            "Epoch 17/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.5697 - accuracy: 0.6912 - val_loss: 0.6047 - val_accuracy: 0.6731\n",
            "Epoch 18/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.5564 - accuracy: 0.7015 - val_loss: 0.5183 - val_accuracy: 0.7011\n",
            "Epoch 19/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.6962INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.5374 - accuracy: 0.6962 - val_loss: 0.4869 - val_accuracy: 0.7200\n",
            "Epoch 20/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.5404 - accuracy: 0.7084 - val_loss: 0.6142 - val_accuracy: 0.6903\n",
            "Epoch 21/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.7076INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 91ms/step - loss: 0.5368 - accuracy: 0.7076 - val_loss: 0.5066 - val_accuracy: 0.7217\n",
            "Epoch 22/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.5102 - accuracy: 0.7103 - val_loss: 0.5253 - val_accuracy: 0.7023\n",
            "Epoch 23/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.5059 - accuracy: 0.7177 - val_loss: 0.5114 - val_accuracy: 0.7114\n",
            "Epoch 24/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.5176 - accuracy: 0.7128 - val_loss: 0.5560 - val_accuracy: 0.7057\n",
            "Epoch 25/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.5014 - accuracy: 0.7080 - val_loss: 0.5296 - val_accuracy: 0.7166\n",
            "Epoch 26/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4776 - accuracy: 0.7280 - val_loss: 0.5372 - val_accuracy: 0.7126\n",
            "Epoch 27/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4906 - accuracy: 0.7152 - val_loss: 0.5167 - val_accuracy: 0.7131\n",
            "Epoch 28/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4955 - accuracy: 0.7240 - val_loss: 0.6055 - val_accuracy: 0.6909\n",
            "Epoch 29/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.5005 - accuracy: 0.7143 - val_loss: 0.4952 - val_accuracy: 0.7109\n",
            "Epoch 30/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4793 - accuracy: 0.7305 - val_loss: 0.5365 - val_accuracy: 0.7171\n",
            "Epoch 31/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.7379INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 99ms/step - loss: 0.4611 - accuracy: 0.7379 - val_loss: 0.5330 - val_accuracy: 0.7223\n",
            "Epoch 32/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4641 - accuracy: 0.7290 - val_loss: 0.5658 - val_accuracy: 0.7137\n",
            "Epoch 33/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4652 - accuracy: 0.7280 - val_loss: 0.5116 - val_accuracy: 0.7211\n",
            "Epoch 34/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.4569 - accuracy: 0.7417INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.4637 - accuracy: 0.7385 - val_loss: 0.5477 - val_accuracy: 0.7229\n",
            "Epoch 35/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.4712 - accuracy: 0.7322INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 92ms/step - loss: 0.4687 - accuracy: 0.7326 - val_loss: 0.5065 - val_accuracy: 0.7269\n",
            "Epoch 36/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4704 - accuracy: 0.7312 - val_loss: 0.5829 - val_accuracy: 0.7143\n",
            "Epoch 37/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4483 - accuracy: 0.7383 - val_loss: 0.6209 - val_accuracy: 0.7063\n",
            "Epoch 38/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.7274INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.4940 - accuracy: 0.7274 - val_loss: 0.5023 - val_accuracy: 0.7326\n",
            "Epoch 39/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4758 - accuracy: 0.7303 - val_loss: 0.5770 - val_accuracy: 0.7040\n",
            "Epoch 40/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4515 - accuracy: 0.7440 - val_loss: 0.5964 - val_accuracy: 0.6920\n",
            "Epoch 41/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4523 - accuracy: 0.7453 - val_loss: 0.5439 - val_accuracy: 0.7086\n",
            "Epoch 42/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4332 - accuracy: 0.7488 - val_loss: 0.5490 - val_accuracy: 0.7246\n",
            "Epoch 43/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4555 - accuracy: 0.7413 - val_loss: 0.6629 - val_accuracy: 0.7017\n",
            "Epoch 44/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4450 - accuracy: 0.7450 - val_loss: 0.6471 - val_accuracy: 0.7006\n",
            "Epoch 45/250\n",
            "21/21 [==============================] - 1s 29ms/step - loss: 0.4356 - accuracy: 0.7396 - val_loss: 0.6029 - val_accuracy: 0.7103\n",
            "Epoch 46/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.4309 - accuracy: 0.7541INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.4334 - accuracy: 0.7533 - val_loss: 0.5158 - val_accuracy: 0.7406\n",
            "Epoch 47/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.4510 - accuracy: 0.7440INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4493 - accuracy: 0.7457 - val_loss: 0.5069 - val_accuracy: 0.7440\n",
            "Epoch 48/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4213 - accuracy: 0.7650 - val_loss: 0.5489 - val_accuracy: 0.7429\n",
            "Epoch 49/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4108 - accuracy: 0.7570 - val_loss: 0.5027 - val_accuracy: 0.7429\n",
            "Epoch 50/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4204 - accuracy: 0.7688 - val_loss: 0.5799 - val_accuracy: 0.7189\n",
            "Epoch 51/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4413 - accuracy: 0.7539 - val_loss: 0.5103 - val_accuracy: 0.7331\n",
            "Epoch 52/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4189 - accuracy: 0.7590 - val_loss: 0.5884 - val_accuracy: 0.7069\n",
            "Epoch 53/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.4336 - accuracy: 0.7584INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.4331 - accuracy: 0.7570 - val_loss: 0.4845 - val_accuracy: 0.7486\n",
            "Epoch 54/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.4225 - accuracy: 0.7632INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 98ms/step - loss: 0.4219 - accuracy: 0.7611 - val_loss: 0.5394 - val_accuracy: 0.7503\n",
            "Epoch 55/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.4136 - accuracy: 0.7667 - val_loss: 0.5927 - val_accuracy: 0.7200\n",
            "Epoch 56/250\n",
            "21/21 [==============================] - 1s 26ms/step - loss: 0.3961 - accuracy: 0.7718 - val_loss: 0.5671 - val_accuracy: 0.7263\n",
            "Epoch 57/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3807 - accuracy: 0.7851 - val_loss: 0.5899 - val_accuracy: 0.7286\n",
            "Epoch 58/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.4021 - accuracy: 0.7766 - val_loss: 0.6920 - val_accuracy: 0.7297\n",
            "Epoch 59/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3976 - accuracy: 0.7779 - val_loss: 0.5364 - val_accuracy: 0.7457\n",
            "Epoch 60/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3788 - accuracy: 0.7891 - val_loss: 0.5291 - val_accuracy: 0.7400\n",
            "Epoch 61/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3769 - accuracy: 0.7876 - val_loss: 0.5664 - val_accuracy: 0.7486\n",
            "Epoch 62/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3663 - accuracy: 0.7941 - val_loss: 0.6269 - val_accuracy: 0.7291\n",
            "Epoch 63/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3725 - accuracy: 0.8040 - val_loss: 0.7562 - val_accuracy: 0.7177\n",
            "Epoch 64/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3997 - accuracy: 0.7846 - val_loss: 0.6494 - val_accuracy: 0.7240\n",
            "Epoch 65/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.3811 - accuracy: 0.7931INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3811 - accuracy: 0.7931 - val_loss: 0.4985 - val_accuracy: 0.7680\n",
            "Epoch 66/250\n",
            "21/21 [==============================] - 1s 26ms/step - loss: 0.3823 - accuracy: 0.7909 - val_loss: 0.7339 - val_accuracy: 0.7371\n",
            "Epoch 67/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.3629 - accuracy: 0.7996 - val_loss: 0.5716 - val_accuracy: 0.7383\n",
            "Epoch 68/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3343 - accuracy: 0.8204 - val_loss: 0.7878 - val_accuracy: 0.7234\n",
            "Epoch 69/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3483 - accuracy: 0.8150 - val_loss: 0.7796 - val_accuracy: 0.7206\n",
            "Epoch 70/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3541 - accuracy: 0.8110 - val_loss: 0.7296 - val_accuracy: 0.7520\n",
            "Epoch 71/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.3729 - accuracy: 0.8029INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.3760 - accuracy: 0.8004 - val_loss: 0.5635 - val_accuracy: 0.7714\n",
            "Epoch 72/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.3548 - accuracy: 0.8112 - val_loss: 0.5132 - val_accuracy: 0.7640\n",
            "Epoch 73/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.3367 - accuracy: 0.8170 - val_loss: 0.6254 - val_accuracy: 0.7486\n",
            "Epoch 74/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.3343 - accuracy: 0.8230INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 91ms/step - loss: 0.3319 - accuracy: 0.8236 - val_loss: 0.5581 - val_accuracy: 0.7726\n",
            "Epoch 75/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3238 - accuracy: 0.8291 - val_loss: 0.6991 - val_accuracy: 0.7503\n",
            "Epoch 76/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.8234INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.3560 - accuracy: 0.8234 - val_loss: 0.5550 - val_accuracy: 0.7771\n",
            "Epoch 77/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3530 - accuracy: 0.8189 - val_loss: 0.5113 - val_accuracy: 0.7720\n",
            "Epoch 78/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3202 - accuracy: 0.8337 - val_loss: 0.6785 - val_accuracy: 0.7589\n",
            "Epoch 79/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.3139 - accuracy: 0.8297INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 89ms/step - loss: 0.3143 - accuracy: 0.8299 - val_loss: 0.5480 - val_accuracy: 0.7794\n",
            "Epoch 80/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.3063 - accuracy: 0.8413 - val_loss: 0.6390 - val_accuracy: 0.7771\n",
            "Epoch 81/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.2928 - accuracy: 0.8478 - val_loss: 0.5515 - val_accuracy: 0.7737\n",
            "Epoch 82/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.2976 - accuracy: 0.8451 - val_loss: 0.6491 - val_accuracy: 0.7754\n",
            "Epoch 83/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.2904 - accuracy: 0.8509 - val_loss: 0.8278 - val_accuracy: 0.7669\n",
            "Epoch 84/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.2812 - accuracy: 0.8581 - val_loss: 0.7654 - val_accuracy: 0.7691\n",
            "Epoch 85/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.8615INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2879 - accuracy: 0.8615 - val_loss: 0.6416 - val_accuracy: 0.7954\n",
            "Epoch 86/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.2844 - accuracy: 0.8640 - val_loss: 0.7725 - val_accuracy: 0.7743\n",
            "Epoch 87/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.2648 - accuracy: 0.8636 - val_loss: 0.7875 - val_accuracy: 0.7857\n",
            "Epoch 88/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.2675 - accuracy: 0.8724INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 96ms/step - loss: 0.2700 - accuracy: 0.8716 - val_loss: 0.6129 - val_accuracy: 0.7971\n",
            "Epoch 89/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.8752INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 88ms/step - loss: 0.2636 - accuracy: 0.8752 - val_loss: 0.6902 - val_accuracy: 0.8091\n",
            "Epoch 90/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.2608 - accuracy: 0.8754INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2706 - accuracy: 0.8728 - val_loss: 0.5389 - val_accuracy: 0.8103\n",
            "Epoch 91/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.3370 - accuracy: 0.8581 - val_loss: 0.4805 - val_accuracy: 0.8023\n",
            "Epoch 92/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.8770INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 86ms/step - loss: 0.2714 - accuracy: 0.8770 - val_loss: 0.5482 - val_accuracy: 0.8229\n",
            "Epoch 93/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.2595 - accuracy: 0.8901INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 102ms/step - loss: 0.2569 - accuracy: 0.8914 - val_loss: 0.5125 - val_accuracy: 0.8309\n",
            "Epoch 94/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.2299 - accuracy: 0.8964INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2283 - accuracy: 0.8968 - val_loss: 0.5556 - val_accuracy: 0.8337\n",
            "Epoch 95/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.2306 - accuracy: 0.9029INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.2265 - accuracy: 0.9042 - val_loss: 0.5846 - val_accuracy: 0.8446\n",
            "Epoch 96/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.2028 - accuracy: 0.9179 - val_loss: 0.6978 - val_accuracy: 0.8171\n",
            "Epoch 97/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9152INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 103ms/step - loss: 0.1976 - accuracy: 0.9152 - val_loss: 0.5243 - val_accuracy: 0.8474\n",
            "Epoch 98/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.2062 - accuracy: 0.9158 - val_loss: 1.2124 - val_accuracy: 0.7811\n",
            "Epoch 99/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.2183 - accuracy: 0.9183INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 87ms/step - loss: 0.2152 - accuracy: 0.9194 - val_loss: 0.4455 - val_accuracy: 0.8651\n",
            "Epoch 100/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1854 - accuracy: 0.9282 - val_loss: 0.4309 - val_accuracy: 0.8634\n",
            "Epoch 101/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1780 - accuracy: 0.9314 - val_loss: 0.7554 - val_accuracy: 0.8360\n",
            "Epoch 102/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1689 - accuracy: 0.9318 - val_loss: 0.6726 - val_accuracy: 0.8360\n",
            "Epoch 103/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.1646 - accuracy: 0.9331INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 92ms/step - loss: 0.1646 - accuracy: 0.9324 - val_loss: 0.5507 - val_accuracy: 0.8680\n",
            "Epoch 104/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1579 - accuracy: 0.9360 - val_loss: 0.6141 - val_accuracy: 0.8583\n",
            "Epoch 105/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1564 - accuracy: 0.9394 - val_loss: 0.5350 - val_accuracy: 0.8657\n",
            "Epoch 106/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.1874 - accuracy: 0.9295INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 85ms/step - loss: 0.1830 - accuracy: 0.9309 - val_loss: 0.4637 - val_accuracy: 0.8737\n",
            "Epoch 107/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1596 - accuracy: 0.9387 - val_loss: 0.5702 - val_accuracy: 0.8583\n",
            "Epoch 108/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1404 - accuracy: 0.9459 - val_loss: 0.5511 - val_accuracy: 0.8697\n",
            "Epoch 109/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1572 - accuracy: 0.9366 - val_loss: 0.7443 - val_accuracy: 0.8429\n",
            "Epoch 110/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1708 - accuracy: 0.9358 - val_loss: 0.4604 - val_accuracy: 0.8697\n",
            "Epoch 111/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1661 - accuracy: 0.9373 - val_loss: 0.9736 - val_accuracy: 0.8234\n",
            "Epoch 112/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1928 - accuracy: 0.9276 - val_loss: 0.5166 - val_accuracy: 0.8691\n",
            "Epoch 113/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1421 - accuracy: 0.9484 - val_loss: 0.6110 - val_accuracy: 0.8606\n",
            "Epoch 114/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.9470INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod/assets\n",
            "21/21 [==============================] - 2s 97ms/step - loss: 0.1429 - accuracy: 0.9470 - val_loss: 0.5193 - val_accuracy: 0.8789\n",
            "Epoch 115/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1283 - accuracy: 0.9541 - val_loss: 0.7818 - val_accuracy: 0.8497\n",
            "Epoch 116/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1242 - accuracy: 0.9535 - val_loss: 0.7974 - val_accuracy: 0.8469\n",
            "Epoch 117/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1214 - accuracy: 0.9573 - val_loss: 0.6520 - val_accuracy: 0.8611\n",
            "Epoch 118/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1303 - accuracy: 0.9522 - val_loss: 0.5105 - val_accuracy: 0.8714\n",
            "Epoch 119/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1166 - accuracy: 0.9505 - val_loss: 0.8048 - val_accuracy: 0.8440\n",
            "Epoch 120/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1182 - accuracy: 0.9556 - val_loss: 0.5578 - val_accuracy: 0.8760\n",
            "Epoch 121/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1270 - accuracy: 0.9518 - val_loss: 0.7024 - val_accuracy: 0.8566\n",
            "Epoch 122/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1185 - accuracy: 0.9550 - val_loss: 0.9181 - val_accuracy: 0.8417\n",
            "Epoch 123/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1290 - accuracy: 0.9516 - val_loss: 0.5881 - val_accuracy: 0.8606\n",
            "Epoch 124/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1122 - accuracy: 0.9602 - val_loss: 0.6455 - val_accuracy: 0.8686\n",
            "Epoch 125/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1200 - accuracy: 0.9547 - val_loss: 0.6308 - val_accuracy: 0.8606\n",
            "Epoch 126/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1212 - accuracy: 0.9558 - val_loss: 1.0289 - val_accuracy: 0.8366\n",
            "Epoch 127/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1224 - accuracy: 0.9570 - val_loss: 0.7829 - val_accuracy: 0.8549\n",
            "Epoch 128/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1076 - accuracy: 0.9606 - val_loss: 0.8005 - val_accuracy: 0.8526\n",
            "Epoch 129/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1036 - accuracy: 0.9630 - val_loss: 0.8821 - val_accuracy: 0.8497\n",
            "Epoch 130/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1238 - accuracy: 0.9556 - val_loss: 0.8580 - val_accuracy: 0.8486\n",
            "Epoch 131/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1100 - accuracy: 0.9602 - val_loss: 0.6174 - val_accuracy: 0.8743\n",
            "Epoch 132/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.1112 - accuracy: 0.9587 - val_loss: 0.6506 - val_accuracy: 0.8731\n",
            "Epoch 133/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0999 - accuracy: 0.9625 - val_loss: 0.7872 - val_accuracy: 0.8629\n",
            "Epoch 134/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.9657\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.1010 - accuracy: 0.9657 - val_loss: 0.9168 - val_accuracy: 0.8474\n",
            "Epoch 135/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0851 - accuracy: 0.9674 - val_loss: 0.7259 - val_accuracy: 0.8611\n",
            "Epoch 136/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0932 - accuracy: 0.9644 - val_loss: 0.6802 - val_accuracy: 0.8680\n",
            "Epoch 137/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0871 - accuracy: 0.9686 - val_loss: 1.0015 - val_accuracy: 0.8429\n",
            "Epoch 138/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0901 - accuracy: 0.9640 - val_loss: 0.8878 - val_accuracy: 0.8491\n",
            "Epoch 139/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0864 - accuracy: 0.9703 - val_loss: 0.7305 - val_accuracy: 0.8686\n",
            "Epoch 140/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0827 - accuracy: 0.9722 - val_loss: 0.8228 - val_accuracy: 0.8549\n",
            "Epoch 141/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0896 - accuracy: 0.9667 - val_loss: 0.7737 - val_accuracy: 0.8634\n",
            "Epoch 142/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0841 - accuracy: 0.9670 - val_loss: 0.6870 - val_accuracy: 0.8691\n",
            "Epoch 143/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0844 - accuracy: 0.9670 - val_loss: 0.7280 - val_accuracy: 0.8697\n",
            "Epoch 144/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0864 - accuracy: 0.9691 - val_loss: 0.9967 - val_accuracy: 0.8480\n",
            "Epoch 145/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0769 - accuracy: 0.9697 - val_loss: 0.7295 - val_accuracy: 0.8674\n",
            "Epoch 146/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0812 - accuracy: 0.9691 - val_loss: 0.7445 - val_accuracy: 0.8674\n",
            "Epoch 147/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0871 - accuracy: 0.9693 - val_loss: 0.8579 - val_accuracy: 0.8560\n",
            "Epoch 148/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0750 - accuracy: 0.9703 - val_loss: 0.8505 - val_accuracy: 0.8560\n",
            "Epoch 149/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0771 - accuracy: 0.9691 - val_loss: 0.9378 - val_accuracy: 0.8491\n",
            "Epoch 150/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0769 - accuracy: 0.9718 - val_loss: 0.8881 - val_accuracy: 0.8537\n",
            "Epoch 151/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0755 - accuracy: 0.9728 - val_loss: 0.7945 - val_accuracy: 0.8680\n",
            "Epoch 152/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0773 - accuracy: 0.9709 - val_loss: 0.9671 - val_accuracy: 0.8514\n",
            "Epoch 153/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0848 - accuracy: 0.9672 - val_loss: 0.6808 - val_accuracy: 0.8731\n",
            "Epoch 154/250\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.9716\n",
            "Epoch 00154: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "21/21 [==============================] - 1s 29ms/step - loss: 0.0827 - accuracy: 0.9716 - val_loss: 0.6848 - val_accuracy: 0.8726\n",
            "Epoch 155/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0716 - accuracy: 0.9733 - val_loss: 0.7427 - val_accuracy: 0.8726\n",
            "Epoch 156/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0732 - accuracy: 0.9726 - val_loss: 0.8103 - val_accuracy: 0.8669\n",
            "Epoch 157/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0705 - accuracy: 0.9754 - val_loss: 0.8300 - val_accuracy: 0.8640\n",
            "Epoch 158/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0718 - accuracy: 0.9741 - val_loss: 0.8019 - val_accuracy: 0.8657\n",
            "Epoch 159/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0697 - accuracy: 0.9754 - val_loss: 0.7886 - val_accuracy: 0.8646\n",
            "Epoch 160/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0690 - accuracy: 0.9760 - val_loss: 0.8378 - val_accuracy: 0.8640\n",
            "Epoch 161/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0700 - accuracy: 0.9741 - val_loss: 0.8032 - val_accuracy: 0.8663\n",
            "Epoch 162/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0785 - accuracy: 0.9716 - val_loss: 0.8278 - val_accuracy: 0.8651\n",
            "Epoch 163/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0670 - accuracy: 0.9756 - val_loss: 0.8458 - val_accuracy: 0.8611\n",
            "Epoch 164/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0721 - accuracy: 0.9758 - val_loss: 0.8292 - val_accuracy: 0.8651\n",
            "Epoch 165/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0762 - accuracy: 0.9739 - val_loss: 0.8011 - val_accuracy: 0.8674\n",
            "Epoch 166/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0742 - accuracy: 0.9726 - val_loss: 0.8101 - val_accuracy: 0.8657\n",
            "Epoch 167/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0755 - accuracy: 0.9733 - val_loss: 0.7716 - val_accuracy: 0.8709\n",
            "Epoch 168/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0717 - accuracy: 0.9720 - val_loss: 0.7530 - val_accuracy: 0.8691\n",
            "Epoch 169/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0680 - accuracy: 0.9750 - val_loss: 0.7699 - val_accuracy: 0.8674\n",
            "Epoch 170/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0755 - accuracy: 0.9741 - val_loss: 0.7910 - val_accuracy: 0.8674\n",
            "Epoch 171/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0695 - accuracy: 0.9739 - val_loss: 0.7905 - val_accuracy: 0.8680\n",
            "Epoch 172/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0706 - accuracy: 0.9728 - val_loss: 0.8000 - val_accuracy: 0.8697\n",
            "Epoch 173/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0745 - accuracy: 0.9714 - val_loss: 0.8507 - val_accuracy: 0.8640\n",
            "Epoch 174/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0712 - accuracy: 0.9760\n",
            "Epoch 00174: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0728 - accuracy: 0.9750 - val_loss: 0.8242 - val_accuracy: 0.8663\n",
            "Epoch 175/250\n",
            "21/21 [==============================] - 1s 26ms/step - loss: 0.0726 - accuracy: 0.9762 - val_loss: 0.8259 - val_accuracy: 0.8669\n",
            "Epoch 176/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0743 - accuracy: 0.9733 - val_loss: 0.8295 - val_accuracy: 0.8651\n",
            "Epoch 177/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0785 - accuracy: 0.9743 - val_loss: 0.8233 - val_accuracy: 0.8663\n",
            "Epoch 178/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0676 - accuracy: 0.9733 - val_loss: 0.8299 - val_accuracy: 0.8651\n",
            "Epoch 179/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0640 - accuracy: 0.9768 - val_loss: 0.8241 - val_accuracy: 0.8663\n",
            "Epoch 180/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0648 - accuracy: 0.9766 - val_loss: 0.8317 - val_accuracy: 0.8669\n",
            "Epoch 181/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0698 - accuracy: 0.9739 - val_loss: 0.8086 - val_accuracy: 0.8680\n",
            "Epoch 182/250\n",
            "21/21 [==============================] - 1s 26ms/step - loss: 0.0770 - accuracy: 0.9728 - val_loss: 0.8084 - val_accuracy: 0.8680\n",
            "Epoch 183/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0734 - accuracy: 0.9735 - val_loss: 0.8126 - val_accuracy: 0.8663\n",
            "Epoch 184/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0663 - accuracy: 0.9750 - val_loss: 0.8281 - val_accuracy: 0.8669\n",
            "Epoch 185/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0638 - accuracy: 0.9779 - val_loss: 0.8319 - val_accuracy: 0.8669\n",
            "Epoch 186/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0707 - accuracy: 0.9735 - val_loss: 0.8336 - val_accuracy: 0.8663\n",
            "Epoch 187/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0767 - accuracy: 0.9718 - val_loss: 0.8183 - val_accuracy: 0.8680\n",
            "Epoch 188/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0641 - accuracy: 0.9766 - val_loss: 0.8166 - val_accuracy: 0.8680\n",
            "Epoch 189/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0753 - accuracy: 0.9733 - val_loss: 0.8122 - val_accuracy: 0.8680\n",
            "Epoch 190/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0667 - accuracy: 0.9741 - val_loss: 0.7963 - val_accuracy: 0.8691\n",
            "Epoch 191/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0645 - accuracy: 0.9787 - val_loss: 0.7899 - val_accuracy: 0.8691\n",
            "Epoch 192/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0730 - accuracy: 0.9743 - val_loss: 0.7820 - val_accuracy: 0.8697\n",
            "Epoch 193/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0726 - accuracy: 0.9737 - val_loss: 0.8075 - val_accuracy: 0.8669\n",
            "Epoch 194/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0713 - accuracy: 0.9758\n",
            "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0700 - accuracy: 0.9760 - val_loss: 0.8231 - val_accuracy: 0.8669\n",
            "Epoch 195/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0682 - accuracy: 0.9750 - val_loss: 0.8207 - val_accuracy: 0.8674\n",
            "Epoch 196/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0686 - accuracy: 0.9756 - val_loss: 0.8213 - val_accuracy: 0.8674\n",
            "Epoch 197/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0753 - accuracy: 0.9705 - val_loss: 0.8242 - val_accuracy: 0.8663\n",
            "Epoch 198/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0622 - accuracy: 0.9781 - val_loss: 0.8199 - val_accuracy: 0.8674\n",
            "Epoch 199/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0735 - accuracy: 0.9728 - val_loss: 0.8194 - val_accuracy: 0.8674\n",
            "Epoch 200/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0709 - accuracy: 0.9749 - val_loss: 0.8190 - val_accuracy: 0.8680\n",
            "Epoch 201/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0688 - accuracy: 0.9771 - val_loss: 0.8193 - val_accuracy: 0.8674\n",
            "Epoch 202/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0730 - accuracy: 0.9735 - val_loss: 0.8231 - val_accuracy: 0.8669\n",
            "Epoch 203/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0706 - accuracy: 0.9731 - val_loss: 0.8256 - val_accuracy: 0.8669\n",
            "Epoch 204/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0704 - accuracy: 0.9728 - val_loss: 0.8248 - val_accuracy: 0.8663\n",
            "Epoch 205/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0699 - accuracy: 0.9749 - val_loss: 0.8177 - val_accuracy: 0.8680\n",
            "Epoch 206/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0676 - accuracy: 0.9762 - val_loss: 0.8133 - val_accuracy: 0.8669\n",
            "Epoch 207/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0654 - accuracy: 0.9764 - val_loss: 0.8123 - val_accuracy: 0.8669\n",
            "Epoch 208/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0671 - accuracy: 0.9758 - val_loss: 0.8084 - val_accuracy: 0.8680\n",
            "Epoch 209/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0707 - accuracy: 0.9728 - val_loss: 0.8069 - val_accuracy: 0.8674\n",
            "Epoch 210/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0746 - accuracy: 0.9739 - val_loss: 0.8088 - val_accuracy: 0.8680\n",
            "Epoch 211/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0733 - accuracy: 0.9709 - val_loss: 0.8099 - val_accuracy: 0.8680\n",
            "Epoch 212/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0689 - accuracy: 0.9735 - val_loss: 0.8117 - val_accuracy: 0.8674\n",
            "Epoch 213/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0687 - accuracy: 0.9768 - val_loss: 0.8161 - val_accuracy: 0.8680\n",
            "Epoch 214/250\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0750 - accuracy: 0.9720\n",
            "Epoch 00214: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0733 - accuracy: 0.9722 - val_loss: 0.8131 - val_accuracy: 0.8680\n",
            "Epoch 215/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0701 - accuracy: 0.9739 - val_loss: 0.8136 - val_accuracy: 0.8680\n",
            "Epoch 216/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0697 - accuracy: 0.9741 - val_loss: 0.8131 - val_accuracy: 0.8680\n",
            "Epoch 217/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0663 - accuracy: 0.9747 - val_loss: 0.8122 - val_accuracy: 0.8680\n",
            "Epoch 218/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0706 - accuracy: 0.9745 - val_loss: 0.8119 - val_accuracy: 0.8680\n",
            "Epoch 219/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0727 - accuracy: 0.9741 - val_loss: 0.8124 - val_accuracy: 0.8680\n",
            "Epoch 220/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0637 - accuracy: 0.9750 - val_loss: 0.8128 - val_accuracy: 0.8680\n",
            "Epoch 221/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0675 - accuracy: 0.9745 - val_loss: 0.8136 - val_accuracy: 0.8680\n",
            "Epoch 222/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0641 - accuracy: 0.9771 - val_loss: 0.8138 - val_accuracy: 0.8680\n",
            "Epoch 223/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0730 - accuracy: 0.9747 - val_loss: 0.8141 - val_accuracy: 0.8674\n",
            "Epoch 224/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0667 - accuracy: 0.9773 - val_loss: 0.8133 - val_accuracy: 0.8680\n",
            "Epoch 225/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0767 - accuracy: 0.9726 - val_loss: 0.8130 - val_accuracy: 0.8680\n",
            "Epoch 226/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0681 - accuracy: 0.9756 - val_loss: 0.8134 - val_accuracy: 0.8680\n",
            "Epoch 227/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0733 - accuracy: 0.9714 - val_loss: 0.8142 - val_accuracy: 0.8680\n",
            "Epoch 228/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0679 - accuracy: 0.9747 - val_loss: 0.8147 - val_accuracy: 0.8680\n",
            "Epoch 229/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0662 - accuracy: 0.9764 - val_loss: 0.8142 - val_accuracy: 0.8680\n",
            "Epoch 230/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0719 - accuracy: 0.9743 - val_loss: 0.8138 - val_accuracy: 0.8680\n",
            "Epoch 231/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0702 - accuracy: 0.9735 - val_loss: 0.8129 - val_accuracy: 0.8680\n",
            "Epoch 232/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0645 - accuracy: 0.9768 - val_loss: 0.8129 - val_accuracy: 0.8680\n",
            "Epoch 233/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0681 - accuracy: 0.9731 - val_loss: 0.8131 - val_accuracy: 0.8680\n",
            "Epoch 234/250\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0640 - accuracy: 0.9770\n",
            "Epoch 00234: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0638 - accuracy: 0.9770 - val_loss: 0.8137 - val_accuracy: 0.8680\n",
            "Epoch 235/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0692 - accuracy: 0.9750 - val_loss: 0.8135 - val_accuracy: 0.8680\n",
            "Epoch 236/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0718 - accuracy: 0.9731 - val_loss: 0.8135 - val_accuracy: 0.8680\n",
            "Epoch 237/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0733 - accuracy: 0.9735 - val_loss: 0.8134 - val_accuracy: 0.8680\n",
            "Epoch 238/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0642 - accuracy: 0.9779 - val_loss: 0.8134 - val_accuracy: 0.8680\n",
            "Epoch 239/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0679 - accuracy: 0.9747 - val_loss: 0.8135 - val_accuracy: 0.8680\n",
            "Epoch 240/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0673 - accuracy: 0.9739 - val_loss: 0.8135 - val_accuracy: 0.8680\n",
            "Epoch 241/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0683 - accuracy: 0.9718 - val_loss: 0.8132 - val_accuracy: 0.8680\n",
            "Epoch 242/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0659 - accuracy: 0.9754 - val_loss: 0.8131 - val_accuracy: 0.8680\n",
            "Epoch 243/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0713 - accuracy: 0.9724 - val_loss: 0.8131 - val_accuracy: 0.8680\n",
            "Epoch 244/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0763 - accuracy: 0.9718 - val_loss: 0.8133 - val_accuracy: 0.8680\n",
            "Epoch 245/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0709 - accuracy: 0.9745 - val_loss: 0.8133 - val_accuracy: 0.8680\n",
            "Epoch 246/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0734 - accuracy: 0.9758 - val_loss: 0.8133 - val_accuracy: 0.8680\n",
            "Epoch 247/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0720 - accuracy: 0.9733 - val_loss: 0.8135 - val_accuracy: 0.8680\n",
            "Epoch 248/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0754 - accuracy: 0.9705 - val_loss: 0.8136 - val_accuracy: 0.8680\n",
            "Epoch 249/250\n",
            "21/21 [==============================] - 1s 27ms/step - loss: 0.0719 - accuracy: 0.9749 - val_loss: 0.8134 - val_accuracy: 0.8680\n",
            "Epoch 250/250\n",
            "21/21 [==============================] - 1s 28ms/step - loss: 0.0687 - accuracy: 0.9760 - val_loss: 0.8133 - val_accuracy: 0.8680\n",
            "Time: 206.62163186073303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLLmpfmQnnck",
        "outputId": "92810aa7-d1f3-47b2-c99d-5ea56dcc5a80"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train the network with 500 simulations per model\n",
        "################################################################################################################################################\n",
        "\n",
        "x=np.concatenate((u1[0:500,:,:],u2[0:500,:,:],u3[0:500,:,:],u4[0:500,:,:],u5[0:500,:,:],u6[0:500,:,:],u7[0:500,:,:]),axis=0)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "\n",
        "x=x.astype(np.uint8)\n",
        "\n",
        "y=[0 for i in range(len(u1[0:500,:,:]))]\n",
        "y.extend([1 for i in range(len(u2[0:500,:,:]))])\n",
        "y.extend([2 for i in range(len(u3[0:500,:,:]))])\n",
        "y.extend([3 for i in range(len(u4[0:500,:,:]))])\n",
        "y.extend([4 for i in range(len(u5[0:500,:,:]))])\n",
        "y.extend([5 for i in range(len(u6[0:500,:,:]))])\n",
        "y.extend([6 for i in range(len(u7[0:500,:,:]))])\n",
        "y = np.array(y)\n",
        "\n",
        "print (len(x), len(y))\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "start = time.time()\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n",
        "print (f'Time: {time.time() - start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3500 3500\n",
            "Model: \"functional_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 195, 64)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 194, 250)          32250     \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 193, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_10 (Averag (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 96, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 95, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_11 (Averag (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 47, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 5875)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 125)               734500    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 7)                 882       \n",
            "=================================================================\n",
            "Total params: 877,382\n",
            "Trainable params: 877,382\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            " 9/11 [=======================>......] - ETA: 0s - loss: 1.9794 - accuracy: 0.1471INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.9751 - accuracy: 0.1451 - val_loss: 1.9341 - val_accuracy: 0.2034\n",
            "Epoch 2/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.9030 - accuracy: 0.1804INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 126ms/step - loss: 1.9042 - accuracy: 0.1806 - val_loss: 1.8131 - val_accuracy: 0.2251\n",
            "Epoch 3/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.7297 - accuracy: 0.2752INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 153ms/step - loss: 1.7273 - accuracy: 0.2777 - val_loss: 1.5950 - val_accuracy: 0.3371\n",
            "Epoch 4/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1.6233 - accuracy: 0.2933 - val_loss: 1.5083 - val_accuracy: 0.2983\n",
            "Epoch 5/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1.5496 - accuracy: 0.3017 - val_loss: 1.4412 - val_accuracy: 0.3131\n",
            "Epoch 6/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.4893 - accuracy: 0.2988INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.4847 - accuracy: 0.2994 - val_loss: 1.3862 - val_accuracy: 0.3589\n",
            "Epoch 7/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.4143 - accuracy: 0.3276INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 138ms/step - loss: 1.4113 - accuracy: 0.3284 - val_loss: 1.3483 - val_accuracy: 0.4389\n",
            "Epoch 8/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1.3872 - accuracy: 0.3326 - val_loss: 1.2953 - val_accuracy: 0.4080\n",
            "Epoch 9/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 1.3337 - accuracy: 0.3756 - val_loss: 1.2345 - val_accuracy: 0.4183\n",
            "Epoch 10/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.2793 - accuracy: 0.3972INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.2772 - accuracy: 0.3996 - val_loss: 1.1658 - val_accuracy: 0.4480\n",
            "Epoch 11/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.2493 - accuracy: 0.3928INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 152ms/step - loss: 1.2496 - accuracy: 0.3935 - val_loss: 1.1397 - val_accuracy: 0.4503\n",
            "Epoch 12/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.2057 - accuracy: 0.4452INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 143ms/step - loss: 1.2064 - accuracy: 0.4442 - val_loss: 1.0790 - val_accuracy: 0.4777\n",
            "Epoch 13/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.1551 - accuracy: 0.4660INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 1.1565 - accuracy: 0.4674 - val_loss: 1.0309 - val_accuracy: 0.5234\n",
            "Epoch 14/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.1110 - accuracy: 0.4708INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 1.1063 - accuracy: 0.4731 - val_loss: 0.9796 - val_accuracy: 0.5589\n",
            "Epoch 15/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.0441 - accuracy: 0.5084INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 169ms/step - loss: 1.0493 - accuracy: 0.5090 - val_loss: 0.8543 - val_accuracy: 0.5669\n",
            "Epoch 16/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.9622 - accuracy: 0.5520INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.9642 - accuracy: 0.5531 - val_loss: 0.7903 - val_accuracy: 0.5829\n",
            "Epoch 17/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.9121 - accuracy: 0.5552INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 133ms/step - loss: 0.9206 - accuracy: 0.5539 - val_loss: 0.7363 - val_accuracy: 0.6080\n",
            "Epoch 18/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.8770 - accuracy: 0.5620INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 145ms/step - loss: 0.8721 - accuracy: 0.5646 - val_loss: 0.7324 - val_accuracy: 0.6206\n",
            "Epoch 19/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.8568 - accuracy: 0.6011 - val_loss: 0.7247 - val_accuracy: 0.5737\n",
            "Epoch 20/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.8500 - accuracy: 0.5860INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.8459 - accuracy: 0.5878 - val_loss: 0.6709 - val_accuracy: 0.6697\n",
            "Epoch 21/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.7736 - accuracy: 0.6156INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 155ms/step - loss: 0.7745 - accuracy: 0.6160 - val_loss: 0.6331 - val_accuracy: 0.6777\n",
            "Epoch 22/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.7615 - accuracy: 0.6202 - val_loss: 0.6944 - val_accuracy: 0.6160\n",
            "Epoch 23/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.7402 - accuracy: 0.6225 - val_loss: 0.7015 - val_accuracy: 0.6400\n",
            "Epoch 24/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.6954 - accuracy: 0.6404 - val_loss: 0.5839 - val_accuracy: 0.6617\n",
            "Epoch 25/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.6615 - accuracy: 0.6579 - val_loss: 0.5863 - val_accuracy: 0.6560\n",
            "Epoch 26/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.6306 - accuracy: 0.6692INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 129ms/step - loss: 0.6264 - accuracy: 0.6720 - val_loss: 0.5625 - val_accuracy: 0.6857\n",
            "Epoch 27/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.6081 - accuracy: 0.6796 - val_loss: 0.5506 - val_accuracy: 0.6811\n",
            "Epoch 28/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.6032 - accuracy: 0.6712 - val_loss: 0.5391 - val_accuracy: 0.6754\n",
            "Epoch 29/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.5907 - accuracy: 0.6857 - val_loss: 0.5643 - val_accuracy: 0.6811\n",
            "Epoch 30/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.5791 - accuracy: 0.6735 - val_loss: 0.5466 - val_accuracy: 0.6811\n",
            "Epoch 31/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.5889 - accuracy: 0.6900INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 130ms/step - loss: 0.5885 - accuracy: 0.6869 - val_loss: 0.6188 - val_accuracy: 0.6891\n",
            "Epoch 32/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.6039 - accuracy: 0.6754 - val_loss: 0.6964 - val_accuracy: 0.6446\n",
            "Epoch 33/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.5579 - accuracy: 0.6928INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 144ms/step - loss: 0.5571 - accuracy: 0.6922 - val_loss: 0.5174 - val_accuracy: 0.7040\n",
            "Epoch 34/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.5374 - accuracy: 0.7059 - val_loss: 0.7075 - val_accuracy: 0.6629\n",
            "Epoch 35/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.5426 - accuracy: 0.6830 - val_loss: 0.5213 - val_accuracy: 0.6926\n",
            "Epoch 36/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.5204 - accuracy: 0.7162 - val_loss: 0.6361 - val_accuracy: 0.6903\n",
            "Epoch 37/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.5310 - accuracy: 0.7147 - val_loss: 0.5798 - val_accuracy: 0.6709\n",
            "Epoch 38/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.5500 - accuracy: 0.6956 - val_loss: 0.5822 - val_accuracy: 0.6949\n",
            "Epoch 39/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.5259 - accuracy: 0.7067 - val_loss: 0.6521 - val_accuracy: 0.6857\n",
            "Epoch 40/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.5311 - accuracy: 0.7048 - val_loss: 0.5856 - val_accuracy: 0.6594\n",
            "Epoch 41/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.5248 - accuracy: 0.7105 - val_loss: 0.5919 - val_accuracy: 0.6789\n",
            "Epoch 42/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.5042 - accuracy: 0.7088INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 154ms/step - loss: 0.5005 - accuracy: 0.7101 - val_loss: 0.5728 - val_accuracy: 0.7154\n",
            "Epoch 43/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4866 - accuracy: 0.7204 - val_loss: 0.5527 - val_accuracy: 0.7063\n",
            "Epoch 44/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4924 - accuracy: 0.7170 - val_loss: 0.5832 - val_accuracy: 0.7017\n",
            "Epoch 45/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4692 - accuracy: 0.7276 - val_loss: 0.6838 - val_accuracy: 0.6869\n",
            "Epoch 46/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4723 - accuracy: 0.7303 - val_loss: 0.5597 - val_accuracy: 0.6811\n",
            "Epoch 47/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4902 - accuracy: 0.7196 - val_loss: 0.6309 - val_accuracy: 0.6949\n",
            "Epoch 48/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4607 - accuracy: 0.7230 - val_loss: 0.6305 - val_accuracy: 0.6766\n",
            "Epoch 49/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4655 - accuracy: 0.7291 - val_loss: 0.6229 - val_accuracy: 0.7006\n",
            "Epoch 50/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4764 - accuracy: 0.7333 - val_loss: 0.6438 - val_accuracy: 0.6846\n",
            "Epoch 51/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4553 - accuracy: 0.7238 - val_loss: 0.5858 - val_accuracy: 0.6880\n",
            "Epoch 52/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.4633 - accuracy: 0.7172INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 127ms/step - loss: 0.4629 - accuracy: 0.7170 - val_loss: 0.5476 - val_accuracy: 0.7223\n",
            "Epoch 53/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4609 - accuracy: 0.7345 - val_loss: 0.6475 - val_accuracy: 0.6811\n",
            "Epoch 54/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4706 - accuracy: 0.7314 - val_loss: 0.6931 - val_accuracy: 0.6926\n",
            "Epoch 55/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4487 - accuracy: 0.7425 - val_loss: 0.5627 - val_accuracy: 0.7063\n",
            "Epoch 56/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4671 - accuracy: 0.7299 - val_loss: 0.5983 - val_accuracy: 0.7189\n",
            "Epoch 57/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4424 - accuracy: 0.7356 - val_loss: 0.6081 - val_accuracy: 0.7154\n",
            "Epoch 58/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4414 - accuracy: 0.7440 - val_loss: 0.5533 - val_accuracy: 0.7017\n",
            "Epoch 59/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4698 - accuracy: 0.7288 - val_loss: 0.5836 - val_accuracy: 0.7017\n",
            "Epoch 60/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.4673 - accuracy: 0.7192 - val_loss: 0.6407 - val_accuracy: 0.7120\n",
            "Epoch 61/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4843 - accuracy: 0.7322 - val_loss: 0.5593 - val_accuracy: 0.6960\n",
            "Epoch 62/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4570 - accuracy: 0.7390 - val_loss: 0.6735 - val_accuracy: 0.7006\n",
            "Epoch 63/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4376 - accuracy: 0.7497 - val_loss: 0.7156 - val_accuracy: 0.7040\n",
            "Epoch 64/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4351 - accuracy: 0.7520 - val_loss: 0.5602 - val_accuracy: 0.6994\n",
            "Epoch 65/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4336 - accuracy: 0.7425 - val_loss: 0.5748 - val_accuracy: 0.7051\n",
            "Epoch 66/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4340 - accuracy: 0.7470 - val_loss: 0.6097 - val_accuracy: 0.7029\n",
            "Epoch 67/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4196 - accuracy: 0.7516 - val_loss: 0.7634 - val_accuracy: 0.6869\n",
            "Epoch 68/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4625 - accuracy: 0.7330 - val_loss: 0.5553 - val_accuracy: 0.6880\n",
            "Epoch 69/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.4422 - accuracy: 0.7468INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 140ms/step - loss: 0.4405 - accuracy: 0.7497 - val_loss: 0.5550 - val_accuracy: 0.7314\n",
            "Epoch 70/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4314 - accuracy: 0.7486 - val_loss: 0.5567 - val_accuracy: 0.7257\n",
            "Epoch 71/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4208 - accuracy: 0.7611 - val_loss: 0.6557 - val_accuracy: 0.6937\n",
            "Epoch 72/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4202 - accuracy: 0.7623 - val_loss: 0.5428 - val_accuracy: 0.7314\n",
            "Epoch 73/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4168 - accuracy: 0.7550 - val_loss: 0.6520 - val_accuracy: 0.7109\n",
            "Epoch 74/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4093 - accuracy: 0.7619 - val_loss: 0.6197 - val_accuracy: 0.6926\n",
            "Epoch 75/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4342 - accuracy: 0.7512 - val_loss: 0.6962 - val_accuracy: 0.7017\n",
            "Epoch 76/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4106 - accuracy: 0.7684 - val_loss: 0.7181 - val_accuracy: 0.6880\n",
            "Epoch 77/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4180 - accuracy: 0.7733 - val_loss: 0.5450 - val_accuracy: 0.7189\n",
            "Epoch 78/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4144 - accuracy: 0.7672 - val_loss: 0.6371 - val_accuracy: 0.7303\n",
            "Epoch 79/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4178 - accuracy: 0.7630 - val_loss: 0.6622 - val_accuracy: 0.7177\n",
            "Epoch 80/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3917 - accuracy: 0.7749 - val_loss: 0.6609 - val_accuracy: 0.7006\n",
            "Epoch 81/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4056 - accuracy: 0.7661 - val_loss: 0.8412 - val_accuracy: 0.6857\n",
            "Epoch 82/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3995 - accuracy: 0.7627 - val_loss: 0.6927 - val_accuracy: 0.6891\n",
            "Epoch 83/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.4156 - accuracy: 0.7669 - val_loss: 0.7980 - val_accuracy: 0.6937\n",
            "Epoch 84/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.4349 - accuracy: 0.7646 - val_loss: 0.7271 - val_accuracy: 0.7051\n",
            "Epoch 85/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3934 - accuracy: 0.7745 - val_loss: 0.7238 - val_accuracy: 0.7211\n",
            "Epoch 86/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3967 - accuracy: 0.7821 - val_loss: 0.5925 - val_accuracy: 0.7040\n",
            "Epoch 87/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3887 - accuracy: 0.7851 - val_loss: 0.6203 - val_accuracy: 0.7314\n",
            "Epoch 88/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3846 - accuracy: 0.7844 - val_loss: 0.8889 - val_accuracy: 0.6846\n",
            "Epoch 89/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3802 - accuracy: 0.7812\n",
            "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3787 - accuracy: 0.7825 - val_loss: 0.5979 - val_accuracy: 0.7189\n",
            "Epoch 90/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3576 - accuracy: 0.7996 - val_loss: 0.7235 - val_accuracy: 0.7166\n",
            "Epoch 91/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3711 - accuracy: 0.7878 - val_loss: 0.6028 - val_accuracy: 0.7120\n",
            "Epoch 92/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3615 - accuracy: 0.7939 - val_loss: 0.7467 - val_accuracy: 0.7269\n",
            "Epoch 93/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3630 - accuracy: 0.7966 - val_loss: 0.6125 - val_accuracy: 0.7314\n",
            "Epoch 94/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3623 - accuracy: 0.7920 - val_loss: 0.7833 - val_accuracy: 0.7223\n",
            "Epoch 95/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3666 - accuracy: 0.8065 - val_loss: 0.6333 - val_accuracy: 0.7269\n",
            "Epoch 96/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3503 - accuracy: 0.7985 - val_loss: 0.7259 - val_accuracy: 0.7223\n",
            "Epoch 97/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3466 - accuracy: 0.8030 - val_loss: 0.6648 - val_accuracy: 0.7223\n",
            "Epoch 98/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3517 - accuracy: 0.8053 - val_loss: 0.6751 - val_accuracy: 0.7223\n",
            "Epoch 99/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.3440 - accuracy: 0.7996 - val_loss: 0.7283 - val_accuracy: 0.7223\n",
            "Epoch 100/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3522 - accuracy: 0.7966 - val_loss: 0.6878 - val_accuracy: 0.7280\n",
            "Epoch 101/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3433 - accuracy: 0.8130 - val_loss: 0.7112 - val_accuracy: 0.7234\n",
            "Epoch 102/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3390 - accuracy: 0.8027 - val_loss: 0.6824 - val_accuracy: 0.7303\n",
            "Epoch 103/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3386 - accuracy: 0.8118 - val_loss: 0.6432 - val_accuracy: 0.7189\n",
            "Epoch 104/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3494 - accuracy: 0.8027 - val_loss: 0.7243 - val_accuracy: 0.7303\n",
            "Epoch 105/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3429 - accuracy: 0.7981 - val_loss: 0.7449 - val_accuracy: 0.7280\n",
            "Epoch 106/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3480 - accuracy: 0.8061 - val_loss: 0.6987 - val_accuracy: 0.7189\n",
            "Epoch 107/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3347 - accuracy: 0.8141 - val_loss: 0.7221 - val_accuracy: 0.7280\n",
            "Epoch 108/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3307 - accuracy: 0.8110 - val_loss: 0.6877 - val_accuracy: 0.7269\n",
            "Epoch 109/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3362 - accuracy: 0.8132INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 1s 131ms/step - loss: 0.3353 - accuracy: 0.8126 - val_loss: 0.6945 - val_accuracy: 0.7349\n",
            "Epoch 110/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3413 - accuracy: 0.8065 - val_loss: 0.7850 - val_accuracy: 0.7257\n",
            "Epoch 111/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3523 - accuracy: 0.8130 - val_loss: 0.6662 - val_accuracy: 0.7223\n",
            "Epoch 112/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3320 - accuracy: 0.8171 - val_loss: 0.7103 - val_accuracy: 0.7291\n",
            "Epoch 113/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3270 - accuracy: 0.8164 - val_loss: 0.7654 - val_accuracy: 0.7314\n",
            "Epoch 114/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3380 - accuracy: 0.8175 - val_loss: 0.7232 - val_accuracy: 0.7211\n",
            "Epoch 115/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3289 - accuracy: 0.8168 - val_loss: 0.7085 - val_accuracy: 0.7291\n",
            "Epoch 116/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3304 - accuracy: 0.8210 - val_loss: 0.8477 - val_accuracy: 0.7291\n",
            "Epoch 117/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3250 - accuracy: 0.8198 - val_loss: 0.8140 - val_accuracy: 0.7234\n",
            "Epoch 118/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3264 - accuracy: 0.8198 - val_loss: 0.7252 - val_accuracy: 0.7223\n",
            "Epoch 119/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.3288 - accuracy: 0.8225 - val_loss: 0.7707 - val_accuracy: 0.7234\n",
            "Epoch 120/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3314 - accuracy: 0.8137 - val_loss: 0.8120 - val_accuracy: 0.7211\n",
            "Epoch 121/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3196 - accuracy: 0.8251 - val_loss: 0.7211 - val_accuracy: 0.7303\n",
            "Epoch 122/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3203 - accuracy: 0.8240 - val_loss: 0.8090 - val_accuracy: 0.7211\n",
            "Epoch 123/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3144 - accuracy: 0.8297 - val_loss: 0.7369 - val_accuracy: 0.7291\n",
            "Epoch 124/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3235 - accuracy: 0.8069 - val_loss: 0.7333 - val_accuracy: 0.7349\n",
            "Epoch 125/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3203 - accuracy: 0.8187 - val_loss: 0.8003 - val_accuracy: 0.7291\n",
            "Epoch 126/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3143 - accuracy: 0.8229 - val_loss: 0.7316 - val_accuracy: 0.7109\n",
            "Epoch 127/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3131 - accuracy: 0.8196INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod/assets\n",
            "11/11 [==============================] - 2s 156ms/step - loss: 0.3153 - accuracy: 0.8202 - val_loss: 0.6729 - val_accuracy: 0.7360\n",
            "Epoch 128/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.3282 - accuracy: 0.8217 - val_loss: 0.7120 - val_accuracy: 0.7349\n",
            "Epoch 129/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3166 - accuracy: 0.8236 - val_loss: 0.8528 - val_accuracy: 0.7326\n",
            "Epoch 130/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.3128 - accuracy: 0.8251 - val_loss: 0.7763 - val_accuracy: 0.7109\n",
            "Epoch 131/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3161 - accuracy: 0.8168 - val_loss: 0.8171 - val_accuracy: 0.7291\n",
            "Epoch 132/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3111 - accuracy: 0.8255 - val_loss: 0.8538 - val_accuracy: 0.7177\n",
            "Epoch 133/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3123 - accuracy: 0.8282 - val_loss: 0.9733 - val_accuracy: 0.7166\n",
            "Epoch 134/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3196 - accuracy: 0.8244 - val_loss: 0.7534 - val_accuracy: 0.7314\n",
            "Epoch 135/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3071 - accuracy: 0.8339 - val_loss: 0.7699 - val_accuracy: 0.7303\n",
            "Epoch 136/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3083 - accuracy: 0.8297 - val_loss: 0.7908 - val_accuracy: 0.7280\n",
            "Epoch 137/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3060 - accuracy: 0.8286 - val_loss: 0.8671 - val_accuracy: 0.7211\n",
            "Epoch 138/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2994 - accuracy: 0.8259 - val_loss: 0.8829 - val_accuracy: 0.7166\n",
            "Epoch 139/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3141 - accuracy: 0.8248 - val_loss: 0.8064 - val_accuracy: 0.7257\n",
            "Epoch 140/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2981 - accuracy: 0.8370 - val_loss: 0.7941 - val_accuracy: 0.7326\n",
            "Epoch 141/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3020 - accuracy: 0.8411 - val_loss: 0.8503 - val_accuracy: 0.7257\n",
            "Epoch 142/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3018 - accuracy: 0.8362 - val_loss: 0.8914 - val_accuracy: 0.7234\n",
            "Epoch 143/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3064 - accuracy: 0.8274 - val_loss: 0.8722 - val_accuracy: 0.7303\n",
            "Epoch 144/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.3002 - accuracy: 0.8263 - val_loss: 0.8063 - val_accuracy: 0.7314\n",
            "Epoch 145/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2972 - accuracy: 0.8381 - val_loss: 0.7604 - val_accuracy: 0.7246\n",
            "Epoch 146/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3062 - accuracy: 0.8335 - val_loss: 0.7723 - val_accuracy: 0.7223\n",
            "Epoch 147/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.3046 - accuracy: 0.8340\n",
            "Epoch 00147: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3034 - accuracy: 0.8350 - val_loss: 0.7766 - val_accuracy: 0.7314\n",
            "Epoch 148/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.3005 - accuracy: 0.8335 - val_loss: 0.8645 - val_accuracy: 0.7280\n",
            "Epoch 149/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2934 - accuracy: 0.8305 - val_loss: 0.7850 - val_accuracy: 0.7257\n",
            "Epoch 150/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2860 - accuracy: 0.8350 - val_loss: 0.8294 - val_accuracy: 0.7314\n",
            "Epoch 151/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2852 - accuracy: 0.8392 - val_loss: 0.8518 - val_accuracy: 0.7246\n",
            "Epoch 152/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2934 - accuracy: 0.8324 - val_loss: 0.8241 - val_accuracy: 0.7291\n",
            "Epoch 153/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2807 - accuracy: 0.8476 - val_loss: 0.7871 - val_accuracy: 0.7326\n",
            "Epoch 154/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2880 - accuracy: 0.8362 - val_loss: 0.8199 - val_accuracy: 0.7349\n",
            "Epoch 155/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2937 - accuracy: 0.8370 - val_loss: 0.8071 - val_accuracy: 0.7291\n",
            "Epoch 156/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2811 - accuracy: 0.8396 - val_loss: 0.8501 - val_accuracy: 0.7303\n",
            "Epoch 157/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2927 - accuracy: 0.8408 - val_loss: 0.8362 - val_accuracy: 0.7326\n",
            "Epoch 158/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2860 - accuracy: 0.8366 - val_loss: 0.8363 - val_accuracy: 0.7337\n",
            "Epoch 159/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2837 - accuracy: 0.8377 - val_loss: 0.7920 - val_accuracy: 0.7314\n",
            "Epoch 160/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2858 - accuracy: 0.8392 - val_loss: 0.8475 - val_accuracy: 0.7360\n",
            "Epoch 161/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2975 - accuracy: 0.8392 - val_loss: 0.8291 - val_accuracy: 0.7303\n",
            "Epoch 162/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2906 - accuracy: 0.8408 - val_loss: 0.8300 - val_accuracy: 0.7337\n",
            "Epoch 163/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2862 - accuracy: 0.8370 - val_loss: 0.8740 - val_accuracy: 0.7337\n",
            "Epoch 164/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2842 - accuracy: 0.8370 - val_loss: 0.8155 - val_accuracy: 0.7349\n",
            "Epoch 165/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2901 - accuracy: 0.8385 - val_loss: 0.8067 - val_accuracy: 0.7291\n",
            "Epoch 166/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2907 - accuracy: 0.8396 - val_loss: 0.8547 - val_accuracy: 0.7349\n",
            "Epoch 167/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2780 - accuracy: 0.8448\n",
            "Epoch 00167: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2792 - accuracy: 0.8465 - val_loss: 0.8216 - val_accuracy: 0.7326\n",
            "Epoch 168/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2830 - accuracy: 0.8434 - val_loss: 0.8297 - val_accuracy: 0.7314\n",
            "Epoch 169/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2881 - accuracy: 0.8389 - val_loss: 0.8436 - val_accuracy: 0.7326\n",
            "Epoch 170/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2840 - accuracy: 0.8331 - val_loss: 0.8371 - val_accuracy: 0.7337\n",
            "Epoch 171/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2908 - accuracy: 0.8442 - val_loss: 0.8304 - val_accuracy: 0.7291\n",
            "Epoch 172/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2875 - accuracy: 0.8408 - val_loss: 0.8378 - val_accuracy: 0.7291\n",
            "Epoch 173/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2846 - accuracy: 0.8358 - val_loss: 0.8422 - val_accuracy: 0.7291\n",
            "Epoch 174/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2797 - accuracy: 0.8411 - val_loss: 0.8469 - val_accuracy: 0.7303\n",
            "Epoch 175/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2825 - accuracy: 0.8358 - val_loss: 0.8551 - val_accuracy: 0.7349\n",
            "Epoch 176/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2837 - accuracy: 0.8510 - val_loss: 0.8427 - val_accuracy: 0.7303\n",
            "Epoch 177/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2846 - accuracy: 0.8373 - val_loss: 0.8428 - val_accuracy: 0.7303\n",
            "Epoch 178/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2872 - accuracy: 0.8446 - val_loss: 0.8429 - val_accuracy: 0.7326\n",
            "Epoch 179/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2855 - accuracy: 0.8404 - val_loss: 0.8434 - val_accuracy: 0.7326\n",
            "Epoch 180/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2964 - accuracy: 0.8389 - val_loss: 0.8358 - val_accuracy: 0.7303\n",
            "Epoch 181/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2846 - accuracy: 0.8415 - val_loss: 0.8399 - val_accuracy: 0.7291\n",
            "Epoch 182/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2801 - accuracy: 0.8484 - val_loss: 0.8441 - val_accuracy: 0.7280\n",
            "Epoch 183/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2918 - accuracy: 0.8488 - val_loss: 0.8498 - val_accuracy: 0.7291\n",
            "Epoch 184/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2794 - accuracy: 0.8434 - val_loss: 0.8358 - val_accuracy: 0.7291\n",
            "Epoch 185/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2983 - accuracy: 0.8236 - val_loss: 0.8167 - val_accuracy: 0.7314\n",
            "Epoch 186/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2828 - accuracy: 0.8419 - val_loss: 0.8187 - val_accuracy: 0.7303\n",
            "Epoch 187/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2867 - accuracy: 0.8372\n",
            "Epoch 00187: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2869 - accuracy: 0.8366 - val_loss: 0.8298 - val_accuracy: 0.7303\n",
            "Epoch 188/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2827 - accuracy: 0.8430 - val_loss: 0.8333 - val_accuracy: 0.7326\n",
            "Epoch 189/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2840 - accuracy: 0.8404 - val_loss: 0.8359 - val_accuracy: 0.7314\n",
            "Epoch 190/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2811 - accuracy: 0.8438 - val_loss: 0.8382 - val_accuracy: 0.7303\n",
            "Epoch 191/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2880 - accuracy: 0.8461 - val_loss: 0.8394 - val_accuracy: 0.7314\n",
            "Epoch 192/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2836 - accuracy: 0.8396 - val_loss: 0.8395 - val_accuracy: 0.7314\n",
            "Epoch 193/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2848 - accuracy: 0.8442 - val_loss: 0.8370 - val_accuracy: 0.7314\n",
            "Epoch 194/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2876 - accuracy: 0.8457 - val_loss: 0.8378 - val_accuracy: 0.7314\n",
            "Epoch 195/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2799 - accuracy: 0.8419 - val_loss: 0.8407 - val_accuracy: 0.7314\n",
            "Epoch 196/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2861 - accuracy: 0.8427 - val_loss: 0.8420 - val_accuracy: 0.7303\n",
            "Epoch 197/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2805 - accuracy: 0.8457 - val_loss: 0.8439 - val_accuracy: 0.7314\n",
            "Epoch 198/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2754 - accuracy: 0.8461 - val_loss: 0.8460 - val_accuracy: 0.7326\n",
            "Epoch 199/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2873 - accuracy: 0.8488 - val_loss: 0.8456 - val_accuracy: 0.7326\n",
            "Epoch 200/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2856 - accuracy: 0.8533 - val_loss: 0.8457 - val_accuracy: 0.7326\n",
            "Epoch 201/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2910 - accuracy: 0.8389 - val_loss: 0.8431 - val_accuracy: 0.7303\n",
            "Epoch 202/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2827 - accuracy: 0.8427 - val_loss: 0.8434 - val_accuracy: 0.7303\n",
            "Epoch 203/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2763 - accuracy: 0.8488 - val_loss: 0.8459 - val_accuracy: 0.7326\n",
            "Epoch 204/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2981 - accuracy: 0.8385 - val_loss: 0.8436 - val_accuracy: 0.7314\n",
            "Epoch 205/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2782 - accuracy: 0.8453 - val_loss: 0.8420 - val_accuracy: 0.7314\n",
            "Epoch 206/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2817 - accuracy: 0.8556 - val_loss: 0.8422 - val_accuracy: 0.7314\n",
            "Epoch 207/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2812 - accuracy: 0.8444\n",
            "Epoch 00207: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2805 - accuracy: 0.8450 - val_loss: 0.8416 - val_accuracy: 0.7314\n",
            "Epoch 208/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2865 - accuracy: 0.8499 - val_loss: 0.8411 - val_accuracy: 0.7314\n",
            "Epoch 209/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2846 - accuracy: 0.8381 - val_loss: 0.8408 - val_accuracy: 0.7314\n",
            "Epoch 210/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2821 - accuracy: 0.8339 - val_loss: 0.8402 - val_accuracy: 0.7314\n",
            "Epoch 211/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2853 - accuracy: 0.8419 - val_loss: 0.8402 - val_accuracy: 0.7314\n",
            "Epoch 212/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2815 - accuracy: 0.8503 - val_loss: 0.8405 - val_accuracy: 0.7314\n",
            "Epoch 213/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2780 - accuracy: 0.8450 - val_loss: 0.8406 - val_accuracy: 0.7314\n",
            "Epoch 214/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2784 - accuracy: 0.8465 - val_loss: 0.8405 - val_accuracy: 0.7314\n",
            "Epoch 215/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2829 - accuracy: 0.8545 - val_loss: 0.8406 - val_accuracy: 0.7314\n",
            "Epoch 216/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2831 - accuracy: 0.8411 - val_loss: 0.8404 - val_accuracy: 0.7314\n",
            "Epoch 217/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2882 - accuracy: 0.8434 - val_loss: 0.8407 - val_accuracy: 0.7314\n",
            "Epoch 218/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2775 - accuracy: 0.8476 - val_loss: 0.8406 - val_accuracy: 0.7314\n",
            "Epoch 219/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2815 - accuracy: 0.8415 - val_loss: 0.8414 - val_accuracy: 0.7314\n",
            "Epoch 220/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2922 - accuracy: 0.8381 - val_loss: 0.8419 - val_accuracy: 0.7314\n",
            "Epoch 221/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2780 - accuracy: 0.8461 - val_loss: 0.8418 - val_accuracy: 0.7314\n",
            "Epoch 222/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2774 - accuracy: 0.8328 - val_loss: 0.8418 - val_accuracy: 0.7314\n",
            "Epoch 223/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2767 - accuracy: 0.8434 - val_loss: 0.8420 - val_accuracy: 0.7314\n",
            "Epoch 224/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2801 - accuracy: 0.8438 - val_loss: 0.8420 - val_accuracy: 0.7303\n",
            "Epoch 225/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2856 - accuracy: 0.8358 - val_loss: 0.8421 - val_accuracy: 0.7303\n",
            "Epoch 226/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2901 - accuracy: 0.8400 - val_loss: 0.8423 - val_accuracy: 0.7303\n",
            "Epoch 227/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2849 - accuracy: 0.8388\n",
            "Epoch 00227: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2851 - accuracy: 0.8389 - val_loss: 0.8427 - val_accuracy: 0.7303\n",
            "Epoch 228/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2862 - accuracy: 0.8309 - val_loss: 0.8428 - val_accuracy: 0.7303\n",
            "Epoch 229/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2789 - accuracy: 0.8389 - val_loss: 0.8428 - val_accuracy: 0.7303\n",
            "Epoch 230/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2806 - accuracy: 0.8476 - val_loss: 0.8430 - val_accuracy: 0.7303\n",
            "Epoch 231/250\n",
            "11/11 [==============================] - 0s 22ms/step - loss: 0.2798 - accuracy: 0.8404 - val_loss: 0.8430 - val_accuracy: 0.7303\n",
            "Epoch 232/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2896 - accuracy: 0.8408 - val_loss: 0.8430 - val_accuracy: 0.7303\n",
            "Epoch 233/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2817 - accuracy: 0.8350 - val_loss: 0.8430 - val_accuracy: 0.7303\n",
            "Epoch 234/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2855 - accuracy: 0.8404 - val_loss: 0.8430 - val_accuracy: 0.7303\n",
            "Epoch 235/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2845 - accuracy: 0.8366 - val_loss: 0.8430 - val_accuracy: 0.7303\n",
            "Epoch 236/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2877 - accuracy: 0.8495 - val_loss: 0.8430 - val_accuracy: 0.7303\n",
            "Epoch 237/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2871 - accuracy: 0.8461 - val_loss: 0.8428 - val_accuracy: 0.7303\n",
            "Epoch 238/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2922 - accuracy: 0.8389 - val_loss: 0.8427 - val_accuracy: 0.7303\n",
            "Epoch 239/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2871 - accuracy: 0.8381 - val_loss: 0.8426 - val_accuracy: 0.7303\n",
            "Epoch 240/250\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.2861 - accuracy: 0.8442 - val_loss: 0.8426 - val_accuracy: 0.7303\n",
            "Epoch 241/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2757 - accuracy: 0.8408 - val_loss: 0.8426 - val_accuracy: 0.7303\n",
            "Epoch 242/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2768 - accuracy: 0.8408 - val_loss: 0.8427 - val_accuracy: 0.7303\n",
            "Epoch 243/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2700 - accuracy: 0.8480 - val_loss: 0.8428 - val_accuracy: 0.7303\n",
            "Epoch 244/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2948 - accuracy: 0.8408 - val_loss: 0.8429 - val_accuracy: 0.7303\n",
            "Epoch 245/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2914 - accuracy: 0.8373 - val_loss: 0.8429 - val_accuracy: 0.7303\n",
            "Epoch 246/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2955 - accuracy: 0.8362 - val_loss: 0.8429 - val_accuracy: 0.7303\n",
            "Epoch 247/250\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 0.2823 - accuracy: 0.8404\n",
            "Epoch 00247: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2817 - accuracy: 0.8392 - val_loss: 0.8428 - val_accuracy: 0.7303\n",
            "Epoch 248/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2779 - accuracy: 0.8408 - val_loss: 0.8429 - val_accuracy: 0.7303\n",
            "Epoch 249/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2901 - accuracy: 0.8381 - val_loss: 0.8429 - val_accuracy: 0.7303\n",
            "Epoch 250/250\n",
            "11/11 [==============================] - 0s 23ms/step - loss: 0.2833 - accuracy: 0.8457 - val_loss: 0.8428 - val_accuracy: 0.7303\n",
            "Time: 100.77059292793274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYlMXO8wiOai",
        "outputId": "1a2a4806-faa6-4a5f-9c10-5fa0b793489a"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 2.5K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "\n",
        "# Label simulations from the test set.\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y.extend([2 for i in range(len(t3))])\n",
        "y.extend([3 for i in range(len(t4))])\n",
        "y.extend([4 for i in range(len(t5))])\n",
        "y.extend([5 for i in range(len(t6))])\n",
        "y.extend([6 for i in range(len(t7))])\n",
        "y = np.array(y)\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_2.5KSims.acc.mod')\n",
        "pred = model.predict(t)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 789    0   53    0    0  157    1]\n",
            " [   0  834    0   17   23    0  126]\n",
            " [   0    0 1000    0    0    0    0]\n",
            " [   0    1  118  825   56    0    0]\n",
            " [   0    1    0    1  997    0    1]\n",
            " [  18    0   25    0    0  957    0]\n",
            " [   0   90    1   14    5    7  883]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfN2JKeeQpwo",
        "outputId": "78b31354-5558-408b-c5fe-9aa7443fcc7b"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 1K simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_1KSims.acc.mod')\n",
        "pred = model.predict(t)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 656    0   67    1    0  276    0]\n",
            " [   0  780    0   15   24    0  181]\n",
            " [   0    0 1000    0    0    0    0]\n",
            " [   0    1  129  823   47    0    0]\n",
            " [   0    3    0   10  987    0    0]\n",
            " [   4    0   33    0    0  963    0]\n",
            " [   1  100    2   13    3    7  874]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYKdCeqPT5Q9",
        "outputId": "978a04a2-2295-482a-a9ef-872372d7044f"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the CNN trained with 500 simulations per model, using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_0.5KSims.acc.mod')\n",
        "pred = model.predict(t)\n",
        "\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[360   0  85   0   0 555   0]\n",
            " [  7 577   0  24  17   0 375]\n",
            " [  0   0 999   1   0   0   0]\n",
            " [  0   1 157 826  16   0   0]\n",
            " [  0  13   0  68 919   0   0]\n",
            " [280   0  39   0   0 681   0]\n",
            " [ 34 182   6  13   2   0 763]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}