library("poppr")
library("vcfR")
library("hierfstat")
setwd("/Users/manolo/Desktop/Amova_porDart/Input_Alternativo_Erythrinus")
install.packages("poppr")
gl <- gl.read.dart(filename = "ErythrinusPCA.csv")
Mydata <- read.table("Erythrinus_genlight.csv", header = TRUE, check.names = FALSE, sep = "," ,quote = "\"'")
dim(Mydata)
ind <- as.character(Mydata$ind)
ind
population <- as.character(Mydata$pop)
population
dim(Mydata)
locus   <- Mydata[, 3:19054]
locus
a <- gl2gi(gl, probar = FALSE, verbose = NULL)
a
gl
## Pra gerar os FST
basic.stats(Mydata1)
Mydata1 <- df2genind(locus, ploidy = 2, ind.names = ind, pop = population, sep = ",")
Mydata1
a
gl
a
gl@pop
Mydata2 <- genind2hierfstat(Mydata1)
## Pra gerar os FST
basic.stats(Mydata1)
wc(Mydata1) # Weir and Cockerham's estimate
population
View(Mydata2)
population
data.frame(population)
loci <- Mydata2[, -1] # Remove the population column
loci
varcomp.glob(levels = data.frame(population), loci, diploid = TRUE)
gl <- gl.read.dart(filename = "ErythrinusPCA.csv", ind.metafile = "Erythrinus_metadata.csv",mono.rm=T,recalc=T)
gl
gl@pop
#Confirm conversion was done corectly (1 - hetero; 2 - homo alternative).
t(as.matrix(gl))[c(1,5,17), 1:20]
as.matrix(gl)
#Confirm conversion was done corectly (1 - hetero; 2 - homo alternative).
t(as.matrix(gl))[c(1,5,17), 1:18]
glPlot(gl)
?glPlot
#Allelic richness; Shannon entropy and diversity; and Heterozygosity
#according to:
#Sherwin, W. B., Chao, A., Jost, L., & Smouse, P. E. (2017).
#Information theory broadens the spectrum of molecular ecology and evolution.
#Trends in ecology & evolution, 32(12), 948-963.
gl.report.diversity(gl)
report.pa(gl)
library("dartR")
report.pa(gl)
library("hierfstat")
require(SeqVarTools) # when using vcf as input file
library(radiator)
library(dartR)
library(vcfR)
require(SeqVarTools) # when using vcf as input file
gl.report.pa(gl)
#Private alleles. To use this you need to prepare one metafile for each population,
#collapsing the reamining population (e.g. naming them as "other")
pa=0
for (i in levels(gl@pop)) {
gl <- gl.read.dart(filename = "ErythrinusPCA.csv",ind.metafile = paste("Erythrinus_metadata_",i,".csv",sep=""),recalc=T)
pa=rbind(pa,gl.report.pa(gl))
}
pa
#Reload the original input
gl <- gl.read.dart(filename = "ErythrinusPCA.csv", ind.metafile = "Erythrinus_metadata.csv",mono.rm=T,recalc=T)
#
gl.report.heterozygosity(gl)
?basic.stats
## Pra gerar os FST
stats = basic.stats(Mydata1)
gi <- gl2gi(gl, probar = FALSE, verbose = NULL)
gi
fstat_input <- genind2hierfstat(gi)
## Pra gerar os FST
stats = basic.stats(Mydata1)
?basic.stats
stats$Ho
stats$Hs
stats$Fis
stats$overvall
mean(stats$Ho)
mean(stats$Hs)
mean(stats$Ho)
stats$Ho
mean(stats$Ho$EAPR)
dim(stats$Ho)
stats$Ho[1]
stats$Ho[:1]
stats$Ho[,:1]
stats$Ho[,1]
stats$Ho[,2]
?mean
mean(stats$Hs, na.rm = T)
stats$Ho[,]
stats$Ho[EAPR]
stats$Ho[,1]
stats$Ho[,3]
stats$Ho
summary(stats$Ho)
colMeans(stats$Ho)
colMeans(stats$Ho, na.rm = T)
colMeans(stats$Fis)
colMeans(stats$Fis,  na.rm = T)
allelic.richness(gl)
allelic.richness(fstat_input)
boxplot(allelic.richness(fstat_input)$Ar)
boxplot(stats$Ho)
boxplot(stats$Hs)
boxplot(stats$Fis)
colMeans(stats$Fis,  na.rm = T)
colMeans(stats$Hs, na.rm = T)
colMeans(stats$Ho, na.rm = T)
gi
fstat_input
stats
gl
?gl2gi
gi
colMeans(allelic.richness(fstat_input)$Ar))
colMeans(allelic.richness(fstat_input)$Ar)
colMeans(allelic.richness(fstat_input)$Ar,  na.rm = T)
#Genetic Diversity, most "important" vaules are:
#m_0Da (Allelic richness), m_1Da (Shannon diversity) and m_2Ha (Heterozygosity).
#Might use m_1Ha (Shannon entropy)
#Statistics calculated according to:
#Sherwin, W. B., Chao, A., Jost, L., & Smouse, P. E. (2017).
#Information theory broadens the spectrum of molecular ecology and evolution.
#Trends in ecology & evolution, 32(12), 948-963.
gl.report.diversity(gl)
tail(stats$Ho)
summary(fstat_input)
## Pra gerar os FST
stats = basic.stats(Mydata1)
stats
gl.amova(gl, permutations = 10)
Amova = gl.amova(gl, permutations = 10)
Amova
#Load DArT data with metadata (pop information) and recalculating locus information
#ATENTION: this commands changes 1s and 2s, so the input should have
#1 as alternative homozygotes and 2 as heterozygotes.
gl <- gl.read.dart(filename = "ErythrinusPCA.csv", ind.metafile = "Erythrinus_metadata.csv",mono.rm=T,recalc=T)
gl
#Confirm conversion was done corectly (1 - hetero; 2 - homo alternative).
t(as.matrix(gl))[c(1,5,17), 1:18]
#Visualize the SNP table
glPlot(gl)
#Genetic Diversity, most "important" vaules are:
#m_0Da (Allelic richness), m_1Da (Shannon diversity) and m_2Ha (Heterozygosity).
#Might use m_1Ha (Shannon entropy)
#Statistics calculated according to:
#Sherwin, W. B., Chao, A., Jost, L., & Smouse, P. E. (2017).
#Information theory broadens the spectrum of molecular ecology and evolution.
#Trends in ecology & evolution, 32(12), 948-963.
gl.report.diversity(gl)
#Estimate Ho and He
gl.report.heterozygosity(gl)
#Private alleles. To use this you need to prepare one metafile for each population,
#collapsing the reamining population (e.g. naming them as "other")
pa=0
for (i in levels(gl@pop)) {
gl <- gl.read.dart(filename = "ErythrinusPCA.csv",ind.metafile = paste("Erythrinus_metadata_",i,".csv",sep=""),recalc=T)
pa=rbind(pa,gl.report.pa(gl))
}
pa
#Reload the original input
gl <- gl.read.dart(filename = "ErythrinusPCA.csv", ind.metafile = "Erythrinus_metadata.csv",mono.rm=T,recalc=T)
#Convert to genind - I think this is not being done correctly,
#hetero and alternative homozygotes are being confounded.
#I believe this because Ho is higher than He.
gi <- gl2gi(gl, probar = FALSE, verbose = NULL)
fstat_input <- genind2hierfstat(gi)
#Estimate Fis and allelic richness with for each population
stats = basic.stats(fstat_input)
colMeans(stats$Fis,  na.rm = F)
colMeans(stats$Fis,  na.rm = T)
colMeans(stats$Ho,  na.rm = T)
colMeans(stats$Hs,  na.rm = T)
colMeans(allelic.richness(fstat_input)$Ar,  na.rm = T)
#Also get overall stats
stats$overvall
stats
#Also get overall stats
stats$overvall
Amova = gl.amova(gl, permutations = 10)
Amova
loci <- Mydata2[, -1] # Remove the population column
varcomp.glob(levels = data.frame(population), loci, diploid = TRUE)
population
amova.result <- poppr.amova(gl, gl@pop)
library("poppr")
amova.result <- poppr.amova(gl, gl@pop)
gl@pop
amova.result <- poppr.amova(gl, populations)
populations
amova.result <- poppr.amova(gl, population)
gl
strata(gl)=gl@pop
data.frame(gl@pop)
strata(gl)=data.frame(gl@pop)
gl
amova.result <- poppr.amova(gl)
amova.result <- poppr.amova(gl,gl.pop)
gl@strata
amova.result <- poppr.amova(gl,gl@strata)
amova.result <- poppr.amova(gl,~gl.pop)
?gl.filter.callrate
filt.gl=gl.filter.callrate(gl,threshold = 1.0)
filt.gl
amova.result <- poppr.amova(filt.gl,~gl.pop)
amova.result
amova.pegas <- poppr.amova(filt.gl,~gl.pop, method = "pegas")
amova.pegas
amova.pegas$varcomp/sum(amova.pegas$varcomp)
amova.test <- randtest(amova.result)
amova.test
library(abc)
setwd("/Volumes/HD2/manolo/OneDrive/Trabalho/UFSCar/PosDoc/SpainSanmartin_Collaboration/Steppe/Data_steppe_species/Results_CNN_forABC")
parameters<-read.table("Esegueriana/parameters15.txt")
colnames(parameters)=c("Theta","T1","T2","T3","Ne","NeZ","NeZLGM","NeZPl","m12_LGM","m21_LGM","m12_Pl","m21_Pl")
parameters$NeZ=parameters$NeZ*parameters$Ne
parameters$NeZLGM=parameters$NeZLGM*parameters$Ne
parameters$NeZPl=parameters$NeZPl*parameters$Ne
parameters$m12_LGM=parameters$m12_LGM*100000/(2*parameters$Ne)
parameters$m21_LGM=parameters$m21_LGM*100000/(2*parameters$Ne)
parameters$m12_Pl=parameters$m12_Pl*100000/(2*parameters$Ne)
parameters$m21_Pl=parameters$m21_Pl*100000/(2*parameters$Ne)
sust<-read.table("Esegueriana/testSet_ParameterPredictions.txt")
emp<-read.table("Esegueriana/Emp_ParametersPredictions.txt")
emp<-apply(emp, 2, FUN = median)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
parameters<-read.table("Scapillata/parameters13.txt")
colnames(parameters)=c("Theta","T1","T2","T3","Ne","NeZ","NeExZLGM","NeZLGM","NeExZPl","NeZPl","m12_LGM","m21_LGM","m12_Pl","m21_Pl")
parameters$NeZ=parameters$NeZ*parameters$Ne
parameters$NeExZLGM=parameters$NeExZLGM*parameters$Ne
parameters$NeZLGM=parameters$NeZLGM*parameters$Ne
parameters$NeExZPl=parameters$NeExZPl*parameters$Ne
parameters$NeZPl=parameters$NeZPl*parameters$Ne
parameters$m12_LGM=parameters$m12_LGM*100000/(2*parameters$Ne)
parameters$m21_LGM=parameters$m21_LGM*100000/(2*parameters$Ne)
parameters$m12_Pl=parameters$m12_Pl*100000/(2*parameters$Ne)
parameters$m21_Pl=parameters$m21_Pl*100000/(2*parameters$Ne)
sust<-read.table("Scapillata/testSet_ParameterPredictions.txt")
emp<-read.table("Scapillata/Emp_ParametersPredictions.txt")
emp<-apply(emp, 2, FUN = median)
NN.parest.1 <- abc(emp, parameters, sust, tol=.1, method = "neuralnet")
summary(NN.parest.1)
parameters<-read.table("Esegueriana/parameters15.txt")
colnames(parameters)=c("Theta","T1","T2","T3","Ne","NeZ","NeZLGM","NeZPl","m12_LGM","m21_LGM","m12_Pl","m21_Pl")
parameters$NeZ=parameters$NeZ*parameters$Ne
parameters$NeZLGM=parameters$NeZLGM*parameters$Ne
parameters$NeZPl=parameters$NeZPl*parameters$Ne
parameters$m12_LGM=parameters$m12_LGM*100000/(2*parameters$Ne)
parameters$m21_LGM=parameters$m21_LGM*100000/(2*parameters$Ne)
parameters$m12_Pl=parameters$m12_Pl*100000/(2*parameters$Ne)
parameters$m21_Pl=parameters$m21_Pl*100000/(2*parameters$Ne)
sust<-read.table("Esegueriana/testSet_ParameterPredictions.txt")
emp<-read.table("Esegueriana/Emp_ParametersPredictions.txt")
emp<-apply(emp, 2, FUN = median)
NN.parest.1 <- abc(emp, parameters, sust, tol = .1,method = "neuralnet")
summary(NN.parest.1)
library(abc)
setwd("/Volumes/HD2/manolo/OneDrive/LaGEVol/Artigos_DoutoradoBelManolo/ArtigoDelimitacao/2021/ModelTest/ABC")
sust<-read.table("SuSt.txt")
numsim=70000
numloc=14
sust <- data.frame(s1=tapply(sust[,1], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s3=tapply(sust[,3], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s4=tapply(sust[,4], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s5=tapply(sust[,5], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s6=tapply(sust[,6], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s7=tapply(sust[,7], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s8=tapply(sust[,8], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s9=tapply(sust[,9], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s10=tapply(sust[,10], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s11=tapply(sust[,11], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s12=tapply(sust[,12], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s13=tapply(sust[,13], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s14=tapply(sust[,14], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s15=tapply(sust[,15], factor(rep(1:numsim, each=numloc)), mean,na.rm=T))
models<-scan("models.txt")
emp<-read.table("Emp.txt")
numsim=1
numloc=14
emp <- data.frame(s1=tapply(emp[,1], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s3=tapply(emp[,3], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s4=tapply(emp[,4], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s5=tapply(emp[,5], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s6=tapply(emp[,6], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s7=tapply(emp[,7], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s8=tapply(emp[,8], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s9=tapply(emp[,9], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s10=tapply(emp[,10], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s11=tapply(emp[,11], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s12=tapply(emp[,12], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s13=tapply(emp[,13], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s14=tapply(emp[,14], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s15=tapply(emp[,15], factor(rep(1:numsim, each=numloc)), mean,na.rm=T))
write.table(sust,file="SuSt_AVG.txt",row.names = F,col.names = F)
write.table(emp,file="Emp_AVG.txt",row.names = F,col.names = F)
pcasust <- prcomp(sust, scale = TRUE)
pcaemp<-predict(pcasust, emp, scale=TRUE)
summary(pcasust)
pcasust<-pcasust$x[,1:7]
pcaemp<-pcaemp[1:7]
start_time <- Sys.time()
PCANN.2<-postpr(pcaemp, models, pcasust, tol = 0.2, method = "neuralnet")
end_time <- Sys.time()
PCANN.2_time = end_time - start_time
PCANN.2_time
summary(PCANN.2)
##load required libraries
library(abc)
##load models for each simulation
models<-scan("models_melano_simulans.txt")
##load simulated summary statistics
sust<-read.table("SuSt_melano_simulans.txt")
##change working directory if necessary
setwd("/Volumes/HD2/manolo/OneDrive/LaGEVol/Artigos_DoutoradoBelManolo/ArtigoDelimitacao/2021/GitHub/Drosophila/ABC")
##load models for each simulation
models<-scan("models_melano_simulans.txt")
##load simulated summary statistics
sust<-read.table("SuSt_melano_simulans.txt")
##inform total number of simulations
numsim=20000
##inform total number of loci
numloc=3
##average loci summary statistic values
sust <- data.frame(s1=tapply(sust[,1], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s3=tapply(sust[,3], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s4=tapply(sust[,4], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s5=tapply(sust[,5], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s6=tapply(sust[,6], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s7=tapply(sust[,7], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s8=tapply(sust[,8], factor(rep(1:numsim, each=numloc)), mean,na.rm=T))
##load empirical data
emp<-read.table("Emp_melano_simulans.txt")
##set number os datasets to one
numsim=1
##average loci summary statistic values
emp <- data.frame(s1=tapply(emp[,1], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s3=tapply(emp[,3], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s4=tapply(emp[,4], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s5=tapply(emp[,5], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s6=tapply(emp[,6], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s7=tapply(emp[,7], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s8=tapply(emp[,8], factor(rep(1:numsim, each=numloc)), mean,na.rm=T))
##Perform a PCA on the simulated datasets
pcasust <- prcomp(sust, scale = TRUE)
##use the calculated eigenvalues to predict PCA values on the empirical dataset
pcaemp<-predict(pcasust, emp, scale=TRUE)
##visualize the summary of the PCA on the simulated dataset
summary(pcasust)
##use the first four axes, as they contained at least 99% of the variance
pcasust<-pcasust$x[,1:4]
##use the same axes for the empirical data
pcaemp<-pcaemp[1:4]
##run cross-validation
pca.cv.modsel10K <- cv4postpr(models, pcasust, nval=100, tol=.2, method="neuralnet")
##visualize the results of the cross validation
summary(pca.cv.modsel10K)
##run the rejection step of ABC with the empirical data, estimating the running time
start_time <- Sys.time()
PCANN.2<-postpr(pcaemp, models, pcasust, tol = 0.2, method = "neuralnet")
end_time <- Sys.time()
PCANN.2_time = end_time - start_time
##visualize the results of the rejection step
summary(PCANN.2)
##visualize running time
PCANN.2_time
##load models for each simulation
models<-scan("models_melano_sechellia.txt")
##load simulated summary statistics
sust<-read.table("SuSt_melano_sechellia.txt")
##inform total number of simulations
numsim=20000
##inform total number of loci
numloc=3
##average loci summary statistic values
sust <- data.frame(s1=tapply(sust[,1], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s3=tapply(sust[,3], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s4=tapply(sust[,4], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s5=tapply(sust[,5], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s6=tapply(sust[,6], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s7=tapply(sust[,7], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s8=tapply(sust[,8], factor(rep(1:numsim, each=numloc)), mean,na.rm=T))
##load empirical data
emp<-read.table("Emp_melano_sechellia.txt")
##set number os datasets to one
numsim=1
##average loci summary statistic values
emp <- data.frame(s1=tapply(emp[,1], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s3=tapply(emp[,3], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s4=tapply(emp[,4], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s5=tapply(emp[,5], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s6=tapply(emp[,6], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s7=tapply(emp[,7], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s8=tapply(emp[,8], factor(rep(1:numsim, each=numloc)), mean,na.rm=T))
##Perform a PCA on the simulated datasets
pcasust <- prcomp(sust, scale = TRUE)
##use the calculated eigenvalues to predict PCA values on the empirical dataset
pcaemp<-predict(pcasust, emp, scale=TRUE)
##visualize the summary of the PCA on the simulated dataset
summary(pcasust)
##use the first five axes, as they contained at least 99% of the variance
pcasust<-pcasust$x[,1:5]
##use the same axes for the empirical data
pcaemp<-pcaemp[1:5]
##visualize the results of the cross validation
summary(pca.cv.modsel10K)
##run the rejection step of ABC with the empirical data, estimating the running time
start_time <- Sys.time()
PCANN.2<-postpr(pcaemp, models, pcasust, tol = 0.2, method = "neuralnet")
end_time <- Sys.time()
PCANN.2_time = end_time - start_time
##visualize the results of the rejection step
summary(PCANN.2)
##visualize running time
PCANN.2_time
##run cross-validation
pca.cv.modsel10K <- cv4postpr(models, pcasust, nval=100, tol=.2, method="neuralnet")
##visualize the results of the cross validation
summary(pca.cv.modsel10K)
##change working directory if necessary
setwd("/Volumes/HD2/manolo/OneDrive/LaGEVol/Artigos_DoutoradoBelManolo/ArtigoDelimitacao/2021/GitHub/Pilosocereus/ABC")
##load models for each simulation
models<-scan("models.txt")
##load simulated summary statistics
sust<-read.table("SuSt.txt")
##inform total number of simulations
numsim=70000
##inform total number of loci
numloc=14
##average loci summary statistic values
sust <- data.frame(s1=tapply(sust[,1], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s3=tapply(sust[,3], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s4=tapply(sust[,4], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s5=tapply(sust[,5], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s6=tapply(sust[,6], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s7=tapply(sust[,7], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s8=tapply(sust[,8], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s9=tapply(sust[,9], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s10=tapply(sust[,10], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s11=tapply(sust[,11], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s12=tapply(sust[,12], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s13=tapply(sust[,13], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s14=tapply(sust[,14], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s15=tapply(sust[,15], factor(rep(1:numsim, each=numloc)), mean,na.rm=T))
##load empirical data
emp<-read.table("Emp.txt")
##set number os datasets to one
numsim=1
##average loci summary statistic values
emp <- data.frame(s1=tapply(emp[,1], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s3=tapply(emp[,3], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s4=tapply(emp[,4], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s5=tapply(emp[,5], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s6=tapply(emp[,6], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s7=tapply(emp[,7], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s8=tapply(emp[,8], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s9=tapply(emp[,9], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s10=tapply(emp[,10], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s11=tapply(emp[,11], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s12=tapply(emp[,12], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s13=tapply(emp[,13], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s14=tapply(emp[,14], factor(rep(1:numsim, each=numloc)), mean,na.rm=T),
s15=tapply(emp[,15], factor(rep(1:numsim, each=numloc)), mean,na.rm=T))
##Perform a PCA on the simulated datasets
pcasust <- prcomp(sust, scale = TRUE)
##use the calculated eigenvalues to predict PCA values on the empirical dataset
pcaemp<-predict(pcasust, emp, scale=TRUE)
##use the first seven axes, as they contained at least 99% of the variance
pcasust<-pcasust$x[,1:7]
##use the same axes for the empirical data
pcaemp<-pcaemp[1:7]
##run the rejection step of ABC with the empirical data, estimating the running time
start_time <- Sys.time()
PCANN.2<-postpr(pcaemp, models, pcasust, tol = 0.2, method = "neuralnet")
end_time <- Sys.time()
PCANN.2_time = end_time - start_time
##visualize the results of the rejection step
summary(PCANN.2)
##visualize running time
PCANN.05_time
