{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_CNN_Drosophila.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAW1uBKHCZQK"
      },
      "source": [
        "## **Notebook containing scripts and outputs of the training, cross-validation and empirical data prediction for the *Drosophila* dataset**\n",
        "From the manuscript Perez et al. \"Species Delimitation Meets Deep Learning: Insights from a Highly Fragmented Cactus System\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffjZgEDIRlld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcb3ca1-eec6-4781-9493-c3189937c28d"
      },
      "source": [
        "#mount google drive to load files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgc_VfbydhlW"
      },
      "source": [
        "# Import all required modules.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Activation, Dense, Dropout, Flatten, concatenate\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from random import shuffle, choice\n",
        "\n",
        "# Define parameters for the CNN run.\n",
        "batch_size = 250\n",
        "epochs = 250\n",
        "num_classes = 2\n",
        "\n",
        "# Define the CNN architecture.\n",
        "def create_cnn(xtest, regularizer=None):\n",
        "\tinputShape = (xtest.shape[1], xtest.shape[2])\n",
        "\tinputs = Input(shape=inputShape)\n",
        "\tx = inputs\n",
        "\tx = Conv1D(250, kernel_size=2, activation='relu',input_shape=(xtest.shape[1], xtest.shape[2]))(x)\n",
        "\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n",
        "\tx = AveragePooling1D(pool_size=2)(x)\n",
        "\tx = Dropout(0.75)(x)\n",
        "\tx = Conv1D(125, kernel_size=2, activation='relu')(x)\n",
        "\tx = AveragePooling1D(pool_size=2)(x)\n",
        "\tx = Dropout(0.75)(x)\n",
        "\tx = Flatten()(x)\n",
        "\tx = Dense(125, activation='relu')(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "\tx = Dense(125, activation='relu')(x)\n",
        "\tx = Dropout(0.5)(x)\n",
        "  # The final fully-connected layer head will have a softmax dense layer\n",
        "\tx = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\t# Construct the CNN\n",
        "\tmodel = Model(inputs, x)\n",
        "\t# Return the CNN\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQNbGK-WC4QE"
      },
      "source": [
        "# **Train a network for each species pair with 10,000 simulations from each model**\n",
        "Here we will use the full simulated dataset to train the network, by splitting the data with 75% of simulations for training and 25% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJgkHTL9Tddn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7e3814-f8b1-43ce-9f8a-8ccbd000025b"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train a network using 10K simulations per model for the D.melanogaster-D.sechellia pair.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing simulations.\n",
        "u1 = np.load(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Drosophila/melano_sechellia/simModel1.npz\")\n",
        "u2 = np.load(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Drosophila/melano_sechellia/simModel2.npz\")\n",
        "u1 = u1[\"simModel1\"]\n",
        "u2 = u2[\"simModel2\"]\n",
        "x=np.concatenate((u1,u2),axis=0)\n",
        "\n",
        "# Label each simulated array.\n",
        "y=[0 for i in range(len(u1))]\n",
        "y.extend([1 for i in range(len(u2))])\n",
        "y = np.array(y)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "x=x.astype(np.uint8)\n",
        "\n",
        "# Print label and simulations length, these should be the same.\n",
        "print (len(x), len(y))\n",
        "\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "# Separate train (75%) and validate (25%) sets.\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network, using the architecture defined above.\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "# Compile the CNN.\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000 20000\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 185, 5)]          0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 184, 250)          2750      \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 183, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d (AveragePo (None, 91, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 91, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 90, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_1 (Average (None, 45, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 45, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5625)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 125)               703250    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 252       \n",
            "=================================================================\n",
            "Total params: 816,002\n",
            "Trainable params: 816,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.7017 - accuracy: 0.5360WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0079s vs `on_train_batch_end` time: 0.0137s). Check your callbacks.\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.6329 - accuracy: 0.6247WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_test_batch_end` time: 0.0050s). Check your callbacks.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 3s 48ms/step - loss: 0.6279 - accuracy: 0.6317 - val_loss: 0.4931 - val_accuracy: 0.7830\n",
            "Epoch 2/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.7905INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 39ms/step - loss: 0.4753 - accuracy: 0.7905 - val_loss: 0.4446 - val_accuracy: 0.8066\n",
            "Epoch 3/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.4414 - accuracy: 0.8083 - val_loss: 0.4298 - val_accuracy: 0.8030\n",
            "Epoch 4/250\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.4355 - accuracy: 0.8107INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 39ms/step - loss: 0.4341 - accuracy: 0.8112 - val_loss: 0.4150 - val_accuracy: 0.8142\n",
            "Epoch 5/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.4186 - accuracy: 0.8201 - val_loss: 0.4206 - val_accuracy: 0.8124\n",
            "Epoch 6/250\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.4158 - accuracy: 0.8209INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 37ms/step - loss: 0.4157 - accuracy: 0.8209 - val_loss: 0.4025 - val_accuracy: 0.8216\n",
            "Epoch 7/250\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.3993 - accuracy: 0.8301INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.3997 - accuracy: 0.8299 - val_loss: 0.3966 - val_accuracy: 0.8276\n",
            "Epoch 8/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3958 - accuracy: 0.8323 - val_loss: 0.3979 - val_accuracy: 0.8248\n",
            "Epoch 9/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3968 - accuracy: 0.8313 - val_loss: 0.4284 - val_accuracy: 0.8088\n",
            "Epoch 10/250\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.3967 - accuracy: 0.8310INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 0.3946 - accuracy: 0.8323 - val_loss: 0.3886 - val_accuracy: 0.8296\n",
            "Epoch 11/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3819 - accuracy: 0.8390 - val_loss: 0.3978 - val_accuracy: 0.8264\n",
            "Epoch 12/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3829 - accuracy: 0.8389 - val_loss: 0.3915 - val_accuracy: 0.8278\n",
            "Epoch 13/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3799 - accuracy: 0.8397 - val_loss: 0.3940 - val_accuracy: 0.8280\n",
            "Epoch 14/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3779 - accuracy: 0.8409 - val_loss: 0.4128 - val_accuracy: 0.8140\n",
            "Epoch 15/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8383INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 0.3826 - accuracy: 0.8383 - val_loss: 0.3807 - val_accuracy: 0.8388\n",
            "Epoch 16/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3727 - accuracy: 0.8432 - val_loss: 0.4182 - val_accuracy: 0.8202\n",
            "Epoch 17/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3762 - accuracy: 0.8420 - val_loss: 0.4112 - val_accuracy: 0.8192\n",
            "Epoch 18/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3724 - accuracy: 0.8435 - val_loss: 0.3858 - val_accuracy: 0.8336\n",
            "Epoch 19/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3695 - accuracy: 0.8449 - val_loss: 0.4029 - val_accuracy: 0.8310\n",
            "Epoch 20/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3734 - accuracy: 0.8417 - val_loss: 0.3819 - val_accuracy: 0.8358\n",
            "Epoch 21/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3681 - accuracy: 0.8444 - val_loss: 0.3982 - val_accuracy: 0.8286\n",
            "Epoch 22/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3701 - accuracy: 0.8437 - val_loss: 0.3879 - val_accuracy: 0.8304\n",
            "Epoch 23/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3631 - accuracy: 0.8459 - val_loss: 0.3788 - val_accuracy: 0.8356\n",
            "Epoch 24/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3665 - accuracy: 0.8455 - val_loss: 0.4051 - val_accuracy: 0.8268\n",
            "Epoch 25/250\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.3642 - accuracy: 0.8450INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.3638 - accuracy: 0.8450 - val_loss: 0.3771 - val_accuracy: 0.8390\n",
            "Epoch 26/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3595 - accuracy: 0.8495 - val_loss: 0.3985 - val_accuracy: 0.8276\n",
            "Epoch 27/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3583 - accuracy: 0.8515 - val_loss: 0.3874 - val_accuracy: 0.8352\n",
            "Epoch 28/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3579 - accuracy: 0.8475 - val_loss: 0.3805 - val_accuracy: 0.8382\n",
            "Epoch 29/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3566 - accuracy: 0.8517 - val_loss: 0.3902 - val_accuracy: 0.8314\n",
            "Epoch 30/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3592 - accuracy: 0.8489 - val_loss: 0.3853 - val_accuracy: 0.8334\n",
            "Epoch 31/250\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.3586 - accuracy: 0.8478INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 0.3595 - accuracy: 0.8477 - val_loss: 0.3688 - val_accuracy: 0.8424\n",
            "Epoch 32/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3566 - accuracy: 0.8529 - val_loss: 0.3814 - val_accuracy: 0.8344\n",
            "Epoch 33/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3530 - accuracy: 0.8531 - val_loss: 0.3811 - val_accuracy: 0.8402\n",
            "Epoch 34/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3523 - accuracy: 0.8545 - val_loss: 0.3853 - val_accuracy: 0.8378\n",
            "Epoch 35/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3527 - accuracy: 0.8514 - val_loss: 0.3740 - val_accuracy: 0.8388\n",
            "Epoch 36/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3523 - accuracy: 0.8530 - val_loss: 0.3748 - val_accuracy: 0.8394\n",
            "Epoch 37/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3560 - accuracy: 0.8501 - val_loss: 0.3894 - val_accuracy: 0.8322\n",
            "Epoch 38/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3496 - accuracy: 0.8524 - val_loss: 0.3794 - val_accuracy: 0.8376\n",
            "Epoch 39/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3513 - accuracy: 0.8547 - val_loss: 0.3913 - val_accuracy: 0.8340\n",
            "Epoch 40/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3509 - accuracy: 0.8545 - val_loss: 0.3861 - val_accuracy: 0.8382\n",
            "Epoch 41/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3478 - accuracy: 0.8534 - val_loss: 0.3846 - val_accuracy: 0.8372\n",
            "Epoch 42/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3531 - accuracy: 0.8515 - val_loss: 0.3960 - val_accuracy: 0.8306\n",
            "Epoch 43/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3441 - accuracy: 0.8550 - val_loss: 0.3791 - val_accuracy: 0.8384\n",
            "Epoch 44/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3513 - accuracy: 0.8525 - val_loss: 0.3906 - val_accuracy: 0.8314\n",
            "Epoch 45/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3458 - accuracy: 0.8551 - val_loss: 0.4038 - val_accuracy: 0.8240\n",
            "Epoch 46/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3499 - accuracy: 0.8552 - val_loss: 0.4037 - val_accuracy: 0.8270\n",
            "Epoch 47/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3492 - accuracy: 0.8534 - val_loss: 0.3921 - val_accuracy: 0.8334\n",
            "Epoch 48/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3467 - accuracy: 0.8548 - val_loss: 0.3787 - val_accuracy: 0.8400\n",
            "Epoch 49/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3451 - accuracy: 0.8589 - val_loss: 0.3780 - val_accuracy: 0.8374\n",
            "Epoch 50/250\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.3446 - accuracy: 0.8549INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 38ms/step - loss: 0.3451 - accuracy: 0.8553 - val_loss: 0.3724 - val_accuracy: 0.8434\n",
            "Epoch 51/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3440 - accuracy: 0.8581 - val_loss: 0.3953 - val_accuracy: 0.8322\n",
            "Epoch 52/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3463 - accuracy: 0.8551 - val_loss: 0.3822 - val_accuracy: 0.8364\n",
            "Epoch 53/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3390 - accuracy: 0.8597 - val_loss: 0.3857 - val_accuracy: 0.8344\n",
            "Epoch 54/250\n",
            "57/60 [===========================>..] - ETA: 0s - loss: 0.3431 - accuracy: 0.8560INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod/assets\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.3437 - accuracy: 0.8557 - val_loss: 0.3628 - val_accuracy: 0.8468\n",
            "Epoch 55/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3429 - accuracy: 0.8561 - val_loss: 0.3753 - val_accuracy: 0.8410\n",
            "Epoch 56/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3397 - accuracy: 0.8606 - val_loss: 0.3685 - val_accuracy: 0.8450\n",
            "Epoch 57/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3393 - accuracy: 0.8599 - val_loss: 0.3719 - val_accuracy: 0.8426\n",
            "Epoch 58/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3385 - accuracy: 0.8607 - val_loss: 0.3703 - val_accuracy: 0.8452\n",
            "Epoch 59/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3425 - accuracy: 0.8585 - val_loss: 0.3806 - val_accuracy: 0.8388\n",
            "Epoch 60/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3389 - accuracy: 0.8593 - val_loss: 0.3765 - val_accuracy: 0.8400\n",
            "Epoch 61/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3405 - accuracy: 0.8589 - val_loss: 0.3769 - val_accuracy: 0.8398\n",
            "Epoch 62/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3381 - accuracy: 0.8593 - val_loss: 0.3870 - val_accuracy: 0.8380\n",
            "Epoch 63/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3351 - accuracy: 0.8617 - val_loss: 0.3772 - val_accuracy: 0.8396\n",
            "Epoch 64/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3355 - accuracy: 0.8605 - val_loss: 0.3691 - val_accuracy: 0.8430\n",
            "Epoch 65/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3404 - accuracy: 0.8557 - val_loss: 0.3884 - val_accuracy: 0.8364\n",
            "Epoch 66/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3394 - accuracy: 0.8567 - val_loss: 0.3761 - val_accuracy: 0.8398\n",
            "Epoch 67/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3343 - accuracy: 0.8609 - val_loss: 0.3701 - val_accuracy: 0.8440\n",
            "Epoch 68/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3318 - accuracy: 0.8609 - val_loss: 0.3951 - val_accuracy: 0.8364\n",
            "Epoch 69/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3339 - accuracy: 0.8609 - val_loss: 0.3827 - val_accuracy: 0.8396\n",
            "Epoch 70/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3341 - accuracy: 0.8620 - val_loss: 0.3890 - val_accuracy: 0.8318\n",
            "Epoch 71/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3318 - accuracy: 0.8605 - val_loss: 0.3677 - val_accuracy: 0.8458\n",
            "Epoch 72/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3318 - accuracy: 0.8617 - val_loss: 0.3696 - val_accuracy: 0.8442\n",
            "Epoch 73/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3358 - accuracy: 0.8591 - val_loss: 0.3856 - val_accuracy: 0.8352\n",
            "Epoch 74/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.8593\n",
            "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3313 - accuracy: 0.8593 - val_loss: 0.3885 - val_accuracy: 0.8346\n",
            "Epoch 75/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3252 - accuracy: 0.8649 - val_loss: 0.3706 - val_accuracy: 0.8440\n",
            "Epoch 76/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3214 - accuracy: 0.8641 - val_loss: 0.3768 - val_accuracy: 0.8418\n",
            "Epoch 77/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3209 - accuracy: 0.8661 - val_loss: 0.3739 - val_accuracy: 0.8446\n",
            "Epoch 78/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3221 - accuracy: 0.8643 - val_loss: 0.3747 - val_accuracy: 0.8436\n",
            "Epoch 79/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3241 - accuracy: 0.8620 - val_loss: 0.3738 - val_accuracy: 0.8444\n",
            "Epoch 80/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3208 - accuracy: 0.8674 - val_loss: 0.3758 - val_accuracy: 0.8430\n",
            "Epoch 81/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3231 - accuracy: 0.8674 - val_loss: 0.3791 - val_accuracy: 0.8424\n",
            "Epoch 82/250\n",
            "60/60 [==============================] - 1s 18ms/step - loss: 0.3233 - accuracy: 0.8649 - val_loss: 0.3765 - val_accuracy: 0.8416\n",
            "Epoch 83/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3216 - accuracy: 0.8659 - val_loss: 0.3754 - val_accuracy: 0.8426\n",
            "Epoch 84/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3209 - accuracy: 0.8653 - val_loss: 0.3781 - val_accuracy: 0.8422\n",
            "Epoch 85/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3174 - accuracy: 0.8682 - val_loss: 0.3765 - val_accuracy: 0.8412\n",
            "Epoch 86/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3193 - accuracy: 0.8694 - val_loss: 0.3763 - val_accuracy: 0.8412\n",
            "Epoch 87/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3213 - accuracy: 0.8641 - val_loss: 0.3764 - val_accuracy: 0.8410\n",
            "Epoch 88/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3204 - accuracy: 0.8664 - val_loss: 0.3796 - val_accuracy: 0.8418\n",
            "Epoch 89/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3179 - accuracy: 0.8663 - val_loss: 0.3794 - val_accuracy: 0.8414\n",
            "Epoch 90/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3191 - accuracy: 0.8692 - val_loss: 0.3779 - val_accuracy: 0.8412\n",
            "Epoch 91/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3169 - accuracy: 0.8683 - val_loss: 0.3740 - val_accuracy: 0.8428\n",
            "Epoch 92/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3182 - accuracy: 0.8690 - val_loss: 0.3761 - val_accuracy: 0.8426\n",
            "Epoch 93/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3174 - accuracy: 0.8665 - val_loss: 0.3717 - val_accuracy: 0.8446\n",
            "Epoch 94/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.8676\n",
            "Epoch 00094: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3190 - accuracy: 0.8676 - val_loss: 0.3773 - val_accuracy: 0.8430\n",
            "Epoch 95/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3148 - accuracy: 0.8696 - val_loss: 0.3768 - val_accuracy: 0.8426\n",
            "Epoch 96/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3132 - accuracy: 0.8675 - val_loss: 0.3760 - val_accuracy: 0.8430\n",
            "Epoch 97/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3143 - accuracy: 0.8698 - val_loss: 0.3760 - val_accuracy: 0.8430\n",
            "Epoch 98/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3181 - accuracy: 0.8672 - val_loss: 0.3796 - val_accuracy: 0.8416\n",
            "Epoch 99/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3174 - accuracy: 0.8680 - val_loss: 0.3772 - val_accuracy: 0.8426\n",
            "Epoch 100/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3117 - accuracy: 0.8679 - val_loss: 0.3773 - val_accuracy: 0.8418\n",
            "Epoch 101/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3141 - accuracy: 0.8694 - val_loss: 0.3773 - val_accuracy: 0.8424\n",
            "Epoch 102/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3183 - accuracy: 0.8667 - val_loss: 0.3759 - val_accuracy: 0.8430\n",
            "Epoch 103/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3172 - accuracy: 0.8665 - val_loss: 0.3766 - val_accuracy: 0.8432\n",
            "Epoch 104/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3113 - accuracy: 0.8706 - val_loss: 0.3795 - val_accuracy: 0.8418\n",
            "Epoch 105/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3123 - accuracy: 0.8709 - val_loss: 0.3801 - val_accuracy: 0.8418\n",
            "Epoch 106/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3128 - accuracy: 0.8695 - val_loss: 0.3776 - val_accuracy: 0.8424\n",
            "Epoch 107/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3154 - accuracy: 0.8671 - val_loss: 0.3754 - val_accuracy: 0.8436\n",
            "Epoch 108/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3113 - accuracy: 0.8707 - val_loss: 0.3768 - val_accuracy: 0.8428\n",
            "Epoch 109/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3149 - accuracy: 0.8699 - val_loss: 0.3751 - val_accuracy: 0.8444\n",
            "Epoch 110/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3179 - accuracy: 0.8671 - val_loss: 0.3769 - val_accuracy: 0.8432\n",
            "Epoch 111/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3151 - accuracy: 0.8671 - val_loss: 0.3802 - val_accuracy: 0.8422\n",
            "Epoch 112/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3184 - accuracy: 0.8679 - val_loss: 0.3758 - val_accuracy: 0.8434\n",
            "Epoch 113/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3168 - accuracy: 0.8685 - val_loss: 0.3761 - val_accuracy: 0.8424\n",
            "Epoch 114/250\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.3155 - accuracy: 0.8696\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3150 - accuracy: 0.8699 - val_loss: 0.3758 - val_accuracy: 0.8428\n",
            "Epoch 115/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3133 - accuracy: 0.8727 - val_loss: 0.3761 - val_accuracy: 0.8422\n",
            "Epoch 116/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3139 - accuracy: 0.8719 - val_loss: 0.3763 - val_accuracy: 0.8414\n",
            "Epoch 117/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3185 - accuracy: 0.8659 - val_loss: 0.3763 - val_accuracy: 0.8422\n",
            "Epoch 118/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3164 - accuracy: 0.8690 - val_loss: 0.3772 - val_accuracy: 0.8416\n",
            "Epoch 119/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3142 - accuracy: 0.8695 - val_loss: 0.3763 - val_accuracy: 0.8422\n",
            "Epoch 120/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3141 - accuracy: 0.8697 - val_loss: 0.3765 - val_accuracy: 0.8424\n",
            "Epoch 121/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3157 - accuracy: 0.8679 - val_loss: 0.3771 - val_accuracy: 0.8420\n",
            "Epoch 122/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3174 - accuracy: 0.8677 - val_loss: 0.3769 - val_accuracy: 0.8422\n",
            "Epoch 123/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3148 - accuracy: 0.8691 - val_loss: 0.3769 - val_accuracy: 0.8420\n",
            "Epoch 124/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3124 - accuracy: 0.8706 - val_loss: 0.3773 - val_accuracy: 0.8422\n",
            "Epoch 125/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3152 - accuracy: 0.8699 - val_loss: 0.3769 - val_accuracy: 0.8428\n",
            "Epoch 126/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3179 - accuracy: 0.8671 - val_loss: 0.3767 - val_accuracy: 0.8428\n",
            "Epoch 127/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3132 - accuracy: 0.8706 - val_loss: 0.3762 - val_accuracy: 0.8430\n",
            "Epoch 128/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3160 - accuracy: 0.8657 - val_loss: 0.3764 - val_accuracy: 0.8432\n",
            "Epoch 129/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3138 - accuracy: 0.8699 - val_loss: 0.3773 - val_accuracy: 0.8422\n",
            "Epoch 130/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3135 - accuracy: 0.8702 - val_loss: 0.3774 - val_accuracy: 0.8418\n",
            "Epoch 131/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3162 - accuracy: 0.8696 - val_loss: 0.3765 - val_accuracy: 0.8428\n",
            "Epoch 132/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3151 - accuracy: 0.8695 - val_loss: 0.3763 - val_accuracy: 0.8430\n",
            "Epoch 133/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3153 - accuracy: 0.8695 - val_loss: 0.3765 - val_accuracy: 0.8428\n",
            "Epoch 134/250\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.8674\n",
            "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3164 - accuracy: 0.8675 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 135/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3154 - accuracy: 0.8687 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 136/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3148 - accuracy: 0.8667 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 137/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3143 - accuracy: 0.8691 - val_loss: 0.3768 - val_accuracy: 0.8428\n",
            "Epoch 138/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3124 - accuracy: 0.8706 - val_loss: 0.3767 - val_accuracy: 0.8430\n",
            "Epoch 139/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3166 - accuracy: 0.8679 - val_loss: 0.3767 - val_accuracy: 0.8430\n",
            "Epoch 140/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3152 - accuracy: 0.8691 - val_loss: 0.3768 - val_accuracy: 0.8430\n",
            "Epoch 141/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3124 - accuracy: 0.8673 - val_loss: 0.3768 - val_accuracy: 0.8428\n",
            "Epoch 142/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3147 - accuracy: 0.8690 - val_loss: 0.3769 - val_accuracy: 0.8428\n",
            "Epoch 143/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3137 - accuracy: 0.8697 - val_loss: 0.3768 - val_accuracy: 0.8428\n",
            "Epoch 144/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3114 - accuracy: 0.8697 - val_loss: 0.3768 - val_accuracy: 0.8428\n",
            "Epoch 145/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3126 - accuracy: 0.8694 - val_loss: 0.3768 - val_accuracy: 0.8428\n",
            "Epoch 146/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3154 - accuracy: 0.8684 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 147/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3145 - accuracy: 0.8688 - val_loss: 0.3768 - val_accuracy: 0.8428\n",
            "Epoch 148/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3128 - accuracy: 0.8677 - val_loss: 0.3767 - val_accuracy: 0.8430\n",
            "Epoch 149/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3141 - accuracy: 0.8685 - val_loss: 0.3768 - val_accuracy: 0.8430\n",
            "Epoch 150/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3144 - accuracy: 0.8675 - val_loss: 0.3768 - val_accuracy: 0.8426\n",
            "Epoch 151/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3148 - accuracy: 0.8677 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 152/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3131 - accuracy: 0.8701 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 153/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3132 - accuracy: 0.8703 - val_loss: 0.3768 - val_accuracy: 0.8430\n",
            "Epoch 154/250\n",
            "59/60 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.8696\n",
            "Epoch 00154: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3130 - accuracy: 0.8694 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 155/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3121 - accuracy: 0.8701 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 156/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3165 - accuracy: 0.8671 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 157/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3176 - accuracy: 0.8667 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 158/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3159 - accuracy: 0.8685 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 159/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3173 - accuracy: 0.8669 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 160/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3155 - accuracy: 0.8667 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 161/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3144 - accuracy: 0.8702 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 162/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3085 - accuracy: 0.8725 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 163/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3140 - accuracy: 0.8711 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 164/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3176 - accuracy: 0.8652 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 165/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3161 - accuracy: 0.8687 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 166/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3140 - accuracy: 0.8674 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 167/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3133 - accuracy: 0.8721 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 168/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3138 - accuracy: 0.8681 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 169/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3144 - accuracy: 0.8667 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 170/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3121 - accuracy: 0.8691 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 171/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3154 - accuracy: 0.8681 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 172/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3168 - accuracy: 0.8697 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 173/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3127 - accuracy: 0.8687 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 174/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.8710\n",
            "Epoch 00174: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3135 - accuracy: 0.8710 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 175/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3148 - accuracy: 0.8661 - val_loss: 0.3769 - val_accuracy: 0.8426\n",
            "Epoch 176/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3102 - accuracy: 0.8680 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 177/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3143 - accuracy: 0.8715 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 178/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3127 - accuracy: 0.8681 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 179/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3157 - accuracy: 0.8672 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 180/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3121 - accuracy: 0.8679 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 181/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3146 - accuracy: 0.8685 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 182/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3136 - accuracy: 0.8665 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 183/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3131 - accuracy: 0.8697 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 184/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3124 - accuracy: 0.8724 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 185/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3138 - accuracy: 0.8688 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 186/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3159 - accuracy: 0.8667 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 187/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3198 - accuracy: 0.8699 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 188/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3168 - accuracy: 0.8665 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 189/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3106 - accuracy: 0.8701 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 190/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3120 - accuracy: 0.8705 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 191/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3117 - accuracy: 0.8714 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 192/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3184 - accuracy: 0.8675 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 193/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3154 - accuracy: 0.8691 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 194/250\n",
            "58/60 [============================>.] - ETA: 0s - loss: 0.3173 - accuracy: 0.8692\n",
            "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3162 - accuracy: 0.8695 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 195/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3129 - accuracy: 0.8687 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 196/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3150 - accuracy: 0.8682 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 197/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3162 - accuracy: 0.8669 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 198/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3142 - accuracy: 0.8694 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 199/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3143 - accuracy: 0.8660 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 200/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3106 - accuracy: 0.8681 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 201/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3126 - accuracy: 0.8702 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 202/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3173 - accuracy: 0.8676 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 203/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3103 - accuracy: 0.8693 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 204/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3075 - accuracy: 0.8709 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 205/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3132 - accuracy: 0.8688 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 206/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3132 - accuracy: 0.8693 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 207/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3161 - accuracy: 0.8699 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 208/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3165 - accuracy: 0.8671 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 209/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3147 - accuracy: 0.8666 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 210/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3139 - accuracy: 0.8673 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 211/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3130 - accuracy: 0.8671 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 212/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3121 - accuracy: 0.8734 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 213/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3147 - accuracy: 0.8668 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 214/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.8699\n",
            "Epoch 00214: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3132 - accuracy: 0.8699 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 215/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3103 - accuracy: 0.8684 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 216/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3132 - accuracy: 0.8715 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 217/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3170 - accuracy: 0.8672 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 218/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3138 - accuracy: 0.8707 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 219/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3164 - accuracy: 0.8692 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 220/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3157 - accuracy: 0.8721 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 221/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3109 - accuracy: 0.8693 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 222/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3143 - accuracy: 0.8687 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 223/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3126 - accuracy: 0.8714 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 224/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3174 - accuracy: 0.8656 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 225/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3136 - accuracy: 0.8693 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 226/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3164 - accuracy: 0.8674 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 227/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3147 - accuracy: 0.8697 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 228/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3136 - accuracy: 0.8706 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 229/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3114 - accuracy: 0.8705 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 230/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3145 - accuracy: 0.8675 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 231/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3159 - accuracy: 0.8674 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 232/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3106 - accuracy: 0.8695 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 233/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3124 - accuracy: 0.8705 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 234/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.8718\n",
            "Epoch 00234: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3121 - accuracy: 0.8718 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 235/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3099 - accuracy: 0.8704 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 236/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3157 - accuracy: 0.8669 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 237/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3128 - accuracy: 0.8695 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 238/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3113 - accuracy: 0.8691 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 239/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3140 - accuracy: 0.8680 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 240/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3120 - accuracy: 0.8704 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 241/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3127 - accuracy: 0.8683 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 242/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3154 - accuracy: 0.8677 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 243/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3110 - accuracy: 0.8701 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 244/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3117 - accuracy: 0.8684 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 245/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3147 - accuracy: 0.8667 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 246/250\n",
            "60/60 [==============================] - 1s 19ms/step - loss: 0.3143 - accuracy: 0.8657 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 247/250\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.3150 - accuracy: 0.8686 - val_loss: 0.3770 - val_accuracy: 0.8426\n",
            "Epoch 248/250\n",
            " 7/60 [==>...........................] - ETA: 0s - loss: 0.3273 - accuracy: 0.8686"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx3iXPj0Y_n4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89812ab4-b396-48e1-f499-b5ebca0507cc"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Train a network using 10K simulations per model for the D.melanogaster-D.sechellia pair.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing simulations.\n",
        "u1 = np.load(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Drosophila/melano_simulans/simModel1.npz\")\n",
        "u2 = np.load(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/trainingSims/Drosophila/melano_simulans/simModel2.npz\")\n",
        "u1 = u1[\"simModel1\"]\n",
        "u2 = u2[\"simModel2\"]\n",
        "x=np.concatenate((u1,u2),axis=0)\n",
        "# Label each simulated array.\n",
        "y=[0 for i in range(len(u1))]\n",
        "y.extend([1 for i in range(len(u2))])\n",
        "y = np.array(y)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(x):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      x[arr][idx][x[arr][idx] == 0] = -1\n",
        "      x[arr][idx][x[arr][idx] == 1] = 0\n",
        "      x[arr][idx][x[arr][idx] == -1] = 1\n",
        "x=x.astype(np.uint8)\n",
        "\n",
        "# Print label and simulations length, these should be the same.\n",
        "print (len(x), len(y))\n",
        "\n",
        "shf = list(range(len(x)))\n",
        "shuffle(shf)\n",
        "y = y[shf]\n",
        "x = x[shf]\n",
        "\n",
        "# Separate train (75%) and validate (25%) sets.\n",
        "xtrain, xtest = x[int(len(y)*.25):], x[:int(len(y)*.25)]\n",
        "ytrain, ytest = y[int(len(y)*.25):], y[:int(len(y)*.25)]\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes)\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes)\n",
        "\n",
        "# Create the CNN network, using the architecture defined above.\n",
        "cnn = create_cnn(xtest)\n",
        "\n",
        "# Compile the CNN.\n",
        "cnn.compile(loss=keras.losses.categorical_crossentropy,\n",
        "\t              optimizer=keras.optimizers.Adam(),\n",
        "\t              metrics=['accuracy'])\n",
        "print(cnn.summary())\n",
        "\n",
        "# Run the CNN and save the model with the best val_accuracy. Record the runtime required to train the network\n",
        "mcp_save = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=20, verbose=1, mode='max')\n",
        "cnn.fit(xtrain, ytrain, batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(xtest, ytest),callbacks=[mcp_save,reduce_lr_loss])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000 20000\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 108, 6)]          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 107, 250)          3250      \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 106, 125)          62625     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_2 (Average (None, 53, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 53, 125)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 52, 125)           31375     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_3 (Average (None, 26, 125)           0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 26, 125)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3250)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 125)               406375    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 125)               15750     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 252       \n",
            "=================================================================\n",
            "Total params: 519,627\n",
            "Trainable params: 519,627\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/250\n",
            " 1/60 [..............................] - ETA: 0s - loss: 0.7142 - accuracy: 0.5320WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.0078s). Check your callbacks.\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.6970 - accuracy: 0.5054WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_test_batch_end` time: 0.0032s). Check your callbacks.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 32ms/step - loss: 0.6970 - accuracy: 0.5045 - val_loss: 0.6909 - val_accuracy: 0.5382\n",
            "Epoch 2/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.6531INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 33ms/step - loss: 0.6131 - accuracy: 0.6531 - val_loss: 0.4521 - val_accuracy: 0.7998\n",
            "Epoch 3/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.4591 - accuracy: 0.7986INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 30ms/step - loss: 0.4589 - accuracy: 0.7989 - val_loss: 0.4104 - val_accuracy: 0.8166\n",
            "Epoch 4/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.4344 - accuracy: 0.8069INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 33ms/step - loss: 0.4357 - accuracy: 0.8065 - val_loss: 0.4069 - val_accuracy: 0.8210\n",
            "Epoch 5/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8155INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 34ms/step - loss: 0.4267 - accuracy: 0.8155 - val_loss: 0.4132 - val_accuracy: 0.8218\n",
            "Epoch 6/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.4226 - accuracy: 0.8168 - val_loss: 0.4259 - val_accuracy: 0.8142\n",
            "Epoch 7/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.4142 - accuracy: 0.8207INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 31ms/step - loss: 0.4121 - accuracy: 0.8215 - val_loss: 0.3943 - val_accuracy: 0.8278\n",
            "Epoch 8/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.4084 - accuracy: 0.8223INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 33ms/step - loss: 0.4075 - accuracy: 0.8229 - val_loss: 0.3770 - val_accuracy: 0.8318\n",
            "Epoch 9/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3999 - accuracy: 0.8287INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 30ms/step - loss: 0.4001 - accuracy: 0.8287 - val_loss: 0.3865 - val_accuracy: 0.8342\n",
            "Epoch 10/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3920 - accuracy: 0.8301 - val_loss: 0.3889 - val_accuracy: 0.8264\n",
            "Epoch 11/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3902 - accuracy: 0.8320INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 35ms/step - loss: 0.3912 - accuracy: 0.8315 - val_loss: 0.3694 - val_accuracy: 0.8364\n",
            "Epoch 12/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3834 - accuracy: 0.8386INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 30ms/step - loss: 0.3868 - accuracy: 0.8366 - val_loss: 0.3760 - val_accuracy: 0.8398\n",
            "Epoch 13/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3765 - accuracy: 0.8429 - val_loss: 0.3641 - val_accuracy: 0.8398\n",
            "Epoch 14/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3765 - accuracy: 0.8375 - val_loss: 0.3764 - val_accuracy: 0.8374\n",
            "Epoch 15/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3798 - accuracy: 0.8379INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 30ms/step - loss: 0.3797 - accuracy: 0.8384 - val_loss: 0.3613 - val_accuracy: 0.8420\n",
            "Epoch 16/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3750 - accuracy: 0.8404 - val_loss: 0.3633 - val_accuracy: 0.8412\n",
            "Epoch 17/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3706 - accuracy: 0.8409INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 32ms/step - loss: 0.3684 - accuracy: 0.8417 - val_loss: 0.3595 - val_accuracy: 0.8430\n",
            "Epoch 18/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3734 - accuracy: 0.8379 - val_loss: 0.3905 - val_accuracy: 0.8278\n",
            "Epoch 19/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3678 - accuracy: 0.8435 - val_loss: 0.3667 - val_accuracy: 0.8416\n",
            "Epoch 20/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3636 - accuracy: 0.8471 - val_loss: 0.3676 - val_accuracy: 0.8390\n",
            "Epoch 21/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3667 - accuracy: 0.8455 - val_loss: 0.3638 - val_accuracy: 0.8398\n",
            "Epoch 22/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3632 - accuracy: 0.8461 - val_loss: 0.3845 - val_accuracy: 0.8304\n",
            "Epoch 23/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3683 - accuracy: 0.8443INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 34ms/step - loss: 0.3672 - accuracy: 0.8449 - val_loss: 0.3569 - val_accuracy: 0.8438\n",
            "Epoch 24/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3604 - accuracy: 0.8479 - val_loss: 0.3586 - val_accuracy: 0.8434\n",
            "Epoch 25/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3583 - accuracy: 0.8496INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 30ms/step - loss: 0.3589 - accuracy: 0.8505 - val_loss: 0.3553 - val_accuracy: 0.8474\n",
            "Epoch 26/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3556 - accuracy: 0.8537INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 30ms/step - loss: 0.3559 - accuracy: 0.8528 - val_loss: 0.3547 - val_accuracy: 0.8482\n",
            "Epoch 27/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3570 - accuracy: 0.8471 - val_loss: 0.3538 - val_accuracy: 0.8478\n",
            "Epoch 28/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3543 - accuracy: 0.8517 - val_loss: 0.3513 - val_accuracy: 0.8458\n",
            "Epoch 29/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3548 - accuracy: 0.8515 - val_loss: 0.3529 - val_accuracy: 0.8462\n",
            "Epoch 30/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3515 - accuracy: 0.8504 - val_loss: 0.3674 - val_accuracy: 0.8414\n",
            "Epoch 31/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3557 - accuracy: 0.8489 - val_loss: 0.3563 - val_accuracy: 0.8446\n",
            "Epoch 32/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3476 - accuracy: 0.8535 - val_loss: 0.3501 - val_accuracy: 0.8470\n",
            "Epoch 33/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3460 - accuracy: 0.8561INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod/assets\n",
            "60/60 [==============================] - 2s 34ms/step - loss: 0.3445 - accuracy: 0.8575 - val_loss: 0.3502 - val_accuracy: 0.8514\n",
            "Epoch 34/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3492 - accuracy: 0.8549 - val_loss: 0.3598 - val_accuracy: 0.8454\n",
            "Epoch 35/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3489 - accuracy: 0.8541 - val_loss: 0.3646 - val_accuracy: 0.8418\n",
            "Epoch 36/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3516 - accuracy: 0.8491 - val_loss: 0.3595 - val_accuracy: 0.8456\n",
            "Epoch 37/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3493 - accuracy: 0.8539 - val_loss: 0.3495 - val_accuracy: 0.8496\n",
            "Epoch 38/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3456 - accuracy: 0.8553 - val_loss: 0.3504 - val_accuracy: 0.8466\n",
            "Epoch 39/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3416 - accuracy: 0.8569 - val_loss: 0.3521 - val_accuracy: 0.8488\n",
            "Epoch 40/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3398 - accuracy: 0.8583 - val_loss: 0.3511 - val_accuracy: 0.8480\n",
            "Epoch 41/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3424 - accuracy: 0.8589 - val_loss: 0.3565 - val_accuracy: 0.8468\n",
            "Epoch 42/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3446 - accuracy: 0.8554 - val_loss: 0.3547 - val_accuracy: 0.8438\n",
            "Epoch 43/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3398 - accuracy: 0.8619 - val_loss: 0.3511 - val_accuracy: 0.8504\n",
            "Epoch 44/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3393 - accuracy: 0.8599 - val_loss: 0.3504 - val_accuracy: 0.8472\n",
            "Epoch 45/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3452 - accuracy: 0.8563 - val_loss: 0.3488 - val_accuracy: 0.8494\n",
            "Epoch 46/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3395 - accuracy: 0.8597 - val_loss: 0.3542 - val_accuracy: 0.8472\n",
            "Epoch 47/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3371 - accuracy: 0.8608 - val_loss: 0.3552 - val_accuracy: 0.8444\n",
            "Epoch 48/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3361 - accuracy: 0.8603 - val_loss: 0.3514 - val_accuracy: 0.8470\n",
            "Epoch 49/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3345 - accuracy: 0.8634 - val_loss: 0.3591 - val_accuracy: 0.8454\n",
            "Epoch 50/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3385 - accuracy: 0.8600 - val_loss: 0.3508 - val_accuracy: 0.8486\n",
            "Epoch 51/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3377 - accuracy: 0.8588 - val_loss: 0.3729 - val_accuracy: 0.8374\n",
            "Epoch 52/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3359 - accuracy: 0.8594 - val_loss: 0.3501 - val_accuracy: 0.8458\n",
            "Epoch 53/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3306 - accuracy: 0.8616\n",
            "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3311 - accuracy: 0.8615 - val_loss: 0.3482 - val_accuracy: 0.8470\n",
            "Epoch 54/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3288 - accuracy: 0.8633 - val_loss: 0.3516 - val_accuracy: 0.8450\n",
            "Epoch 55/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3246 - accuracy: 0.8639 - val_loss: 0.3485 - val_accuracy: 0.8460\n",
            "Epoch 56/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3250 - accuracy: 0.8696 - val_loss: 0.3488 - val_accuracy: 0.8458\n",
            "Epoch 57/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3242 - accuracy: 0.8661 - val_loss: 0.3496 - val_accuracy: 0.8460\n",
            "Epoch 58/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3220 - accuracy: 0.8649 - val_loss: 0.3552 - val_accuracy: 0.8442\n",
            "Epoch 59/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3204 - accuracy: 0.8695 - val_loss: 0.3530 - val_accuracy: 0.8446\n",
            "Epoch 60/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3225 - accuracy: 0.8693 - val_loss: 0.3516 - val_accuracy: 0.8456\n",
            "Epoch 61/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3201 - accuracy: 0.8699 - val_loss: 0.3484 - val_accuracy: 0.8478\n",
            "Epoch 62/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3185 - accuracy: 0.8710 - val_loss: 0.3489 - val_accuracy: 0.8454\n",
            "Epoch 63/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3191 - accuracy: 0.8707 - val_loss: 0.3496 - val_accuracy: 0.8444\n",
            "Epoch 64/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3186 - accuracy: 0.8682 - val_loss: 0.3484 - val_accuracy: 0.8462\n",
            "Epoch 65/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3181 - accuracy: 0.8687 - val_loss: 0.3488 - val_accuracy: 0.8476\n",
            "Epoch 66/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3183 - accuracy: 0.8675 - val_loss: 0.3515 - val_accuracy: 0.8450\n",
            "Epoch 67/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3193 - accuracy: 0.8667 - val_loss: 0.3492 - val_accuracy: 0.8482\n",
            "Epoch 68/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3195 - accuracy: 0.8685 - val_loss: 0.3502 - val_accuracy: 0.8464\n",
            "Epoch 69/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3172 - accuracy: 0.8679 - val_loss: 0.3500 - val_accuracy: 0.8470\n",
            "Epoch 70/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3161 - accuracy: 0.8699 - val_loss: 0.3489 - val_accuracy: 0.8480\n",
            "Epoch 71/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3148 - accuracy: 0.8703 - val_loss: 0.3503 - val_accuracy: 0.8484\n",
            "Epoch 72/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3133 - accuracy: 0.8746 - val_loss: 0.3480 - val_accuracy: 0.8466\n",
            "Epoch 73/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3179 - accuracy: 0.8706\n",
            "Epoch 00073: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3175 - accuracy: 0.8709 - val_loss: 0.3490 - val_accuracy: 0.8462\n",
            "Epoch 74/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3142 - accuracy: 0.8707 - val_loss: 0.3502 - val_accuracy: 0.8468\n",
            "Epoch 75/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3158 - accuracy: 0.8708 - val_loss: 0.3508 - val_accuracy: 0.8464\n",
            "Epoch 76/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3155 - accuracy: 0.8715 - val_loss: 0.3501 - val_accuracy: 0.8468\n",
            "Epoch 77/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3118 - accuracy: 0.8699 - val_loss: 0.3517 - val_accuracy: 0.8470\n",
            "Epoch 78/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3156 - accuracy: 0.8688 - val_loss: 0.3494 - val_accuracy: 0.8452\n",
            "Epoch 79/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3109 - accuracy: 0.8725 - val_loss: 0.3507 - val_accuracy: 0.8464\n",
            "Epoch 80/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3125 - accuracy: 0.8717 - val_loss: 0.3501 - val_accuracy: 0.8462\n",
            "Epoch 81/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3102 - accuracy: 0.8747 - val_loss: 0.3530 - val_accuracy: 0.8466\n",
            "Epoch 82/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3132 - accuracy: 0.8713 - val_loss: 0.3512 - val_accuracy: 0.8466\n",
            "Epoch 83/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3120 - accuracy: 0.8707 - val_loss: 0.3508 - val_accuracy: 0.8460\n",
            "Epoch 84/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3130 - accuracy: 0.8744 - val_loss: 0.3505 - val_accuracy: 0.8452\n",
            "Epoch 85/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3145 - accuracy: 0.8727 - val_loss: 0.3508 - val_accuracy: 0.8466\n",
            "Epoch 86/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3116 - accuracy: 0.8721 - val_loss: 0.3517 - val_accuracy: 0.8464\n",
            "Epoch 87/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3128 - accuracy: 0.8724 - val_loss: 0.3506 - val_accuracy: 0.8460\n",
            "Epoch 88/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3097 - accuracy: 0.8725 - val_loss: 0.3514 - val_accuracy: 0.8456\n",
            "Epoch 89/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3107 - accuracy: 0.8707 - val_loss: 0.3538 - val_accuracy: 0.8464\n",
            "Epoch 90/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3118 - accuracy: 0.8731 - val_loss: 0.3519 - val_accuracy: 0.8464\n",
            "Epoch 91/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3141 - accuracy: 0.8707 - val_loss: 0.3514 - val_accuracy: 0.8454\n",
            "Epoch 92/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3107 - accuracy: 0.8737 - val_loss: 0.3528 - val_accuracy: 0.8460\n",
            "Epoch 93/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3158 - accuracy: 0.8713\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3156 - accuracy: 0.8711 - val_loss: 0.3515 - val_accuracy: 0.8448\n",
            "Epoch 94/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3107 - accuracy: 0.8719 - val_loss: 0.3517 - val_accuracy: 0.8448\n",
            "Epoch 95/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3077 - accuracy: 0.8735 - val_loss: 0.3518 - val_accuracy: 0.8452\n",
            "Epoch 96/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3113 - accuracy: 0.8724 - val_loss: 0.3519 - val_accuracy: 0.8454\n",
            "Epoch 97/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3127 - accuracy: 0.8723 - val_loss: 0.3517 - val_accuracy: 0.8446\n",
            "Epoch 98/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3127 - accuracy: 0.8738 - val_loss: 0.3517 - val_accuracy: 0.8450\n",
            "Epoch 99/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3105 - accuracy: 0.8735 - val_loss: 0.3514 - val_accuracy: 0.8450\n",
            "Epoch 100/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3094 - accuracy: 0.8721 - val_loss: 0.3517 - val_accuracy: 0.8446\n",
            "Epoch 101/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3083 - accuracy: 0.8722 - val_loss: 0.3518 - val_accuracy: 0.8448\n",
            "Epoch 102/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3072 - accuracy: 0.8733 - val_loss: 0.3517 - val_accuracy: 0.8452\n",
            "Epoch 103/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3087 - accuracy: 0.8754 - val_loss: 0.3522 - val_accuracy: 0.8456\n",
            "Epoch 104/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3125 - accuracy: 0.8683 - val_loss: 0.3522 - val_accuracy: 0.8454\n",
            "Epoch 105/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3119 - accuracy: 0.8719 - val_loss: 0.3517 - val_accuracy: 0.8452\n",
            "Epoch 106/250\n",
            "60/60 [==============================] - 1s 12ms/step - loss: 0.3123 - accuracy: 0.8732 - val_loss: 0.3523 - val_accuracy: 0.8460\n",
            "Epoch 107/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3087 - accuracy: 0.8719 - val_loss: 0.3520 - val_accuracy: 0.8452\n",
            "Epoch 108/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3093 - accuracy: 0.8729 - val_loss: 0.3520 - val_accuracy: 0.8454\n",
            "Epoch 109/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3096 - accuracy: 0.8727 - val_loss: 0.3522 - val_accuracy: 0.8460\n",
            "Epoch 110/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3104 - accuracy: 0.8734 - val_loss: 0.3519 - val_accuracy: 0.8452\n",
            "Epoch 111/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3108 - accuracy: 0.8721 - val_loss: 0.3526 - val_accuracy: 0.8456\n",
            "Epoch 112/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3075 - accuracy: 0.8744 - val_loss: 0.3520 - val_accuracy: 0.8454\n",
            "Epoch 113/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3072 - accuracy: 0.8766\n",
            "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3063 - accuracy: 0.8770 - val_loss: 0.3516 - val_accuracy: 0.8454\n",
            "Epoch 114/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3099 - accuracy: 0.8736 - val_loss: 0.3518 - val_accuracy: 0.8450\n",
            "Epoch 115/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3090 - accuracy: 0.8739 - val_loss: 0.3519 - val_accuracy: 0.8456\n",
            "Epoch 116/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3105 - accuracy: 0.8736 - val_loss: 0.3520 - val_accuracy: 0.8454\n",
            "Epoch 117/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3089 - accuracy: 0.8733 - val_loss: 0.3519 - val_accuracy: 0.8456\n",
            "Epoch 118/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3106 - accuracy: 0.8727 - val_loss: 0.3520 - val_accuracy: 0.8454\n",
            "Epoch 119/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3087 - accuracy: 0.8740 - val_loss: 0.3520 - val_accuracy: 0.8454\n",
            "Epoch 120/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3086 - accuracy: 0.8723 - val_loss: 0.3521 - val_accuracy: 0.8452\n",
            "Epoch 121/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3108 - accuracy: 0.8713 - val_loss: 0.3521 - val_accuracy: 0.8452\n",
            "Epoch 122/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3074 - accuracy: 0.8741 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 123/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3115 - accuracy: 0.8712 - val_loss: 0.3521 - val_accuracy: 0.8452\n",
            "Epoch 124/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3125 - accuracy: 0.8705 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 125/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3076 - accuracy: 0.8748 - val_loss: 0.3521 - val_accuracy: 0.8452\n",
            "Epoch 126/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3117 - accuracy: 0.8687 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 127/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3111 - accuracy: 0.8718 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 128/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3102 - accuracy: 0.8735 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 129/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3100 - accuracy: 0.8713 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 130/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3105 - accuracy: 0.8739 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 131/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3093 - accuracy: 0.8733 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 132/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3101 - accuracy: 0.8734 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 133/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3130 - accuracy: 0.8709\n",
            "Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3124 - accuracy: 0.8715 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 134/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3088 - accuracy: 0.8743 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 135/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3120 - accuracy: 0.8755 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 136/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3093 - accuracy: 0.8725 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 137/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3077 - accuracy: 0.8719 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 138/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3089 - accuracy: 0.8763 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 139/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3093 - accuracy: 0.8731 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 140/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3116 - accuracy: 0.8714 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 141/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3114 - accuracy: 0.8746 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 142/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3119 - accuracy: 0.8717 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 143/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3133 - accuracy: 0.8719 - val_loss: 0.3520 - val_accuracy: 0.8450\n",
            "Epoch 144/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3074 - accuracy: 0.8762 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 145/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3060 - accuracy: 0.8743 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 146/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3077 - accuracy: 0.8741 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 147/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3136 - accuracy: 0.8691 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 148/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3145 - accuracy: 0.8711 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 149/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3094 - accuracy: 0.8731 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 150/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3124 - accuracy: 0.8741 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 151/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3082 - accuracy: 0.8728 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 152/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3091 - accuracy: 0.8743 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 153/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3110 - accuracy: 0.8734\n",
            "Epoch 00153: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3097 - accuracy: 0.8735 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 154/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3125 - accuracy: 0.8753 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 155/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3096 - accuracy: 0.8705 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 156/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3088 - accuracy: 0.8722 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 157/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3084 - accuracy: 0.8731 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 158/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3092 - accuracy: 0.8720 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 159/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3078 - accuracy: 0.8726 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 160/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3091 - accuracy: 0.8731 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 161/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3123 - accuracy: 0.8715 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 162/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3069 - accuracy: 0.8743 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 163/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3092 - accuracy: 0.8741 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 164/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3093 - accuracy: 0.8739 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 165/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3158 - accuracy: 0.8692 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 166/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3102 - accuracy: 0.8723 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 167/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3106 - accuracy: 0.8725 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 168/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3084 - accuracy: 0.8742 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 169/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3089 - accuracy: 0.8725 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 170/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3078 - accuracy: 0.8733 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 171/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3111 - accuracy: 0.8721 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 172/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3121 - accuracy: 0.8691 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 173/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3109 - accuracy: 0.8755\n",
            "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3109 - accuracy: 0.8755 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 174/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3106 - accuracy: 0.8715 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 175/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3084 - accuracy: 0.8742 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 176/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3114 - accuracy: 0.8701 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 177/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3125 - accuracy: 0.8715 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 178/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3097 - accuracy: 0.8723 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 179/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3097 - accuracy: 0.8750 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 180/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3082 - accuracy: 0.8744 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 181/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3121 - accuracy: 0.8708 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 182/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3090 - accuracy: 0.8735 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 183/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3100 - accuracy: 0.8731 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 184/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3104 - accuracy: 0.8738 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 185/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3078 - accuracy: 0.8760 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 186/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3130 - accuracy: 0.8726 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 187/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3152 - accuracy: 0.8704 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 188/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3119 - accuracy: 0.8722 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 189/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3079 - accuracy: 0.8746 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 190/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3111 - accuracy: 0.8743 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 191/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3080 - accuracy: 0.8733 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 192/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3139 - accuracy: 0.8731 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 193/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3078 - accuracy: 0.8743\n",
            "Epoch 00193: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3090 - accuracy: 0.8739 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 194/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3117 - accuracy: 0.8720 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 195/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3130 - accuracy: 0.8717 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 196/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3109 - accuracy: 0.8753 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 197/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3148 - accuracy: 0.8701 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 198/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3086 - accuracy: 0.8711 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 199/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3100 - accuracy: 0.8736 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 200/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3131 - accuracy: 0.8717 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 201/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3086 - accuracy: 0.8741 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 202/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3106 - accuracy: 0.8732 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 203/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3106 - accuracy: 0.8752 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 204/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3108 - accuracy: 0.8745 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 205/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3103 - accuracy: 0.8720 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 206/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3088 - accuracy: 0.8733 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 207/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3122 - accuracy: 0.8744 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 208/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3130 - accuracy: 0.8711 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 209/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3118 - accuracy: 0.8718 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 210/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3070 - accuracy: 0.8759 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 211/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3106 - accuracy: 0.8742 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 212/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3078 - accuracy: 0.8733 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 213/250\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.8716\n",
            "Epoch 00213: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3148 - accuracy: 0.8716 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 214/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3088 - accuracy: 0.8720 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 215/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3154 - accuracy: 0.8705 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 216/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3120 - accuracy: 0.8721 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 217/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3106 - accuracy: 0.8739 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 218/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3118 - accuracy: 0.8713 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 219/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3102 - accuracy: 0.8711 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 220/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3093 - accuracy: 0.8733 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 221/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3101 - accuracy: 0.8717 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 222/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3079 - accuracy: 0.8717 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 223/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3094 - accuracy: 0.8731 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 224/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3103 - accuracy: 0.8694 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 225/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3112 - accuracy: 0.8719 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 226/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3119 - accuracy: 0.8710 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 227/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3133 - accuracy: 0.8719 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 228/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3098 - accuracy: 0.8721 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 229/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3092 - accuracy: 0.8737 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 230/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3121 - accuracy: 0.8727 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 231/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3080 - accuracy: 0.8748 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 232/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3112 - accuracy: 0.8737 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 233/250\n",
            "56/60 [===========================>..] - ETA: 0s - loss: 0.3118 - accuracy: 0.8728\n",
            "Epoch 00233: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3106 - accuracy: 0.8737 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 234/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3081 - accuracy: 0.8757 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 235/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3067 - accuracy: 0.8740 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 236/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3128 - accuracy: 0.8719 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 237/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3100 - accuracy: 0.8723 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 238/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3116 - accuracy: 0.8717 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 239/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3073 - accuracy: 0.8747 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 240/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3097 - accuracy: 0.8710 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 241/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3135 - accuracy: 0.8720 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 242/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3111 - accuracy: 0.8711 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 243/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3098 - accuracy: 0.8735 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 244/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3086 - accuracy: 0.8738 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 245/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3123 - accuracy: 0.8708 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 246/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3109 - accuracy: 0.8720 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 247/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3085 - accuracy: 0.8721 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 248/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3058 - accuracy: 0.8770 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 249/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3137 - accuracy: 0.8708 - val_loss: 0.3521 - val_accuracy: 0.8450\n",
            "Epoch 250/250\n",
            "60/60 [==============================] - 1s 13ms/step - loss: 0.3102 - accuracy: 0.8737 - val_loss: 0.3521 - val_accuracy: 0.8450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6eab232e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsq0PSE9lf-L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc3a7bb-64b5-4b35-9aad-63f8d354fd61"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the trained CNN for the D.melanogaster-D.sechellia pair using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing test set simulations.\n",
        "t1 = np.load(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Drosophila/melano_sechellia/simModel1.npz\")\n",
        "t2 = np.load(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Drosophila/melano_sechellia/simModel2.npz\")\n",
        "t1 = t1[\"simModel1\"]\n",
        "t2 = t2[\"simModel2\"]\n",
        "t=np.concatenate((t1,t2),axis=0)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(t):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      t[arr][idx][t[arr][idx] == 0] = -1\n",
        "      t[arr][idx][t[arr][idx] == 1] = 0\n",
        "      t[arr][idx][t[arr][idx] == -1] = 1\n",
        "t=t.astype(np.uint8)\n",
        "\n",
        "# Label simulations from the test set.\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y = np.array(y)\n",
        "\n",
        "# Load the trained model.\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod')\n",
        "\n",
        "# Predict and export a confusion matrix.\n",
        "pred = model.predict(t)\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[879 121]\n",
            " [187 813]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NqOA1Lrl5-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e40b631-e1db-48a7-9c98-21a9443bb941"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Evaluate the trained CNN for the D.melanogaster-D.simulans pair using 1,000 simulations per model as test set.\n",
        "################################################################################################################################################\n",
        "# Load Numpy arrays containing test set simulations.\n",
        "t1 = np.load(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Drosophila/melano_simulans/simModel1.npz\")\n",
        "t2 = np.load(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/TestData/Drosophila/melano_simulans/simModel2.npz\")\n",
        "t1 = t1[\"simModel1\"]\n",
        "t2 = t2[\"simModel2\"]\n",
        "t=np.concatenate((t1,t2),axis=0)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for arr,array in enumerate(t):\n",
        "  for idx,row in enumerate(array):\n",
        "    if np.count_nonzero(row) > len(row)/2:\n",
        "      t[arr][idx][t[arr][idx] == 0] = -1\n",
        "      t[arr][idx][t[arr][idx] == 1] = 0\n",
        "      t[arr][idx][t[arr][idx] == -1] = 1\n",
        "t=t.astype(np.uint8)\n",
        "\n",
        "# Label simulations from the test set.\n",
        "y=[0 for i in range(len(t1))]\n",
        "y.extend([1 for i in range(len(t2))])\n",
        "y = np.array(y)\n",
        "\n",
        "# Load the trained model.\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod')\n",
        "\n",
        "# Predict and export a confusion matrix.\n",
        "pred = model.predict(t)\n",
        "pred_cat = [i.argmax() for i in pred]\n",
        "print (confusion_matrix(y, pred_cat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[783 217]\n",
            " [145 855]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JozLQLUBBSzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feac6e23-3f28-4990-8723-b0e240dd04d0"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Predict the mos likely model for the empirical data, using the CNN trained with 10K simulations per model.\n",
        "################################################################################################################################################\n",
        "# Load the trained network.\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_sechellia.acc.mod')\n",
        "# Load empirical data and transpose it.\n",
        "infile=np.loadtxt(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/input_melano_sechellia.txt\")\n",
        "inp=[]\n",
        "inp.append(np.array(infile).T)\n",
        "inp = np.array(inp)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for idx,row in enumerate(inp[0]):\n",
        "  if np.count_nonzero(row) > len(row)/2:\n",
        "    inp[0][idx][inp[0][idx] == 0] = -1\n",
        "    inp[0][idx][inp[0][idx] == 1] = 0\n",
        "    inp[0][idx][inp[0][idx] == -1] = 1\n",
        "inp=inp.astype(np.uint8)\n",
        "\n",
        "# Predict the most likely model.\n",
        "pred = model.predict(inp)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.05142106 0.94857895]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5jg71Og9gCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5ccaed-1013-4249-f0af-2e87bbe455d6"
      },
      "source": [
        "################################################################################################################################################\n",
        "#Predict the mos likely model for the empirical data, using the CNN trained with 10K simulations per model.\n",
        "################################################################################################################################################\n",
        "# Load the trained network.\n",
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/Trained_10KSims_melano_simulans.acc.mod')\n",
        "# Load empirical data and transpose it.\n",
        "infile=np.loadtxt(\"/content/drive/MyDrive/Colab Notebooks/CNN_SpDelimitation_Piloso/input_melano_simulans.txt\")\n",
        "inp=[]\n",
        "inp.append(np.array(infile).T)\n",
        "inp = np.array(inp)\n",
        "\n",
        "#Convert major allele to 0 and minor allele to 1\n",
        "for idx,row in enumerate(inp[0]):\n",
        "  if np.count_nonzero(row) > len(row)/2:\n",
        "    inp[0][idx][inp[0][idx] == 0] = -1\n",
        "    inp[0][idx][inp[0][idx] == 1] = 0\n",
        "    inp[0][idx][inp[0][idx] == -1] = 1\n",
        "inp=inp.astype(np.uint8)\n",
        "\n",
        "# Predict the most likely model.\n",
        "pred = model.predict(inp)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00754976 0.99245024]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}